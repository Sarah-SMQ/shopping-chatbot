{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19470b16",
   "metadata": {},
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "No such keys(s): 'io.excel.zip.reader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOptionError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m file_brave = \u001b[33m\"\u001b[39m\u001b[33mC:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_brave\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_links\u001b[39m(cell):\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pd.isna(cell):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1559\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1559\u001b[39m engine = \u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_option\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mio.excel.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.reader\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1561\u001b[39m     engine = get_default_engine(ext, mode=\u001b[33m\"\u001b[39m\u001b[33mreader\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\_config\\config.py:274\u001b[39m, in \u001b[36mCallableDynamicDoc.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwds) -> T:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__func__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\_config\\config.py:146\u001b[39m, in \u001b[36m_get_option\u001b[39m\u001b[34m(pat, silent)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_option\u001b[39m(pat: \u001b[38;5;28mstr\u001b[39m, silent: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     key = \u001b[43m_get_single_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;66;03m# walk the nested dict\u001b[39;00m\n\u001b[32m    149\u001b[39m     root, k = _get_root(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\_config\\config.py:132\u001b[39m, in \u001b[36m_get_single_key\u001b[39m\u001b[34m(pat, silent)\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[32m    131\u001b[39m         _warn_if_deprecated(pat)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OptionError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo such keys(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(pat)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keys) > \u001b[32m1\u001b[39m:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OptionError(\u001b[33m\"\u001b[39m\u001b[33mPattern matched multiple keys\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOptionError\u001b[39m: No such keys(s): 'io.excel.zip.reader'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_brave = \"C:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\"\n",
    "df = pd.read_excel(file_brave)\n",
    "\n",
    "def extract_links(cell):\n",
    "    if pd.isna(cell):\n",
    "        return \"\"\n",
    "    links = []\n",
    "    for line in str(cell.split(\"\\n\")):\n",
    "        parts = line.split(\" - \")\n",
    "        if len(parts) >= 2:\n",
    "            links.append(parts[-1].strip())\n",
    "    return \"\\n\".join(links)\n",
    "\n",
    "df[\"url\"] = df[\"brave_source\"].apply(extract_links)\n",
    "\n",
    "\n",
    "\n",
    "df.to_excel(file_brave, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6fc86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cba798",
   "metadata": {},
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "No such keys(s): 'io.excel.zip.reader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOptionError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m file_brave = \u001b[33m\"\u001b[39m\u001b[33mC:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_brave\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_links\u001b[39m(cell):\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pd.isna(cell):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1559\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1559\u001b[39m engine = \u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_option\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mio.excel.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.reader\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1561\u001b[39m     engine = get_default_engine(ext, mode=\u001b[33m\"\u001b[39m\u001b[33mreader\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\_config\\config.py:274\u001b[39m, in \u001b[36mCallableDynamicDoc.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwds) -> T:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__func__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\_config\\config.py:146\u001b[39m, in \u001b[36m_get_option\u001b[39m\u001b[34m(pat, silent)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_option\u001b[39m(pat: \u001b[38;5;28mstr\u001b[39m, silent: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     key = \u001b[43m_get_single_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;66;03m# walk the nested dict\u001b[39;00m\n\u001b[32m    149\u001b[39m     root, k = _get_root(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\_config\\config.py:132\u001b[39m, in \u001b[36m_get_single_key\u001b[39m\u001b[34m(pat, silent)\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[32m    131\u001b[39m         _warn_if_deprecated(pat)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OptionError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo such keys(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(pat)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keys) > \u001b[32m1\u001b[39m:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OptionError(\u001b[33m\"\u001b[39m\u001b[33mPattern matched multiple keys\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOptionError\u001b[39m: No such keys(s): 'io.excel.zip.reader'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_brave = \"C:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\"\n",
    "df = pd.read_excel(file_brave)\n",
    "\n",
    "def extract_links(cell):\n",
    "    if pd.isna(cell):\n",
    "        return \"\"\n",
    "    links = []\n",
    "    for line in str(cell).split(\"\\n\"):\n",
    "        parts = line.split(\" - \")\n",
    "        if len(parts) >= 2:\n",
    "            links.append(parts[-1].strip())\n",
    "    return \"\\n\".join(links)\n",
    "\n",
    "df[\"url\"] = df[\"brave_source\"].apply(extract_links)\n",
    "\n",
    "\n",
    "\n",
    "df.to_excel(file_brave, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13f9bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_brave\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenpyxl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1565\u001b[39m \u001b[38;5;28mself\u001b[39m.storage_options = storage_options\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:553\u001b[39m, in \u001b[36mOpenpyxlReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    552\u001b[39m import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:573\u001b[39m, in \u001b[36mBaseExcelReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28mself\u001b[39m.book = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:572\u001b[39m, in \u001b[36mOpenpyxlReader.load_workbook\u001b[39m\u001b[34m(self, filepath_or_buffer, engine_kwargs)\u001b[39m\n\u001b[32m    570\u001b[39m default_kwargs = {\u001b[33m\"\u001b[39m\u001b[33mread_only\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mdata_only\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mkeep_links\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[32m--> \u001b[39m\u001b[32m572\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_workbook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\reader\\excel.py:348\u001b[39m, in \u001b[36mload_workbook\u001b[39m\u001b[34m(filename, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[39m\n\u001b[32m    346\u001b[39m reader = ExcelReader(filename, read_only, keep_vba,\n\u001b[32m    347\u001b[39m                      data_only, keep_links, rich_text)\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m \u001b[43mreader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reader.wb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\reader\\excel.py:289\u001b[39m, in \u001b[36mExcelReader.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_manifest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m     action = \u001b[33m\"\u001b[39m\u001b[33mread strings\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\reader\\excel.py:134\u001b[39m, in \u001b[36mExcelReader.read_manifest\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_manifest\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     src = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marchive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mARC_CONTENT_TYPES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     root = fromstring(src)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py:1526\u001b[39m, in \u001b[36mZipFile.read\u001b[39m\u001b[34m(self, name, pwd)\u001b[39m\n\u001b[32m   1525\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return file bytes for name.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1526\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m   1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py:1563\u001b[39m, in \u001b[36mZipFile.open\u001b[39m\u001b[34m(self, name, mode, pwd, force_zip64)\u001b[39m\n\u001b[32m   1561\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1562\u001b[39m     \u001b[38;5;66;03m# Get info object for name\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1563\u001b[39m     zinfo = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgetinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py:1492\u001b[39m, in \u001b[36mZipFile.getinfo\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1492\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m   1493\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mThere is no item named \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m in the archive\u001b[39m\u001b[33m'\u001b[39m % name)\n\u001b[32m   1495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m info\n",
      "\u001b[31mKeyError\u001b[39m: \"There is no item named '[Content_Types].xml' in the archive\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m     df = pd.read_excel(file_brave, engine=\u001b[33m\"\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_brave\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_bad_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mskip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_links\u001b[39m(cell):\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pd.isna(cell):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_brave = \"C:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\"\n",
    "\n",
    "# نحاول نقرأ الملف، ولو مو Excel حقيقي نحوله CSV\n",
    "try:\n",
    "    df = pd.read_excel(file_brave, engine=\"openpyxl\")\n",
    "except Exception:\n",
    "    df = pd.read_csv(file_brave, encoding=\"utf-8\", sep=\",\", on_bad_lines=\"skip\")\n",
    "\n",
    "def extract_links(cell):\n",
    "    if pd.isna(cell):\n",
    "        return \"\"\n",
    "    links = []\n",
    "    for line in str(cell).split(\"\\n\"):\n",
    "        parts = line.split(\" - \")\n",
    "        if len(parts) >= 2:\n",
    "            links.append(parts[-1].strip())  # ناخذ الرابط فقط\n",
    "    return \"\\n\".join(links)\n",
    "\n",
    "# إنشاء العمود الجديد\n",
    "df[\"url\"] = df[\"brave_source\"].apply(extract_links)\n",
    "\n",
    "# نحفظ نسخة جديدة عشان ما نخرب الملف الأصلي\n",
    "output_file = \"C:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_urls.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"تم استخراج الروابط وحفظ الملف الجديد:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2193e239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PK\u0003\u0004\u0014\u0000\u0000\u0000\u0013`8[FMH\u0000\u0000\u0000\u0000\u0000\u0000\u0010\u0000\u0000\u0000docProps/app.xmlMM\u000b0\f\u0006Rv\u001e\u000eD=.u)m\u0004?nyy\u001b.\"&E.m32\n",
      "\n",
      "@#>ʡ{1݁\u001a\u000f\u001f\u001e\u0003âm׀1\f8ⷰ.FguϖBw:Q&X4:'\u001f\u001c\n",
      "\n",
      "\u0010z%>\u0013K9+\u0005S\u0015Sod\u0005\u0007\u0017PK\u0003\u0004\u0014\u0000\u0000\u0000\u0013`8[q\u0010&\u0000\u0000\u0000\u0000+\u0002\u0000\u0000\u0011\u0000\u0000\u0000docProps/core.xml͒N0\f_\u0005:m\u0001\u0005\t$$&EEk(1je\u00018gɭB/)DLd1_\n",
      "\n",
      "Yf{(\u0000ޣS\u001c\u0013~lnCrgAT5Q`\u0002\u0016q!2\u001a-tBE!F/\u0019f4`\u000e=e\n",
      "\n",
      "&еp\u0001L0w\u0001Bb\u000eSrvI}_͜\u001bwu^>\u001a_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# نقرأ الملف كنص خام\n",
    "file_brave = \"C:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\"\n",
    "\n",
    "with open(file_brave, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1179bcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"There is no item named '[Content_Types].xml' in the archive\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m file_brave = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_brave\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenpyxl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.head())   \u001b[38;5;66;03m# يعرض أول 5 صفوف\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.columns)  \u001b[38;5;66;03m# يعرض أسماء الأعمدة\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28mself\u001b[39m.engine = engine\n\u001b[32m   1565\u001b[39m \u001b[38;5;28mself\u001b[39m.storage_options = storage_options\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:553\u001b[39m, in \u001b[36mOpenpyxlReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    542\u001b[39m \u001b[33;03mReader using openpyxl engine.\u001b[39;00m\n\u001b[32m    543\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    550\u001b[39m \u001b[33;03m    Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    552\u001b[39m import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:573\u001b[39m, in \u001b[36mBaseExcelReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28mself\u001b[39m.handles.handle.seek(\u001b[32m0\u001b[39m)\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28mself\u001b[39m.book = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    575\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:572\u001b[39m, in \u001b[36mOpenpyxlReader.load_workbook\u001b[39m\u001b[34m(self, filepath_or_buffer, engine_kwargs)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenpyxl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_workbook\n\u001b[32m    570\u001b[39m default_kwargs = {\u001b[33m\"\u001b[39m\u001b[33mread_only\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mdata_only\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mkeep_links\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[32m--> \u001b[39m\u001b[32m572\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_workbook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\reader\\excel.py:348\u001b[39m, in \u001b[36mload_workbook\u001b[39m\u001b[34m(filename, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Open the given filename and return the workbook\u001b[39;00m\n\u001b[32m    319\u001b[39m \n\u001b[32m    320\u001b[39m \u001b[33;03m:param filename: the path to open or a file-like object\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    344\u001b[39m \n\u001b[32m    345\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    346\u001b[39m reader = ExcelReader(filename, read_only, keep_vba,\n\u001b[32m    347\u001b[39m                      data_only, keep_links, rich_text)\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m \u001b[43mreader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reader.wb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\reader\\excel.py:289\u001b[39m, in \u001b[36mExcelReader.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    287\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mread manifest\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_manifest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m     action = \u001b[33m\"\u001b[39m\u001b[33mread strings\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m.read_strings()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\reader\\excel.py:134\u001b[39m, in \u001b[36mExcelReader.read_manifest\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_manifest\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     src = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marchive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mARC_CONTENT_TYPES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     root = fromstring(src)\n\u001b[32m    136\u001b[39m     \u001b[38;5;28mself\u001b[39m.package = Manifest.from_tree(root)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py:1526\u001b[39m, in \u001b[36mZipFile.read\u001b[39m\u001b[34m(self, name, pwd)\u001b[39m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, pwd=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1525\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return file bytes for name.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1526\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m   1527\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py:1563\u001b[39m, in \u001b[36mZipFile.open\u001b[39m\u001b[34m(self, name, mode, pwd, force_zip64)\u001b[39m\n\u001b[32m   1560\u001b[39m     zinfo._compresslevel = \u001b[38;5;28mself\u001b[39m.compresslevel\n\u001b[32m   1561\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1562\u001b[39m     \u001b[38;5;66;03m# Get info object for name\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1563\u001b[39m     zinfo = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgetinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1566\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py:1492\u001b[39m, in \u001b[36mZipFile.getinfo\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1490\u001b[39m info = \u001b[38;5;28mself\u001b[39m.NameToInfo.get(name)\n\u001b[32m   1491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1492\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m   1493\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mThere is no item named \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m in the archive\u001b[39m\u001b[33m'\u001b[39m % name)\n\u001b[32m   1495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m info\n",
      "\u001b[31mKeyError\u001b[39m: \"There is no item named '[Content_Types].xml' in the archive\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_brave = r\"C:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\"\n",
    "\n",
    "df = pd.read_excel(file_brave, engine=\"openpyxl\")\n",
    "\n",
    "print(df.head())   # يعرض أول 5 صفوف\n",
    "print(df.columns)  # يعرض أسماء الأعمدة\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34c513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "فشل كـ CSV: 'utf-8' codec can't decode byte 0xc7 in position 15: invalid continuation byte\n",
      "                                            question  \\\n",
      "0   When did TikTok launch its US shopping platform?   \n",
      "1  What is the expected global online retail sale...   \n",
      "2  Who authored the article '6 Best E-commerce Pl...   \n",
      "3  According to 'The State of AI in E-Commerce: 2...   \n",
      "4  According to the article '4 Big Trends For DTC...   \n",
      "\n",
      "                                        answer_brave  \\\n",
      "0   TikTok launched its US shopping platform, Tik...   \n",
      "1   According to the ECDB report, the global onli...   \n",
      "2   I apologize, but I am unable to provide the a...   \n",
      "3   According to the report, sustainability accou...   \n",
      "4   According to the article, 70% of online shopp...   \n",
      "\n",
      "                                        ground_truth  \\\n",
      "0  TikTok launched its US shopping platform in Se...   \n",
      "1  Global online retail sales are expected to exc...   \n",
      "2  The article '6 Best E-commerce Platforms of 20...   \n",
      "3  Sustainability accounted for 8.8% of the total...   \n",
      "4  70% of online shoppers say that product conten...   \n",
      "\n",
      "                                        brave_source  \\\n",
      "0  ['TikTok - Wikipedia - https://en.wikipedia.or...   \n",
      "1  ['Global retail e-commerce sales 2022-2028| St...   \n",
      "2  ['6 Best E-commerce Platforms of 2025: My Revi...   \n",
      "3  ['The State of AI in E-Commerce: 2025 Quid Tre...   \n",
      "4  ['Council Post: 4 Big Trends For DTC E-Commerc...   \n",
      "\n",
      "                                          brave_sinp     subject verdict  \\\n",
      "0  [{'doc_id': 0, 'source': 'TikTok - Wikipedia -...  E-commerce    Pass   \n",
      "1  [{'doc_id': 0, 'source': 'Global retail e-comm...  E-commerce    Fail   \n",
      "2  [{'doc_id': 0, 'source': '6 Best E-commerce Pl...  E-commerce    Fail   \n",
      "3  [{'doc_id': 0, 'source': 'The State of AI in E...  E-commerce    Pass   \n",
      "4  [{'doc_id': 0, 'source': 'Council Post: 4 Big ...  E-commerce    Pass   \n",
      "\n",
      "      error_type                                        explanation  \\\n",
      "0            NaN  The system response is factually accurate, rel...   \n",
      "1  Factual Error  The system response fails because it provides ...   \n",
      "2  Factual Error  The system response fails to provide the corre...   \n",
      "3            NaN  The system response is factually accurate, rel...   \n",
      "4            NaN  The system response is factually accurate, dir...   \n",
      "\n",
      "                                           reasoning  pass_bool url  \n",
      "0  The system response correctly states that TikT...       True      \n",
      "1  1. **Factual Accuracy**: The system response s...      False      \n",
      "2  The system response states that it cannot prov...      False      \n",
      "3  The system response accurately states that sus...       True      \n",
      "4  The system response accurately states that 70%...       True      \n",
      "Index(['question', 'answer_brave', 'ground_truth', 'brave_source',\n",
      "       'brave_sinp', 'subject', 'verdict', 'error_type', 'explanation',\n",
      "       'reasoning', 'pass_bool', 'url'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_brave = r\"C:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\"\n",
    "\n",
    "# نحاول نقرأ الملف كـ CSV\n",
    "try:\n",
    "    df = pd.read_csv(file_brave, encoding=\"utf-8\", engine=\"python\")\n",
    "    print(\"تمت قراءته كـ CSV ✅\")\n",
    "except Exception as e:\n",
    "    print(\"فشل كـ CSV:\", e)\n",
    "\n",
    "# نعرض أول 5 صفوف\n",
    "print(df.head())\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e03f83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "',' expected after '\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mError\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:805\u001b[39m, in \u001b[36mPythonParser._next_iter_line\u001b[39m\u001b[34m(self, row_num)\u001b[39m\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m805\u001b[39m line = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.data)\n\u001b[32m    806\u001b[39m \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "\u001b[31mError\u001b[39m: ',' expected after '\"'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m file_excel = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_fixed.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# نقرأ الملف كـ CSV (مع التجربة encoding مناسب)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlatin1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# نحفظه كـ Excel صحيح\u001b[39;00m\n\u001b[32m     10\u001b[39m df.to_excel(file_excel, index=\u001b[38;5;28;01mFalse\u001b[39;00m, engine=\u001b[33m\"\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:252\u001b[39m, in \u001b[36mPythonParser.read\u001b[39m\u001b[34m(self, rows)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\n\u001b[32m    247\u001b[39m     \u001b[38;5;28mself\u001b[39m, rows: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    248\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\n\u001b[32m    249\u001b[39m     Index | \u001b[38;5;28;01mNone\u001b[39;00m, Sequence[Hashable] | MultiIndex, Mapping[Hashable, ArrayLike]\n\u001b[32m    250\u001b[39m ]:\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m         content = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    254\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._first_chunk:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:1140\u001b[39m, in \u001b[36mPythonParser._get_lines\u001b[39m\u001b[34m(self, rows)\u001b[39m\n\u001b[32m   1137\u001b[39m rows = \u001b[32m0\u001b[39m\n\u001b[32m   1139\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m     next_row = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_iter_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_num\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m     rows += \u001b[32m1\u001b[39m\n\u001b[32m   1143\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m next_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:834\u001b[39m, in \u001b[36mPythonParser._next_iter_line\u001b[39m\u001b[34m(self, row_num)\u001b[39m\n\u001b[32m    825\u001b[39m         reason = (\n\u001b[32m    826\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mError could possibly be due to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    827\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparsing errors in the skipped footer rows \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    830\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mall rows).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    831\u001b[39m         )\n\u001b[32m    832\u001b[39m         msg += \u001b[33m\"\u001b[39m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m + reason\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_alert_malformed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:781\u001b[39m, in \u001b[36mPythonParser._alert_malformed\u001b[39m\u001b[34m(self, msg, row_num)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    765\u001b[39m \u001b[33;03mAlert a user about a malformed row, depending on value of\u001b[39;00m\n\u001b[32m    766\u001b[39m \u001b[33;03m`self.on_bad_lines` enum.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    778\u001b[39m \u001b[33;03m    even though we 0-index internally.\u001b[39;00m\n\u001b[32m    779\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.on_bad_lines == \u001b[38;5;28mself\u001b[39m.BadLineHandleMethod.ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m781\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(msg)\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.on_bad_lines == \u001b[38;5;28mself\u001b[39m.BadLineHandleMethod.WARN:\n\u001b[32m    783\u001b[39m     warnings.warn(\n\u001b[32m    784\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipping line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    785\u001b[39m         ParserWarning,\n\u001b[32m    786\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    787\u001b[39m     )\n",
      "\u001b[31mParserError\u001b[39m: ',' expected after '\"'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_csv = r\"C:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\"\n",
    "file_excel = r\"C:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_fixed.xlsx\"\n",
    "\n",
    "# نقرأ الملف كـ CSV (مع التجربة encoding مناسب)\n",
    "df = pd.read_csv(file_csv, encoding=\"latin1\", engine=\"python\")\n",
    "\n",
    "# نحفظه كـ Excel صحيح\n",
    "df.to_excel(file_excel, index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(\"تم حفظ نسخة Excel صحيحة:\", file_excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d080e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: PK\u0003\u0004\u0014\u0000\u0000\u0000\u0013`8[FÇMH\u0000\u0000\u0000Í\u0000\u0000\u0000\u0010\u0000\u0000\u0000docProps/app.xmlMÏM\u000bÂ0\f\u0006à¿Rv·\u001e¤\u000eD=¼Ï.u¶)múïí\u0004?nyyÈ\u001b¢.\"&¶Eñ.äm32Ç\n",
      "\n",
      "Line 2: @Ö#ú>ËÊ¡¡ä{®1Ý±\u001a\u000f¤\u001f\u001e\u0003Ã¢m×1\f8Ìâ·°éÔ.FguÏBw²:Q&ÃâX4:±'\u001f«Ü\u001c\n",
      "\n",
      "Line 3: \u0010çz%>\u0013K9+\u0005ÿSË\u0015SæÊoüd\u0005¿\u0007º\u0017PK\u0003\u0004\u0014\u0000\u0000\u0000\u0013`8[q\u0010&\u0000ï\u0000\u0000\u0000+\u0002\u0000\u0000\u0011\u0000\u0000\u0000docProps/core.xmlÍÏNÃ0\f_\u0005åÞ:m\u0001±¨Ë\u0005Ä\t$$&¸E·Ekþ(1j÷ö´eëà\u00018ÆþåógÉ­B/)DLd1_\n",
      "\n",
      "Line 4: ®óYè¸f{¢(\u0000²Þ£S¹\u001c\u0013~lnCrÆgÚATú 5ç·àQ¤`\u0002\u0016q!2Ù\u001a-tBE!ðF/øøº\u0019f4`\u000e=e¨Ê\n",
      "\n",
      "Line 5: &ÆãÐµp\u0001L0Âäòw\u0001ÍB«bç\u000e°SrÈvIõ}_öÍ\u001bw¨àýùéu^·°>ò\u001aÇ_Ù\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_raw = r\"C:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\"\n",
    "\n",
    "# نقرأ الملف كسطور نصية (بدون اعتبار أنه Excel أو CSV مرتب)\n",
    "with open(file_raw, \"r\", encoding=\"latin1\", errors=\"ignore\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# نشوف أول 5 سطور عشان نحدد شكل الداتا\n",
    "for i, line in enumerate(lines[:5]):\n",
    "    print(f\"Line {i+1}: {line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795f7d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"There is no item named '[Content_Types].xml' in the archive\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m file_brave = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# لازم نستخدم محرك openpyxl لأنه XLSX\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_brave\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenpyxl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.head())   \u001b[38;5;66;03m# أول 5 صفوف\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.columns)  \u001b[38;5;66;03m# أسماء الأعمدة\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28mself\u001b[39m.engine = engine\n\u001b[32m   1565\u001b[39m \u001b[38;5;28mself\u001b[39m.storage_options = storage_options\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:553\u001b[39m, in \u001b[36mOpenpyxlReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    542\u001b[39m \u001b[33;03mReader using openpyxl engine.\u001b[39;00m\n\u001b[32m    543\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    550\u001b[39m \u001b[33;03m    Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    552\u001b[39m import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:573\u001b[39m, in \u001b[36mBaseExcelReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28mself\u001b[39m.handles.handle.seek(\u001b[32m0\u001b[39m)\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28mself\u001b[39m.book = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    575\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:572\u001b[39m, in \u001b[36mOpenpyxlReader.load_workbook\u001b[39m\u001b[34m(self, filepath_or_buffer, engine_kwargs)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenpyxl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_workbook\n\u001b[32m    570\u001b[39m default_kwargs = {\u001b[33m\"\u001b[39m\u001b[33mread_only\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mdata_only\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mkeep_links\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[32m--> \u001b[39m\u001b[32m572\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_workbook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\reader\\excel.py:348\u001b[39m, in \u001b[36mload_workbook\u001b[39m\u001b[34m(filename, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Open the given filename and return the workbook\u001b[39;00m\n\u001b[32m    319\u001b[39m \n\u001b[32m    320\u001b[39m \u001b[33;03m:param filename: the path to open or a file-like object\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    344\u001b[39m \n\u001b[32m    345\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    346\u001b[39m reader = ExcelReader(filename, read_only, keep_vba,\n\u001b[32m    347\u001b[39m                      data_only, keep_links, rich_text)\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m \u001b[43mreader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reader.wb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\reader\\excel.py:289\u001b[39m, in \u001b[36mExcelReader.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    287\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mread manifest\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_manifest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m     action = \u001b[33m\"\u001b[39m\u001b[33mread strings\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m.read_strings()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\reader\\excel.py:134\u001b[39m, in \u001b[36mExcelReader.read_manifest\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_manifest\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     src = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marchive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mARC_CONTENT_TYPES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     root = fromstring(src)\n\u001b[32m    136\u001b[39m     \u001b[38;5;28mself\u001b[39m.package = Manifest.from_tree(root)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py:1526\u001b[39m, in \u001b[36mZipFile.read\u001b[39m\u001b[34m(self, name, pwd)\u001b[39m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, pwd=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1525\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return file bytes for name.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1526\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m   1527\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py:1563\u001b[39m, in \u001b[36mZipFile.open\u001b[39m\u001b[34m(self, name, mode, pwd, force_zip64)\u001b[39m\n\u001b[32m   1560\u001b[39m     zinfo._compresslevel = \u001b[38;5;28mself\u001b[39m.compresslevel\n\u001b[32m   1561\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1562\u001b[39m     \u001b[38;5;66;03m# Get info object for name\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1563\u001b[39m     zinfo = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgetinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1566\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py:1492\u001b[39m, in \u001b[36mZipFile.getinfo\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1490\u001b[39m info = \u001b[38;5;28mself\u001b[39m.NameToInfo.get(name)\n\u001b[32m   1491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1492\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m   1493\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mThere is no item named \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m in the archive\u001b[39m\u001b[33m'\u001b[39m % name)\n\u001b[32m   1495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m info\n",
      "\u001b[31mKeyError\u001b[39m: \"There is no item named '[Content_Types].xml' in the archive\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_brave = r\"C:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\"\n",
    "\n",
    "# لازم نستخدم محرك openpyxl لأنه XLSX\n",
    "df = pd.read_excel(file_brave, engine=\"openpyxl\")\n",
    "\n",
    "print(df.head())   # أول 5 صفوف\n",
    "print(df.columns)  # أسماء الأعمدة\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae42b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is real XLSX (zip)? True\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "file_brave = r\"C:/Users/SarahAlqahtani/Documents/code/brave_eval_with_allam_judge_240_dd_temp_to_p_v2.xlsx\"\n",
    "\n",
    "is_zip = zipfile.is_zipfile(file_brave)\n",
    "print(\"Is real XLSX (zip)?\", is_zip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c190f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0   When did TikTok launch its US shopping platform?   \n",
      "1  What is the expected global online retail sale...   \n",
      "2  Who authored the article '6 Best E-commerce Pl...   \n",
      "3  According to 'The State of AI in E-Commerce: 2...   \n",
      "4  According to the article '4 Big Trends For DTC...   \n",
      "\n",
      "                                        answer_brave  \\\n",
      "0   TikTok launched its US shopping platform, Tik...   \n",
      "1   According to the ECDB report, the global onli...   \n",
      "2   I apologize, but I am unable to provide the a...   \n",
      "3   According to the report, sustainability accou...   \n",
      "4   According to the article, 70% of online shopp...   \n",
      "\n",
      "                                        ground_truth  \\\n",
      "0  TikTok launched its US shopping platform in Se...   \n",
      "1  Global online retail sales are expected to exc...   \n",
      "2  The article '6 Best E-commerce Platforms of 20...   \n",
      "3  Sustainability accounted for 8.8% of the total...   \n",
      "4  70% of online shoppers say that product conten...   \n",
      "\n",
      "                                        brave_source  \\\n",
      "0  ['TikTok - Wikipedia - https://en.wikipedia.or...   \n",
      "1  ['Global retail e-commerce sales 2022-2028| St...   \n",
      "2  ['6 Best E-commerce Platforms of 2025: My Revi...   \n",
      "3  ['The State of AI in E-Commerce: 2025 Quid Tre...   \n",
      "4  ['Council Post: 4 Big Trends For DTC E-Commerc...   \n",
      "\n",
      "                                          brave_sinp     subject verdict  \\\n",
      "0  [{'doc_id': 0, 'source': 'TikTok - Wikipedia -...  E-commerce    Pass   \n",
      "1  [{'doc_id': 0, 'source': 'Global retail e-comm...  E-commerce    Fail   \n",
      "2  [{'doc_id': 0, 'source': '6 Best E-commerce Pl...  E-commerce    Fail   \n",
      "3  [{'doc_id': 0, 'source': 'The State of AI in E...  E-commerce    Pass   \n",
      "4  [{'doc_id': 0, 'source': 'Council Post: 4 Big ...  E-commerce    Pass   \n",
      "\n",
      "      error_type                                        explanation  \\\n",
      "0            NaN  The system response is factually accurate, rel...   \n",
      "1  Factual Error  The system response fails because it provides ...   \n",
      "2  Factual Error  The system response fails to provide the corre...   \n",
      "3            NaN  The system response is factually accurate, rel...   \n",
      "4            NaN  The system response is factually accurate, dir...   \n",
      "\n",
      "                                           reasoning  pass_bool  \n",
      "0  The system response correctly states that TikT...       True  \n",
      "1  1. **Factual Accuracy**: The system response s...      False  \n",
      "2  The system response states that it cannot prov...      False  \n",
      "3  The system response accurately states that sus...       True  \n",
      "4  The system response accurately states that 70%...       True  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_brave = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_eval_with_allam_judge_240_dd_temp_to_p_v2_3.xlsx\"\n",
    "df = pd.read_excel(file_brave, engine=\"openpyxl\")\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a1944",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "#file_brave = \"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2.xlsx\"\n",
    "file_brave = \"C:\\\\Users\\\\SarahAlqahtani\\\\Documents\\\\code\\\\brave_sec_t2.xlsx\"\n",
    "\n",
    "df = pd.read_excel(file_brave)\n",
    "\n",
    "def extract_links(cell):\n",
    "    if pd.isna(cell):\n",
    "        return \"\"\n",
    "    links = []\n",
    "    for line in str(cell.split(\"\\n\")):\n",
    "        parts = line.split(\" - \")\n",
    "        if len(parts) >= 2:\n",
    "            links.append(parts[-1].strip())\n",
    "    return \"\\n\".join(links)\n",
    "\n",
    "df[\"url\"] = df[\"brave_source\"].apply(extract_links)\n",
    "\n",
    "\n",
    "\n",
    "df.to_excel(file_brave, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        brave_source url\n",
      "0  ['TikTok - Wikipedia - https://en.wikipedia.or...    \n",
      "1  ['Global retail e-commerce sales 2022-2028| St...    \n",
      "2  ['6 Best E-commerce Platforms of 2025: My Revi...    \n",
      "3  ['The State of AI in E-Commerce: 2025 Quid Tre...    \n",
      "4  ['Council Post: 4 Big Trends For DTC E-Commerc...    \n",
      "5  ['Council Post: From AI To AR: The Bold Innova...    \n",
      "6  ['MENA E-commerce Market Report 2025, with Pro...    \n",
      "7  ['RetailMeNot Launches App-Exclusive \"5 to Buy...    \n",
      "8  ['History of compiler construction - Wikipedia...    \n",
      "9  ['E-commerce Market Size to Hit USD 75.12 Trn ...    \n"
     ]
    }
   ],
   "source": [
    "print(df[[\"brave_source\", \"url\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c6963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم حفظ الملف: C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\n"
     ]
    }
   ],
   "source": [
    "output_file = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "print(\"تم حفظ الملف:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ad5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"['TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok', 'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok', 'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok', 'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok', 'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok', 'Introducing TikTok Shop - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/introducing-tiktok-shop', 'Introducing TikTok Shop - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/introducing-tiktok-shop', 'Introducing TikTok Shop - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/introducing-tiktok-shop', 'Introducing TikTok Shop - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/introducing-tiktok-shop', 'TikTok Shop - Wikipedia - https://en.wikipedia.org/wiki/TikTok_Shop', 'TikTok Shop - Wikipedia - https://en.wikipedia.org/wiki/TikTok_Shop', 'TikTok Shop - Wikipedia - https://en.wikipedia.org/wiki/TikTok_Shop', 'TikTok officially debuts shopping platform, TikTok Shop, to U.S. consumers - CBS News - https://www.cbsnews.com/news/tiktok-shop-e-commerce-us-debut/', 'TikTok officially debuts shopping platform, TikTok Shop, to U.S. consumers - CBS News - https://www.cbsnews.com/news/tiktok-shop-e-commerce-us-debut/', 'TikTok officially debuts shopping platform, TikTok Shop, to U.S. consumers - CBS News - https://www.cbsnews.com/news/tiktok-shop-e-commerce-us-debut/', 'TikTok officially debuts shopping platform, TikTok Shop, to U.S. consumers - CBS News - https://www.cbsnews.com/news/tiktok-shop-e-commerce-us-debut/', 'TikTok launches online shopping in the US | Reuters - https://www.reuters.com/technology/tiktok-launches-online-shopping-us-2023-09-12/', 'TikTok launches online shopping in the US | Reuters - https://www.reuters.com/technology/tiktok-launches-online-shopping-us-2023-09-12/', 'TikTok launches online shopping in the US | Reuters - https://www.reuters.com/technology/tiktok-launches-online-shopping-us-2023-09-12/', 'TikTok Shop is where shoppers come to discover - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/tiktok-shop-is-where-shoppers-come-to-discover', 'TikTok Shop is where shoppers come to discover - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/tiktok-shop-is-where-shoppers-come-to-discover', 'TikTok Shop is where shoppers come to discover - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/tiktok-shop-is-where-shoppers-come-to-discover', 'TikTok Shop is where shoppers come to discover - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/tiktok-shop-is-where-shoppers-come-to-discover', 'TikTok Shop launches in the U.S. as the company bets big on e-commerce | AP News - https://apnews.com/article/tiktok-online-shopping-65470c109c80408f05875d8678fe5072', 'TikTok Shop launches in the U.S. as the company bets big on e-commerce | AP News - https://apnews.com/article/tiktok-online-shopping-65470c109c80408f05875d8678fe5072', 'TikTok Shop launches in the U.S. as the company bets big on e-commerce | AP News - https://apnews.com/article/tiktok-online-shopping-65470c109c80408f05875d8678fe5072', 'TikTok Shop launches in the U.S. as the company bets big on e-commerce | AP News - https://apnews.com/article/tiktok-online-shopping-65470c109c80408f05875d8678fe5072', 'TikTok Shop officially launches in the US | TechCrunch - https://techcrunch.com/2023/09/12/tiktok-shop-officially-launches-in-the-u-s/', 'TikTok Shop officially launches in the US | TechCrunch - https://techcrunch.com/2023/09/12/tiktok-shop-officially-launches-in-the-u-s/', 'TikTok Shop officially launches in the US | TechCrunch - https://techcrunch.com/2023/09/12/tiktok-shop-officially-launches-in-the-u-s/', 'TikTok Shop officially launches in the US | TechCrunch - https://techcrunch.com/2023/09/12/tiktok-shop-officially-launches-in-the-u-s/', 'TikTok Launches eCommerce Platform, TikTok Shop in the US - Blue Wheel - https://www.bluewheelmedia.com/blog/tiktok-launches-tiktok-shop', 'TikTok Launches eCommerce Platform, TikTok Shop in the US - Blue Wheel - https://www.bluewheelmedia.com/blog/tiktok-launches-tiktok-shop', 'TikTok Launches eCommerce Platform, TikTok Shop in the US - Blue Wheel - https://www.bluewheelmedia.com/blog/tiktok-launches-tiktok-shop', 'TikTok Launches eCommerce Platform, TikTok Shop in the US - Blue Wheel - https://www.bluewheelmedia.com/blog/tiktok-launches-tiktok-shop', 'TikTok’s online marketplace for the US could launch in August | The Verge - https://www.theverge.com/2023/7/25/23806781/tiktok-ecommerce-store-august-launch-date', 'TikTok’s online marketplace for the US could launch in August | The Verge - https://www.theverge.com/2023/7/25/23806781/tiktok-ecommerce-store-august-launch-date', 'TikTok’s online marketplace for the US could launch in August | The Verge - https://www.theverge.com/2023/7/25/23806781/tiktok-ecommerce-store-august-launch-date', 'TikTok’s online marketplace for the US could launch in August | The Verge - https://www.theverge.com/2023/7/25/23806781/tiktok-ecommerce-store-august-launch-date']\", \"['Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/', 'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/', 'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/', 'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/', 'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics', 'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics', 'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics', 'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics', '51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/', '51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/', '51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/', '51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/', 'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/', 'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/', 'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/', 'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/', 'Global Online Retail Statistics and Trends For 2025 - Invesp - https://www.invespcro.com/blog/online-retail-statistics-and-trends/', 'Global Online Retail Statistics and Trends For 2025 - Invesp - https://www.invespcro.com/blog/online-retail-statistics-and-trends/', 'Global Online Retail Statistics and Trends For 2025 - Invesp - https://www.invespcro.com/blog/online-retail-statistics-and-trends/', 'Global Online Retail Statistics and Trends For 2025 - Invesp - https://www.invespcro.com/blog/online-retail-statistics-and-trends/', 'Global e-commerce overview: 2025 insights - https://ecommercegermany.com/blog/global-e-commerce', 'Global e-commerce overview: 2025 insights - https://ecommercegermany.com/blog/global-e-commerce', 'Global e-commerce overview: 2025 insights - https://ecommercegermany.com/blog/global-e-commerce', 'Global e-commerce overview: 2025 insights - https://ecommercegermany.com/blog/global-e-commerce', 'Global Ecommerce Sales Growth (2022–2028) [Updated Oct 2024] - https://www.oberlo.com/statistics/global-ecommerce-sales-growth', 'Global Ecommerce Sales Growth (2022–2028) [Updated Oct 2024] - https://www.oberlo.com/statistics/global-ecommerce-sales-growth', 'Global Ecommerce Sales Growth (2022–2028) [Updated Oct 2024] - https://www.oberlo.com/statistics/global-ecommerce-sales-growth', 'Global Ecommerce Sales Growth (2022–2028) [Updated Oct 2024] - https://www.oberlo.com/statistics/global-ecommerce-sales-growth', 'Global Ecommerce Sales Growth Report [Updated Oct 2024] - Shopify - https://www.shopify.com/blog/global-ecommerce-sales', 'Global Ecommerce Sales Growth Report [Updated Oct 2024] - Shopify - https://www.shopify.com/blog/global-ecommerce-sales', 'Global Ecommerce Sales Growth Report [Updated Oct 2024] - Shopify - https://www.shopify.com/blog/global-ecommerce-sales', 'Global Ecommerce Sales Growth Report [Updated Oct 2024] - Shopify - https://www.shopify.com/blog/global-ecommerce-sales', 'Global eCommerce Sales Growth From 2021-2027 - https://www.yaguara.co/global-ecommerce-sales-growth/', 'Global eCommerce Sales Growth From 2021-2027 - https://www.yaguara.co/global-ecommerce-sales-growth/', 'Global eCommerce Sales Growth From 2021-2027 - https://www.yaguara.co/global-ecommerce-sales-growth/', 'Global eCommerce Sales Growth From 2021-2027 - https://www.yaguara.co/global-ecommerce-sales-growth/']\", \"['6 Best E-commerce Platforms of 2025: My Review - https://learn.g2.com/best-ecommerce-platforms', '6 Best E-commerce Platforms of 2025: My Review - https://learn.g2.com/best-ecommerce-platforms', '6 Best E-commerce Platforms of 2025: My Review - https://learn.g2.com/best-ecommerce-platforms', '6 Best E-commerce Platforms of 2025: My Review - https://learn.g2.com/best-ecommerce-platforms', 'Best E-Commerce Platforms of 2025 – Forbes Advisor - https://www.forbes.com/advisor/business/software/best-ecommerce-platform/', 'Best E-Commerce Platforms of 2025 – Forbes Advisor - https://www.forbes.com/advisor/business/software/best-ecommerce-platform/', 'Best E-Commerce Platforms of 2025 – Forbes Advisor - https://www.forbes.com/advisor/business/software/best-ecommerce-platform/', 'Best E-Commerce Platforms of 2025 – Forbes Advisor - https://www.forbes.com/advisor/business/software/best-ecommerce-platform/', 'Best E-Commerce Platforms for 2025 | The Ad Firm - https://www.theadfirm.net/2025-update-best-e-commerce-platforms-for-2025/', 'Best E-Commerce Platforms for 2025 | The Ad Firm - https://www.theadfirm.net/2025-update-best-e-commerce-platforms-for-2025/', 'Best E-Commerce Platforms for 2025 | The Ad Firm - https://www.theadfirm.net/2025-update-best-e-commerce-platforms-for-2025/', 'Best E-Commerce Platforms for 2025 | The Ad Firm - https://www.theadfirm.net/2025-update-best-e-commerce-platforms-for-2025/', '9 Best Ecommerce Platforms of 2025 (Know Your Options) - https://www.bigcommerce.com/articles/ecommerce/ecommerce-platforms/', '9 Best Ecommerce Platforms of 2025 (Know Your Options) - https://www.bigcommerce.com/articles/ecommerce/ecommerce-platforms/', '9 Best Ecommerce Platforms of 2025 (Know Your Options) - https://www.bigcommerce.com/articles/ecommerce/ecommerce-platforms/', '9 Best Ecommerce Platforms of 2025 (Know Your Options) - https://www.bigcommerce.com/articles/ecommerce/ecommerce-platforms/', '10 Best Ecommerce Platforms in 2025 (Reviewed, Compared, and Rated) - https://www.emailvendorselection.com/best-ecommerce-platforms-review/', '10 Best Ecommerce Platforms in 2025 (Reviewed, Compared, and Rated) - https://www.emailvendorselection.com/best-ecommerce-platforms-review/', '10 Best Ecommerce Platforms in 2025 (Reviewed, Compared, and Rated) - https://www.emailvendorselection.com/best-ecommerce-platforms-review/', '10 Best Ecommerce Platforms in 2025 (Reviewed, Compared, and Rated) - https://www.emailvendorselection.com/best-ecommerce-platforms-review/', 'The 6 best eCommerce website building platforms in 2025 - https://zapier.com/blog/best-ecommerce-shopping-cart-software/', 'The 6 best eCommerce website building platforms in 2025 - https://zapier.com/blog/best-ecommerce-shopping-cart-software/', 'The 6 best eCommerce website building platforms in 2025 - https://zapier.com/blog/best-ecommerce-shopping-cart-software/', 'The 6 best eCommerce website building platforms in 2025 - https://zapier.com/blog/best-ecommerce-shopping-cart-software/', 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', '11 Best Ecommerce Platforms for Your Business in 2025 - Shopify - https://www.shopify.com/blog/best-ecommerce-platforms', '11 Best Ecommerce Platforms for Your Business in 2025 - Shopify - https://www.shopify.com/blog/best-ecommerce-platforms', '11 Best Ecommerce Platforms for Your Business in 2025 - Shopify - https://www.shopify.com/blog/best-ecommerce-platforms', '11 Best Ecommerce Platforms for Your Business in 2025 - Shopify - https://www.shopify.com/blog/best-ecommerce-platforms', '10 E-Commerce Platforms in 2025 - Sunrise Geek - https://www.sunrisegeek.com/post/10-e-commerce-platforms-in-2025', '10 E-Commerce Platforms in 2025 - Sunrise Geek - https://www.sunrisegeek.com/post/10-e-commerce-platforms-in-2025', '10 E-Commerce Platforms in 2025 - Sunrise Geek - https://www.sunrisegeek.com/post/10-e-commerce-platforms-in-2025', '10 E-Commerce Platforms in 2025 - Sunrise Geek - https://www.sunrisegeek.com/post/10-e-commerce-platforms-in-2025']\"]\n"
     ]
    }
   ],
   "source": [
    "print(df[\"brave_source\"].head(3).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b59f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم حفظ الملف: C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# تحديد الملف الأصلي\n",
    "file_brave = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2.xlsx\"\n",
    "\n",
    "# قراءة الملف\n",
    "df = pd.read_excel(file_brave)\n",
    "\n",
    "# دالة لاستخراج الروابط\n",
    "def extract_links(cell):\n",
    "    if pd.isna(cell):\n",
    "        return \"\"\n",
    "    links = []\n",
    "    for line in str(cell).split(\"\\n\"):\n",
    "        parts = line.split(\" - \")\n",
    "        if len(parts) >= 2:\n",
    "            links.append(parts[-1].strip())\n",
    "    return \"\\n\".join(links)\n",
    "\n",
    "# إنشاء العمود الجديد\n",
    "df[\"url\"] = df[\"brave_source\"].apply(extract_links)\n",
    "\n",
    "# حفظ الملف الجديد\n",
    "output_file = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"تم حفظ الملف:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_links(cell):\n",
    "    if pd.isna(cell):\n",
    "        return \"\"\n",
    "    try:\n",
    "        items = ast.literal_eval(cell)\n",
    "        print(\"المحتوى المحلّل:\", items)  # طباعة القوائم لتحقق\n",
    "        links = [x.split(\" - \")[-1].strip() for x in items if \" - \" in x]\n",
    "        return \"\\n\".join(links)\n",
    "    except Exception as e:\n",
    "        print(\"خطأ في التحليل:\", e, \"في الخلية:\", cell)\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d580da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_links(cell):\n",
    "    if pd.isna(cell):\n",
    "        return \"\"\n",
    "    try:\n",
    "        items = ast.literal_eval(cell)\n",
    "    except Exception as e:\n",
    "        # لو التحويل يفشل، نرجع النص الخام ك fallback\n",
    "        return str(cell)\n",
    "    links = []\n",
    "    for x in items:\n",
    "        # تأكد إن هذا العنصر فيه \" - \" قبل ما تقسّمه\n",
    "        if \" - \" in x:\n",
    "            link = x.split(\" - \")[-1].strip()\n",
    "            links.append(link)\n",
    "    return \"\\n\".join(links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102c284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم حفظ الملف: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_clean.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ملف الإدخال\n",
    "file_brave = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2.xlsx\"\n",
    "\n",
    "# قراءة الملف\n",
    "df = pd.read_excel(file_brave)\n",
    "\n",
    "# دالة استخراج الروابط باستخدام regex\n",
    "def extract_links(cell):\n",
    "    if pd.isna(cell):\n",
    "        return \"\"\n",
    "    # نستخدم regex عشان نلتقط أي شيء يبدأ بـ http أو https\n",
    "    links = re.findall(r'https?://\\S+', str(cell))\n",
    "    return \"\\n\".join(links)\n",
    "\n",
    "# تطبيق الدالة\n",
    "df[\"url\"] = df[\"brave_source\"].apply(extract_links)\n",
    "\n",
    "# حفظ الملف الجديد\n",
    "output_file = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_clean.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"تم حفظ الملف:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115011fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم حفظ الملف: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_clean.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # عشان نحول النص لقائمة بايثون\n",
    "\n",
    "file_brave = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2.xlsx\"\n",
    "df = pd.read_excel(file_brave)\n",
    "\n",
    "def extract_links(cell):\n",
    "    if pd.isna(cell):\n",
    "        return \"\"\n",
    "    try:\n",
    "        # تحويل النص لقائمة (مثلاً ['title - url', ...])\n",
    "        items = ast.literal_eval(cell)\n",
    "        links = []\n",
    "        for item in items:\n",
    "            parts = item.split(\" - \")\n",
    "            if len(parts) >= 2:\n",
    "                links.append(parts[-1].strip())\n",
    "        return \"\\n\".join(links)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "df[\"url\"] = df[\"brave_source\"].apply(extract_links)\n",
    "\n",
    "output_file = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_clean.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"تم حفظ الملف:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd89be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم حفظ الملف: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_clean.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # عشان نحول النص لقائمة بايثون\n",
    "\n",
    "file_brave = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2.xlsx\"\n",
    "df = pd.read_excel(file_brave)\n",
    "\n",
    "def extract_links_as_list(cell):\n",
    "    if pd.isna(cell):\n",
    "        return \"\"\n",
    "    try:\n",
    "        # تحويل النص لقائمة (مثلاً ['title - url', ...])\n",
    "        items = ast.literal_eval(cell)\n",
    "        links = []\n",
    "        for item in items:\n",
    "            parts = item.split(\" - \")\n",
    "            if len(parts) >= 2:\n",
    "                links.append(parts[-1].strip())\n",
    "        return \"\\n\".join(links)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "df[\"url\"] = df[\"brave_source\"].apply(extract_links_as_list)\n",
    "\n",
    "output_file = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_clean.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"تم حفظ الملف:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabb7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم حفظ الملف: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_clean.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "file_brave = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2.xlsx\"\n",
    "df = pd.read_excel(file_brave)\n",
    "\n",
    "def extract_links_as_list(cell):\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    try:\n",
    "        items = ast.literal_eval(cell)  # تحويل النص إلى قائمة Python\n",
    "        links = []\n",
    "        for item in items:\n",
    "            parts = item.split(\" - \")\n",
    "            if len(parts) >= 2:\n",
    "                links.append(parts[-1].strip())\n",
    "        return links\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# استخراج الروابط كـ list داخل عمود جديد\n",
    "df[\"links\"] = df[\"brave_source\"].apply(extract_links_as_list)\n",
    "\n",
    "# نخزن الملف الجديد\n",
    "output_file = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_clean.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"تم حفظ الملف:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a4d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم حفظ الملف: C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_with_script.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "def check_need_script(row):\n",
    "    # إذا الإجابة (brave_sinp) موجودة داخل ground_truth\n",
    "    if pd.notna(row[\"brave_sinp\"]) and pd.notna(row[\"ground_truth\"]):\n",
    "        if str(row[\"brave_sinp\"]).strip() in str(row[\"ground_truth\"]):\n",
    "            return \"No\"\n",
    "    return \"Yes\"\n",
    "\n",
    "# إضافة العمود الجديد\n",
    "df[\"need_script\"] = df.apply(check_need_script, axis=1)\n",
    "\n",
    "# حفظ الملف مع الاحتفاظ بـ url\n",
    "output_file = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_with_script.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"تم حفظ الملف:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0e7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "الأعمدة الموجودة فعلياً في الملف:\n",
      "['e', 'answer_brave', 'ground_truth', 'brave_source', 'brave_sinp', 'subject', 'verdict', 'error_type', 'explanation', 'reasoning', 'pass_bool', 'url', 'links']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(\"الأعمدة الموجودة فعلياً في الملف:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7072d4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          brave_sinp  \\\n",
      "0  [{'doc_id': 0, 'source': 'TikTok - Wikipedia -...   \n",
      "1  [{'doc_id': 0, 'source': 'Global retail e-comm...   \n",
      "2  [{'doc_id': 0, 'source': '6 Best E-commerce Pl...   \n",
      "3  [{'doc_id': 0, 'source': 'The State of AI in E...   \n",
      "4  [{'doc_id': 0, 'source': 'Council Post: 4 Big ...   \n",
      "5  [{'doc_id': 0, 'source': 'Council Post: From A...   \n",
      "6  [{'doc_id': 0, 'source': 'MENA E-commerce Mark...   \n",
      "7  [{'doc_id': 0, 'source': 'RetailMeNot Launches...   \n",
      "8  [{'doc_id': 0, 'source': 'History of compiler ...   \n",
      "9  [{'doc_id': 0, 'source': 'E-commerce Market Si...   \n",
      "\n",
      "                                        ground_truth need_script  \n",
      "0  TikTok launched its US shopping platform in Se...         Yes  \n",
      "1  Global online retail sales are expected to exc...         Yes  \n",
      "2  The article '6 Best E-commerce Platforms of 20...         Yes  \n",
      "3  Sustainability accounted for 8.8% of the total...         Yes  \n",
      "4  70% of online shoppers say that product conten...         Yes  \n",
      "5  The article 'From AI To AR: The Bold Innovatio...         Yes  \n",
      "6  The estimated market value of the MENA e-comme...         Yes  \n",
      "7  RetailMeNot launched the '5 to Buy' event in S...         Yes  \n",
      "8  Grace Hopper developed the first compiler in 1...         Yes  \n",
      "9  The global e-commerce market size in 2025 was ...         Yes  \n",
      "تم حفظ الملف: C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_with_script.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "def check_need_script(row):\n",
    "    sinp = str(row[\"brave_sinp\"]).strip().lower() if pd.notna(row[\"brave_sinp\"]) else \"\"\n",
    "    gt = str(row[\"ground_truth\"]).strip().lower() if pd.notna(row[\"ground_truth\"]) else \"\"\n",
    "\n",
    "    if sinp and gt and sinp in gt:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# إضافة العمود الجديد\n",
    "df[\"need_script\"] = df.apply(check_need_script, axis=1)\n",
    "\n",
    "# للتأكد نعرض بعض الصفوف\n",
    "print(df[[\"brave_sinp\", \"ground_truth\", \"need_script\"]].head(10))\n",
    "\n",
    "# حفظ الملف\n",
    "output_file = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_with_script.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"تم حفظ الملف:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم إنشاء العمود وحفظ الملف: C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_with_script.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# نعيد قراءة الملف (أو نكمل على df الموجود عندك)\n",
    "file_brave = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\"\n",
    "df = pd.read_excel(file_brave)\n",
    "\n",
    "# دالة للتحقق\n",
    "def check_need_script(row):\n",
    "    brave_sinp = str(row[\"brave_sinp\"]).lower()\n",
    "    ground_truth = str(row[\"ground_truth\"]).lower()\n",
    "    \n",
    "    if brave_sinp.strip() == \"\" or brave_sinp == \"nan\":\n",
    "        return \"Yes\"   # إذا ما فيه إجابة أصلاً\n",
    "    elif brave_sinp in ground_truth:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# إنشاء العمود الجديد\n",
    "df[\"need_script\"] = df.apply(check_need_script, axis=1)\n",
    "\n",
    "# حفظ الملف الجديد\n",
    "output_file = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_with_script.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"تم إنشاء العمود وحفظ الملف:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad080db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم إنشاء العمود وحفظ الملف: C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_with_script.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_brave = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\"\n",
    "df = pd.read_excel(file_brave)\n",
    "\n",
    "# إنشاء العمود مباشرة باستخدام apply\n",
    "df[\"need_script\"] = df.apply(\n",
    "    lambda row: \"No\" if str(row[\"brave_sinp\"]).lower() in str(row[\"ground_truth\"]).lower() and str(row[\"brave_sinp\"]).strip() not in [\"\", \"nan\"]\n",
    "    else \"Yes\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# حفظ الملف الجديد\n",
    "output_file = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_with_script.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"تم إنشاء العمود وحفظ الملف:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd17e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          brave_sinp  \\\n",
      "0  [{'doc_id': 0, 'source': 'TikTok - Wikipedia -...   \n",
      "1  [{'doc_id': 0, 'source': 'Global retail e-comm...   \n",
      "2  [{'doc_id': 0, 'source': '6 Best E-commerce Pl...   \n",
      "3  [{'doc_id': 0, 'source': 'The State of AI in E...   \n",
      "4  [{'doc_id': 0, 'source': 'Council Post: 4 Big ...   \n",
      "\n",
      "                                        ground_truth  \n",
      "0  TikTok launched its US shopping platform in Se...  \n",
      "1  Global online retail sales are expected to exc...  \n",
      "2  The article '6 Best E-commerce Platforms of 20...  \n",
      "3  Sustainability accounted for 8.8% of the total...  \n",
      "4  70% of online shoppers say that product conten...  \n",
      "Row 0 => brave_sinp: [{'doc_id': 0, 'source': 'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok', 'text': 'In October 2020, the e-commerce platform Shopify added TikTok to its portfolio of social media platforms, allowing online merchants to sell their products directly to consumers on TikTok. Some small businesses have used TikTok to advertise and to reach an audience wider than the geographical region they would normally serve.'}, {'doc_id': 0, 'source': 'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok', 'text': 'In September 2021, TikTok reported that it had reached 1 billion users. In 2021, TikTok earned $4 billion in advertising revenue. In October 2022, TikTok was reported to be planning an expansion into the e-commerce market in the US, following the launch of TikTok Shop in the United Kingdom.'}, {'doc_id': 0, 'source': 'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok', 'text': \"TikTok, known in mainland China and Hong Kong as Douyin (Chinese: 抖音; pinyin: Dǒuyīn; lit. 'Shaking Sound'), is a social media and short-form online video platform owned by Chinese Internet company ByteDance. It hosts user-submitted videos, which may range in duration from three seconds to 60 minutes. It can be accessed through a mobile app or through its website. Since its launch, TikTok has become one of the world's most popular social media platforms, using recommendation algorithms to connect content creators and influencers with new audiences.\"}, {'doc_id': 0, 'source': 'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok', 'text': 'TikTok says that since 2020, its US-based CEO is responsible for making important decisions, and has downplayed its China connection. Douyin was launched on September 20, 2016, by ByteDance, originally under the name A.me, before rebranding to Douyin (抖音) in December 2016. Douyin was developed in 200 days and within a year had 100 million users, with more than one billion videos viewed every day. While TikTok and Douyin share a similar user interface, the platforms operate separately.'}, {'doc_id': 0, 'source': 'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok', 'text': 'ByteDance said its early guidelines were global and aimed at reducing online harassment and divisiveness when its platforms were still growing. They have been replaced by versions customized by local teams for users in different regions. A March 2021 study by the Citizen Lab found that TikTok did not censor searches politically but was inconclusive about whether posts are.'}, {'doc_id': 1, 'source': 'Introducing TikTok Shop - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/introducing-tiktok-shop', 'text': \"US users' payment information is managed by USDS and we work with third party payment platforms to facilitate transactions on TikTok Shop. In addition, all product listings must adhere to TikTok Shop policies and Community Guidelines. We use a combination of technology and manual moderation to enforce our policies and will remove merchants and products we find break our rules. There's no finish line when it comes to protecting our community, and we'll continually strengthen our policies, processes, and features.\"}, {'doc_id': 1, 'source': 'Introducing TikTok Shop - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/introducing-tiktok-shop', 'text': 'Secure Checkout: TikTok works with trusted third party payment platforms to facilitate transactions on TikTok Shop, to ensure a quick, smooth, and secure checkout process. All TikTok protected US user data is stored in the US and managed by USDS.'}, {'doc_id': 1, 'source': 'Introducing TikTok Shop - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/introducing-tiktok-shop', 'text': \"Across the US, over 150 million people turn to TikTok to be entertained and inspired by content they find from their favorite creators -- including the latest trends, fashion and beauty tips, recipes, and more. Today, we're excited to announce a new way for people to now find and shop for their favorite products with the full launch of TikTok Shop in the US.\"}, {'doc_id': 1, 'source': 'Introducing TikTok Shop - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/introducing-tiktok-shop', 'text': 'Shopify merchants can manage their TikTok Shop directly from Shopify through the TikTok for Shopify App. TikTok also offers direct integrations and connectors with WooCommerce, Salesforce Commerce Cloud, BigCommerce, Magento and other leading commerce platforms.'}, {'doc_id': 2, 'source': 'TikTok Shop - Wikipedia - https://en.wikipedia.org/wiki/TikTok_Shop', 'text': 'Officially launched in September 2023, the feature enables users interested in starting a business and generating income to upload their curated products on TikTok for others to discover and purchase. Daily sales averaged approximately US$7 million in October 2023. In October 2019, TikTok announced its partnership with Shopify for a feature called TikTok: For Business. In November 2022, ByteDance commenced beta testing of the platform in the United Kingdom and several Southeast Asian countries.'}, {'doc_id': 2, 'source': 'TikTok Shop - Wikipedia - https://en.wikipedia.org/wiki/TikTok_Shop', 'text': 'In December 2022, Amazon announced the release of Amazon Inspire, a platform resembling TikTok Shop, in a bid to compete with TikTok itself. In September 2023, ByteDance announced the launch of TikTok Shop globally, which was notably influenced by the launch of Amazon Inspire.'}, {'doc_id': 2, 'source': 'TikTok Shop - Wikipedia - https://en.wikipedia.org/wiki/TikTok_Shop', 'text': 'TikTok Shop is an e-commerce feature of the video hosting service TikTok. Officially launched in September 2023, the feature enables users interested in starting a business and generating income to upload their curated products on TikTok for others to discover and purchase.'}, {'doc_id': 3, 'source': 'TikTok officially debuts shopping platform, TikTok Shop, to U.S. consumers - CBS News - https://www.cbsnews.com/news/tiktok-shop-e-commerce-us-debut/', 'text': 'TikTok Shop is on track to lose more than $500 million in the U.S. this year, according to an August report from The Information. Still, TikTok has a massive user base to which to sell. The app has skyrocketed in popularity in the U.S., amassing more than 150 million American users, the company said in a statement earlier this year. It has also become the second-most popular app among teens after YouTube, a Pew Research study from 2022 shows.'}, {'doc_id': 3, 'source': 'TikTok officially debuts shopping platform, TikTok Shop, to U.S. consumers - CBS News - https://www.cbsnews.com/news/tiktok-shop-e-commerce-us-debut/', 'text': 'TikTok is officially rolling out its TikTok Shop marketplace and services to U.S. users this week.'}, {'doc_id': 3, 'source': 'TikTok officially debuts shopping platform, TikTok Shop, to U.S. consumers - CBS News - https://www.cbsnews.com/news/tiktok-shop-e-commerce-us-debut/', 'text': 'About 40% of users currently have the Shop tab available in the app, the company said. TikTok creator Heather DiRocco talks lawsuit over Montana ban 06:54 · To be sure, the fledgling platform faces a number of challenges in the U.S., not least of which being that lawmakers here see the Chinese-owned social network as a national security risk and favor banning the app.'}, {'doc_id': 3, 'source': 'TikTok officially debuts shopping platform, TikTok Shop, to U.S. consumers - CBS News - https://www.cbsnews.com/news/tiktok-shop-e-commerce-us-debut/', 'text': 'In Indonesia alone, TikTok has more than 100 million active users, who spend more than 100 minutes on the app a day, on average, according to Bloomberg.  · The shopping platform strives to reach $20 billion in merchandise sales this year, more than quadruple that from last year, Bloomberg reported.'}, {'doc_id': 4, 'source': 'TikTok launches online shopping in the US | Reuters - https://www.reuters.com/technology/tiktok-launches-online-shopping-us-2023-09-12/', 'text': 'New features include a shop tab, where businesses can display their products with logistics and payments solutions powered by TikTok. The social media firm said it also integrated its shopping service with various third-party platforms like Shopify (SHOP.TO), opens new tab, Salesforce (CRM.N), opens new tab, and Zendesk, among others.'}, {'doc_id': 4, 'source': 'TikTok launches online shopping in the US | Reuters - https://www.reuters.com/technology/tiktok-launches-online-shopping-us-2023-09-12/', 'text': \"TikTok is bringing online shopping through a series of features on its main app and is hoping to replicate the success of Asian platforms Shein and PDD Holdings' (PDD.O), opens new tab Temu.\"}, {'doc_id': 4, 'source': 'TikTok launches online shopping in the US | Reuters - https://www.reuters.com/technology/tiktok-launches-online-shopping-us-2023-09-12/', 'text': 'U.S. flag and TikTok logo are seen in this illustration taken, June 2, 2023.'}, {'doc_id': 5, 'source': 'TikTok Shop is where shoppers come to discover - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/tiktok-shop-is-where-shoppers-come-to-discover', 'text': 'Eligible customers can use Venmo at checkout to redeem an additional discount. TikTok Shop will launch a LIVE Price Match Guaranteed program for the first time, offering customers watching select Deals for You Days livestreams cash back on the difference (subject to terms and conditions) if they find a lower price off-platform on featured products.'}, {'doc_id': 5, 'source': 'TikTok Shop is where shoppers come to discover - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/tiktok-shop-is-where-shoppers-come-to-discover', 'text': 'TikTok Shop has been on a journey since launching in the US in September 2023 to bring joy and inspiration to the shopping experience. Online shopping revolutionized fast and convenient shopping, but over time, this excitement of this experience lost its spark.'}, {'doc_id': 5, 'source': 'TikTok Shop is where shoppers come to discover - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/tiktok-shop-is-where-shoppers-come-to-discover', 'text': \"Based on what we observed in 2024, brands and creators hosted over 8 million hours of LIVE shopping sessions in the US. This is significant, especially when GlobalData's survey shows that 76% of consumers who engaged with TikTok Shop bought something from a livestream in the past year. With TikTok Shop, large brands and small businesses have a platform to be the storytellers of their brand and products, and shoppers are finding brands and products they didn’t even know they were looking for.\"}, {'doc_id': 5, 'source': 'TikTok Shop is where shoppers come to discover - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/tiktok-shop-is-where-shoppers-come-to-discover', 'text': 'In May, we issued our 2025 safety and IPR reports, sharing our progress in protecting the platform. To date, TikTok Shop has invested nearly $1 billion in tools, technologies, and people in order to protect customers, sellers, brands, and our marketplace from counterfeit activities, fraudulent behavior, and other instances of abuse. People don’t come to TikTok Shop just to buy—they come to explore and discover. It might be a creator styling an everyday outfit, a small business owner sharing the story behind their product, or a LIVE session that feels like shopping with a friend.'}, {'doc_id': 6, 'source': 'TikTok Shop launches in the U.S. as the company bets big on e-commerce | AP News - https://apnews.com/article/tiktok-online-shopping-65470c109c80408f05875d8678fe5072', 'text': 'The e-commerce platform is being launched as TikTok continues to negotiate with the U.S. government over its future in the country. Critics have levied accusations that the social media giant could be a tool for China’s government to surveil Americans. The company said TikTok shop will offer a secure checkout process and that all of its U.S. user data is stored and managed by servers maintained by the software giant Oracle.'}, {'doc_id': 6, 'source': 'TikTok Shop launches in the U.S. as the company bets big on e-commerce | AP News - https://apnews.com/article/tiktok-online-shopping-65470c109c80408f05875d8678fe5072', 'text': 'After months of testing, TikTok is fully launching its e-commerce product in the U.S., in an effort to translate the app’s cultural relevance among young consumers to sales. The company said Tuesday, Sept. 12, 2023 its shopping wing, called TikTok Shop, will include several features such as a “Shop Tab,” a marketplace its been testing on the app since August.'}, {'doc_id': 6, 'source': 'TikTok Shop launches in the U.S. as the company bets big on e-commerce | AP News - https://apnews.com/article/tiktok-online-shopping-65470c109c80408f05875d8678fe5072', 'text': 'The company said Tuesday its shopping wing, called TikTok Shop, will include several features such as a “Shop Tab,” a marketplace its been testing on the app since August; affiliate videos in user’s feed that allows creators to earn commissions from products; as well as a logistics arm called Fulfilled by TikTok that stores and ships products for merchants.'}, {'doc_id': 6, 'source': 'TikTok Shop launches in the U.S. as the company bets big on e-commerce | AP News - https://apnews.com/article/tiktok-online-shopping-65470c109c80408f05875d8678fe5072', 'text': 'The Shop Tab, where products from TikTok’s marketplace are listed, is now available for 40% of users on the app’s home screen. The feature will be rolled out gradually until its available for the app’s 150 million U.S.'}, {'doc_id': 7, 'source': 'TikTok Shop officially launches in the US | TechCrunch - https://techcrunch.com/2023/09/12/tiktok-shop-officially-launches-in-the-u-s/', 'text': 'TikTok Shop also has a dedicated tab, which it rolled out to other markets in June, to let users search for different products, discover products through recommendations, browse items in different categories and manage their orders. TikTok also has set up an affiliate funnel for sellers that lets them work with creators on a commission basis to sell products. Apart from letting brands host their products on the platform, ByteDance also provides logistics solutions under “Fulfilled by TikTok,” along with a secure checkout method.'}, {'doc_id': 7, 'source': 'TikTok Shop officially launches in the US | TechCrunch - https://techcrunch.com/2023/09/12/tiktok-shop-officially-launches-in-the-u-s/', 'text': 'After months of testing, TikTok has finally launched its e-commerce product, TikTok Shop, in the U.S. — where it has more than 150 million users.'}, {'doc_id': 7, 'source': 'TikTok Shop officially launches in the US | TechCrunch - https://techcrunch.com/2023/09/12/tiktok-shop-officially-launches-in-the-u-s/', 'text': 'TikTok has been testing its e-commerce initiative in the U.S. since last November. Over the course of the last few months, the company has added more vendors to the test. ByteDance has been experimenting with different formats of shopping in various markets, such as the U.K.'}, {'doc_id': 7, 'source': 'TikTok Shop officially launches in the US | TechCrunch - https://techcrunch.com/2023/09/12/tiktok-shop-officially-launches-in-the-u-s/', 'text': 'TikTok told TechCrunch that the company has already signed up more than 200,000 sellers on the Shop product. Additionally, more than 100,000 creators have signed up for the Affiliate program. Earlier this week, Bloomberg reported that many U.S. users have been seeing the shop button on their app. However, it was just a showcase for cheap or counterfeit products from China.'}, {'doc_id': 8, 'source': 'TikTok Launches eCommerce Platform, TikTok Shop in the US - Blue Wheel - https://www.bluewheelmedia.com/blog/tiktok-launches-tiktok-shop', 'text': 'Social media giant, TikTok, has announced the official launch of its US ecommerce platform, TikTok Shop, now appearing in users’ For You feeds.'}, {'doc_id': 8, 'source': 'TikTok Launches eCommerce Platform, TikTok Shop in the US - Blue Wheel - https://www.bluewheelmedia.com/blog/tiktok-launches-tiktok-shop', 'text': 'In a recent study, it was found that 75% of US marketers plan to increase their spend on TikTok over the next 12 months – and for good reason with the recent launch of TikTok Shop. As a one-stop eCommerce solution, it allows users to discover products, checkout, and make a purchase all within the TikTok App making the customer experience nearly seamless.'}, {'doc_id': 8, 'source': 'TikTok Launches eCommerce Platform, TikTok Shop in the US - Blue Wheel - https://www.bluewheelmedia.com/blog/tiktok-launches-tiktok-shop', 'text': 'Along with a relatively seamless customer experience, TikTok Shop has added several new features in addition to its in-feed videos and live shopping streams. A Product Showcase allows users to browse product tiles, read reviews, and make purchases directly from a brand’s profile page and brands can curate their products into collections directly on their profiles. The Shop Tab is a dedicated shopping option where customers can easily search and discover products with current and ongoing promotions.'}, {'doc_id': 8, 'source': 'TikTok Launches eCommerce Platform, TikTok Shop in the US - Blue Wheel - https://www.bluewheelmedia.com/blog/tiktok-launches-tiktok-shop', 'text': 'Your margins will likely be lower on TikTok Shop due to the 5% commission TikTok takes off every purchase, but acquiring a new customer allows you to enact other parts of your omni-channel strategy, like email marketing and abandoned cart ads, to increase their lifetime value.'}, {'doc_id': 9, 'source': 'TikTok’s online marketplace for the US could launch in August | The Verge - https://www.theverge.com/2023/7/25/23806781/tiktok-ecommerce-store-august-launch-date', 'text': 'TikTok is getting ready to launch its online marketplace in the US, according to a report from The Wall Street Journal. As part of its launch, TikTok will reportedly store and ship products on behalf of retailers based in China.'}, {'doc_id': 9, 'source': 'TikTok’s online marketplace for the US could launch in August | The Verge - https://www.theverge.com/2023/7/25/23806781/tiktok-ecommerce-store-august-launch-date', 'text': 'TikTok’s online marketplace has been rumored to be in the works for a while now, with a June report from Semafor suggesting that the video platform will integrate its online marketplace into the app under an e-commerce tab. TikTok has already rolled out a shopping tab and live shopping features in countries outside the US.'}, {'doc_id': 9, 'source': 'TikTok’s online marketplace for the US could launch in August | The Verge - https://www.theverge.com/2023/7/25/23806781/tiktok-ecommerce-store-august-launch-date', 'text': 'TikTok is planning to launch its e-commerce business in the US early next month, according to a report from The Wall Street Journal. Similar to the “Sold by Amazon” program, TikTok’s online marketplace will store and ship a variety of products from sellers based in China, including clothes, kitchen gadgets, and electronics. The “TikTok Shop Shopping Center” described contains different channels where users can browse through and buy products.'}, {'doc_id': 9, 'source': 'TikTok’s online marketplace for the US could launch in August | The Verge - https://www.theverge.com/2023/7/25/23806781/tiktok-ecommerce-store-august-launch-date', 'text': 'According to the WSJ, TikTok will only pay Chinese suppliers once they find buyers in the US and will return unpopular items “to avoid being stuck with inventory.” The company reportedly plans to open up its program to merchants outside of China as it works to create an “international settlement and logistics system.” · Why influencers love a free trip — even a controversial one from Shein ... While Semafor initially reported that the marketplace could launch in the US this month, the WSJ says TikTok delayed the launch.'}] | ground_truth: TikTok launched its US shopping platform in September 2023. | موجودة؟ False\n",
      "Row 1 => brave_sinp: [{'doc_id': 0, 'source': 'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/', 'text': 'In 2024, global retail e-commerce sales reached an estimated ************ U.S. dollars. Projections indicate a ** percent growth in this figure over the coming years, with expectations to come close to ************** dollars by 2028.'}, {'doc_id': 0, 'source': 'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/', 'text': 'ACSI - U.S. customer satisfaction with online retail as of 2025'}, {'doc_id': 0, 'source': 'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/', 'text': 'Premium Statistic U.S. consumer shipping companies - customer experience 2017-2025'}, {'doc_id': 0, 'source': 'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/', 'text': 'Retail e-commerce sales worldwide from 2022 to 2028 (in billion U.S. dollars) [Graph], eMarketer, April 8, 2025.'}, {'doc_id': 1, 'source': 'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics', 'text': 'Products or services are sold into non-native markets via online sales and marketing. ... Worldwide, it is anticipated that B2B ecommerce will reach $36 trillion by 2026. And B2C ecommerce will reach $5.5 trillion by 2027.  · The global ecommerce market is expected to total $4.8 trillion in 2025. That figure is estimated to grow over the next few years, showing that borderless ecommerce is becoming a profitable option for online retailers.'}, {'doc_id': 1, 'source': 'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics', 'text': 'However, as an extension of social commerce, live shopping has started to become more popular as the strategy has soared in China. The live commerce market in China was $562 billion in 2023 and is expected to increase to $843 billion in 2025. It made up 19.2% of the retail ecommerce sales in 2023.'}, {'doc_id': 1, 'source': 'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics', 'text': 'While this impact is global, European retailers expect higher revenue growth, with a larger proportion anticipating a 5% to 9% increase. As ecommerce matures, Deloitte found retailers are focusing on making online sales more profitable rather than just expanding market share.'}, {'doc_id': 1, 'source': 'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics', 'text': 'The rise of mobile commerce (m-commerce) is significant, with some forecasting it to reach $558 billion in 2024, accounting for 7.6% of total retail sales.  · In 2023, nearly 80% of global consumers used their smartphone to access a retailer’s website while shopping in-store. Another 74% used a retailer’s app while shopping, according to Insider Intelligence.'}, {'doc_id': 2, 'source': '51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/', 'text': 'In China, a staggering 92% of respondents use their phones for online shopping, while in India, the figure stands at 88%. mCommerce sales will account for $2.51 trillion in 2025, that would be a 21.25% increase from the previous year when the recorded sales were $2.07 trillion. The growth of mobile commerce is expected to be larger than the average annual growth rate of 15.3% forecast from 2018 to 2027.'}, {'doc_id': 2, 'source': '51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/', 'text': 'In 2025, 21% of retail purchases are expected to take place online, and this share will rise to 22.6% by 2027. Ecommerce sales will surpass $6.8 trillion in 2025.'}, {'doc_id': 2, 'source': '51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/', 'text': 'It is further expected that 22.6% of all retail purchases will be made online by 2027. The share of online retail purchases is rising at an average of 0.32% every year since 2021. This is a sign to invest more in the online presence of your business and stay relevant in the current retail scene. Here is a table showing the share of online retail transactions over the years: Source: Statista. Global eCommerce sales will account for $6.86 trillion in 2025, which is an 8.37% increase from 2024.'}, {'doc_id': 2, 'source': '51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/', 'text': 'The sales will continue growing at a CAGR of 7.8% between 2025 to 2027 and reach $8 trillion by 2027. Growing at more than 2x rate compared to physical stores. This shows that eCommerce is becoming a more profitable choice for companies worldwide. Here is a table showing the growth in retail eCommerce sales globally over the years:'}, {'doc_id': 3, 'source': 'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/', 'text': 'Online shopping has grown steadily in popularity in recent years. In 2021, global online retail sales amounted to almost five trillion U.S. dollars, a figure expected to exceed seven trillion U.S. dollars by 2025. Digital development in Latin America boomed during the COVID-19 pandemic, generating unprecedented e-commerce growth in various economies across the region.'}, {'doc_id': 3, 'source': 'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/', 'text': 'eMarketer, E-commerce as percentage of total retail sales worldwide from 2021 to 2027 Statista, https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/ (last visited January 05, 2025)'}, {'doc_id': 3, 'source': 'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/', 'text': 'E-commerce share of retail sales in Singapore 2015-2025'}, {'doc_id': 3, 'source': 'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/', 'text': 'eMarketer. \"E-commerce as percentage of total retail sales worldwide from 2021 to 2027.\" Chart. February 27, 2024. Statista. Accessed January 05, 2025.'}, {'doc_id': 4, 'source': 'Global Online Retail Statistics and Trends For 2025 - Invesp - https://www.invespcro.com/blog/online-retail-statistics-and-trends/', 'text': 'Global retail eCommerce sales are forecast to reach $7.4 trillion in 2025, according to eMarketer. This will account for nearly 24% of all global retail spending, showing how online shopping is becoming a dominant force in the retail landscape. The projected value of the global eCommerce market in 2025 is $7.4 trillion, driven by increased internet access, mobile commerce, and AI-powered shopping experiences across both emerging and mature markets. By 2025, the number of digital buyers worldwide is expected to surpass 2.77 billion, representing over 33% of the global population.'}, {'doc_id': 4, 'source': 'Global Online Retail Statistics and Trends For 2025 - Invesp - https://www.invespcro.com/blog/online-retail-statistics-and-trends/', 'text': 'The United States, just a little behind, contributes significantly to global e-commerce spending. Together, these two countries accounted for more than $4.1 trillion in e-commerce sales. ... These massive figures highlight China’s and the US’s dominance of the global online retail sector and their role in shaping global e-commerce trends.'}, {'doc_id': 4, 'source': 'Global Online Retail Statistics and Trends For 2025 - Invesp - https://www.invespcro.com/blog/online-retail-statistics-and-trends/', 'text': 'The next few years are expected to bring new technologies, improved customer experiences, and fresh growth opportunities—all pointing to one thing: ecommerce isn’t slowing down anywhere. In 2022, the global retail market generated sales of over 27 trillion U.S.'}, {'doc_id': 4, 'source': 'Global Online Retail Statistics and Trends For 2025 - Invesp - https://www.invespcro.com/blog/online-retail-statistics-and-trends/', 'text': 'With e-commerce sales hitting record highs and new shopping trends popping up everywhere, it takes time to keep up. But don’t worry—we’ve got you covered. In this article, we’re diving deep into the “Global Online Retail Statistics and Trends For 2025.” We’ll explore everything from the growth of ecommerce to the rise of mobile commerce and the impact of AI on shopping experiences.'}, {'doc_id': 6, 'source': 'Global e-commerce overview: 2025 insights - https://ecommercegermany.com/blog/global-e-commerce', 'text': 'The category split in 2025 shows what people care about: ... But the revenue also shows what’s becoming essential in the digital shelf. Let’s start with the top earners. According to the ECDB report, the #1 revenue category globally is: 01 fashion, $1.251 trillion in online sales in 2024'}, {'doc_id': 6, 'source': 'Global e-commerce overview: 2025 insights - https://ecommercegermany.com/blog/global-e-commerce', 'text': 'Global e-commerce is no longer some kind of trend. It’s infrastructure. And it’s growing in new directions that matter for every retailer, manufacturer, or brand selling online. We looked into SellersCommerce and the ECDB Global eCommerce 2025 whitepaper to bring you this overview.'}, {'doc_id': 6, 'source': 'Global e-commerce overview: 2025 insights - https://ecommercegermany.com/blog/global-e-commerce', 'text': 'You need to know where it’s happening, how fast it’s shifting, and what your buyers expect from the experience. It’s not evenly spread — and that’s the whole point. It’s more regional, strategic, and often surprising. Let’s start with the raw numbers. According to ECDB, the fastest-growing continent between 2024 and 2028 is Africa, with a projected +52.6% growth.'}, {'doc_id': 6, 'source': 'Global e-commerce overview: 2025 insights - https://ecommercegermany.com/blog/global-e-commerce', 'text': 'According to SellersCommerce, global e-commerce will surpass $6.86 trillion in 2025. That’s up 8.37% from 2024, and part of a steady climb that will take the market to nearly $8 trillion by 2027. The ECDB report takes a narrower scope — just B2C physical goods (excluding services, B2B, C2C, returns, compensation for damaged or missing goods, any discounts granted, and digital products).'}, {'doc_id': 7, 'source': 'Global Ecommerce Sales Growth (2022–2028) [Updated Oct 2024] - https://www.oberlo.com/statistics/global-ecommerce-sales-growth', 'text': 'The growth rate of ecommerce consistently outpaces that of total retail sales, indicating a continued shift in consumer preference toward online shopping over traditional retail channels. The global ecommerce growth rate for 2024 is forecast at 8.4%, bringing global ecommerce sales worldwide to $6.09 trillion. According to experts’ forecasts, global ecommerce sales growth is set to continue, albeit at a slightly slower pace. Ecommerce’s growth rate worldwide is expected to decelerate to 7.8% in 2025, which will bring total ecommerce sales to $6.56 trillion.'}, {'doc_id': 7, 'source': 'Global Ecommerce Sales Growth (2022–2028) [Updated Oct 2024] - https://www.oberlo.com/statistics/global-ecommerce-sales-growth', 'text': 'In 2024, total retail sales worldwide are expected to rise to $31.1 trillion, marking an increase of 4.9% from 2023. This is 3.5 percentage points lower than the global rate.'}, {'doc_id': 7, 'source': 'Global Ecommerce Sales Growth (2022–2028) [Updated Oct 2024] - https://www.oberlo.com/statistics/global-ecommerce-sales-growth', 'text': 'In subsequent years, the gap between ecommerce and retail growth rates is projected to remain, with ecommerce consistently outpacing traditional retail growth, which is expected to slow to 3.6% by 2027.'}, {'doc_id': 7, 'source': 'Global Ecommerce Sales Growth (2022–2028) [Updated Oct 2024] - https://www.oberlo.com/statistics/global-ecommerce-sales-growth', 'text': 'In the Philippines, the country with the second-biggest online retail growth, this is set to increase by 24.1%. Malaysia and Argentina rank next, with annual growth rates of around 17.5% each. Brazil rounds out the five countries with the largest online retail growth rates, with 15.4%.'}, {'doc_id': 8, 'source': 'Global Ecommerce Sales Growth Report [Updated Oct 2024] - Shopify - https://www.shopify.com/blog/global-ecommerce-sales', 'text': 'Online sales are expected to continue rising and take a larger piece of the retail pie. In 2025, global ecommerce sales are forecast to rise to $6.56 trillion, before adding another $500 billion in 2026, to $7.06 trillion. In 2027, growth is anticipated to slow slightly to 7.2%, to take online sales revenues to $7.57 trillion.'}, {'doc_id': 8, 'source': 'Global Ecommerce Sales Growth Report [Updated Oct 2024] - Shopify - https://www.shopify.com/blog/global-ecommerce-sales', 'text': 'popular postsSell OnlineHow To Create a Website in 9 Steps (2025)Starting UpHow To Start an Online Store in 2025 (Step-by-Step Guide)Find an IdeaHow To Make and Sell Merch Your Fans Will Love (2025)Sell Online10 Best Ecommerce Website Builders for Your Online Store (2025)'}, {'doc_id': 8, 'source': 'Global Ecommerce Sales Growth Report [Updated Oct 2024] - Shopify - https://www.shopify.com/blog/global-ecommerce-sales', 'text': 'popular postsSocial Media OptimizationHow To Make Money on Instagram in 2025 (9 Actionable Ideas)Starting UpHow To Start an Ecommerce Business: Guide for 2025GuidesWhat Is Dropshipping and How Does It Work?'}, {'doc_id': 8, 'source': 'Global Ecommerce Sales Growth Report [Updated Oct 2024] - Shopify - https://www.shopify.com/blog/global-ecommerce-sales', 'text': '(2025)Find an IdeaWhat Is Print on Demand & How To Start a Business (2025)'}, {'doc_id': 9, 'source': 'Global eCommerce Sales Growth From 2021-2027 - https://www.yaguara.co/global-ecommerce-sales-growth/', 'text': 'Global eCommerce sales are estimated to reach $6.9 trillion by the end of 2025 and are projected to hit $8.09 trillion by 2028. With eCommerce now accounting for 21.2% of total retail sales, digital commerce has become the backbone of global retail.  · In this article, I have covered the latest facts and figures about the current e-commerce market, its growth, and market dynamics across B2B, B2C, and cross-border segments with the latest data.'}, {'doc_id': 9, 'source': 'Global eCommerce Sales Growth From 2021-2027 - https://www.yaguara.co/global-ecommerce-sales-growth/', 'text': 'Note: The global retail eCommerce sales growth rate is calculated according to the given data of global retail eCommerce sales.  · Source: Statista. In 2025, eCommerce sales are estimated to make up 21% of retail sales worldwide.'}, {'doc_id': 9, 'source': 'Global eCommerce Sales Growth From 2021-2027 - https://www.yaguara.co/global-ecommerce-sales-growth/', 'text': 'US retail e-commerce sales are estimated to reach $1.392 in 2025.'}, {'doc_id': 9, 'source': 'Global eCommerce Sales Growth From 2021-2027 - https://www.yaguara.co/global-ecommerce-sales-growth/', 'text': 'The market is expected to grow at a CAGR of 15% during the forecast period of 2023 and 2032. The following table displays the global eCommerce market size over the years. ... Source: Precedence Research. EcomeCommercemerce revenue is predicted to grow at a CAGR of 7.83% between 2025 and 2029.'}] | ground_truth: Global online retail sales are expected to exceed $7.4 trillion in 2025. | موجودة؟ False\n",
      "Row 2 => brave_sinp: [{'doc_id': 0, 'source': '6 Best E-commerce Platforms of 2025: My Review - https://learn.g2.com/best-ecommerce-platforms', 'text': 'To gain deeper insights, I collaborated with different e-commerce store owners, who provided valuable context on why they prefer certain platforms and how they use AI-powered tools. In cases where I couldn’t personally test a tool due to limited access, I consulted a professional with hands-on experience and validated their insights using verified G2 reviews. The screenshots featured in this article may be a mix of those captured during testing and ones obtained from the vendor’s G2 page.'}, {'doc_id': 0, 'source': '6 Best E-commerce Platforms of 2025: My Review - https://learn.g2.com/best-ecommerce-platforms', 'text': 'It was there that I developed a strong foundation in understanding what makes an e-commerce platform beneficial—fully connected functionality, scalability, and ease of use. I have always been curious about which platform would suit most businesses.'}, {'doc_id': 0, 'source': '6 Best E-commerce Platforms of 2025: My Review - https://learn.g2.com/best-ecommerce-platforms', 'text': 'In my experience, e-commerce platforms have made running an online store simple for everyone. They allow you to list products, process payments, track inventory, and manage orders—all from one place. But the best e-commerce platforms go well beyond the basics.'}, {'doc_id': 0, 'source': '6 Best E-commerce Platforms of 2025: My Review - https://learn.g2.com/best-ecommerce-platforms', 'text': 'I spent weeks testing these e-commerce platforms, exploring their unique features and whether they supported scalability - from small startups to scaling enterprises. I signed up to understand the different advantages they had when compared to their competitors.'}, {'doc_id': 1, 'source': 'Best E-Commerce Platforms of 2025 – Forbes Advisor - https://www.forbes.com/advisor/business/software/best-ecommerce-platform/', 'text': 'We analyzed and tested the best e-commerce platforms to find the best choices to power your online store and help you grow your business.'}, {'doc_id': 1, 'source': 'Best E-Commerce Platforms of 2025 – Forbes Advisor - https://www.forbes.com/advisor/business/software/best-ecommerce-platform/', 'text': 'Theme management and editing in OpenCart requires patience and fighting through a deeper learning curve than other e-commerce platforms. With direct hosting, you always know what your server resources are. It’s also a fantastic safety net for technical support outside of OpenCart. If anything goes wrong with hosting, you have your host’s included tech support, like Scala Hosting’s 24/7 live chat support with a 30-second guaranteed response time or its 15-minute response time ticketed support.'}, {'doc_id': 1, 'source': 'Best E-Commerce Platforms of 2025 – Forbes Advisor - https://www.forbes.com/advisor/business/software/best-ecommerce-platform/', 'text': 'Pricing and features are not quite as attractive as they once were, however. Ecwid used to be the starting point for many online shops due to a free forever plan, but pricing changed at the start of 2025 Q2. The previously free Starter plan is now $5 monthly but still carries the nearly draconian limits on products and features.'}, {'doc_id': 1, 'source': 'Best E-Commerce Platforms of 2025 – Forbes Advisor - https://www.forbes.com/advisor/business/software/best-ecommerce-platform/', 'text': 'As a small business owner, Liz understands the unique challenges entrepreneurs face. Well-versed in the digital landscape, she combines real-world experience in website design, building e-commerce shops, managing social media and marketing with years...'}, {'doc_id': 2, 'source': 'Best E-Commerce Platforms for 2025 | The Ad Firm - https://www.theadfirm.net/2025-update-best-e-commerce-platforms-for-2025/', 'text': 'Modern consumers demand ethical practices and eco-conscious options, compelling platforms to prioritize green commerce in their features and operations. Local SEO: Dominate your local market and attract more customers with targeted local SEO strategies. PPC: Use precise PPC management to draw high-quality traffic and boost your leads effectively. Content Marketing: Create and distribute valuable, relevant content that captivates your audience and builds authority.'}, {'doc_id': 2, 'source': 'Best E-Commerce Platforms for 2025 | The Ad Firm - https://www.theadfirm.net/2025-update-best-e-commerce-platforms-for-2025/', 'text': 'E-commerce platforms have transformed significantly in recent years, with new trends, technologies, and user expectations driving innovation. As we head into 2025, businesses must choose platforms that align with their growth strategies, ensuring scalability, usability, and optimized performance.'}, {'doc_id': 2, 'source': 'Best E-Commerce Platforms for 2025 | The Ad Firm - https://www.theadfirm.net/2025-update-best-e-commerce-platforms-for-2025/', 'text': 'E-commerce platforms in 2025 are adapting to the ever-changing demands of businesses and consumers. These trends reshape how online stores operate and compete, from cutting-edge technologies to value-driven innovations.'}, {'doc_id': 2, 'source': 'Best E-Commerce Platforms for 2025 | The Ad Firm - https://www.theadfirm.net/2025-update-best-e-commerce-platforms-for-2025/', 'text': 'Artificial intelligence (AI) is transforming e-commerce by enhancing personalization, optimizing processes, and providing actionable insights. In 2025, AI-powered features will be a luxury and a necessity for platforms aiming to deliver top-tier user experiences.'}, {'doc_id': 3, 'source': '9 Best Ecommerce Platforms of 2025 (Know Your Options) - https://www.bigcommerce.com/articles/ecommerce/ecommerce-platforms/', 'text': 'Resell ecommerce with Commerce-as-a-Service. ... This in-depth report provides actionable strategies to help you sell more online. ... Whether you’re ready for it or not, ecommerce is here to stay. If you don’t believe us, just look at the statistics: According to Statista, global retail ecommerce sales will surpass $6 billion for the first time in 2024. But the record-breaking growth doesn’t stop there. By 2025, ecommerce sales will reach over $8 billion.'}, {'doc_id': 3, 'source': '9 Best Ecommerce Platforms of 2025 (Know Your Options) - https://www.bigcommerce.com/articles/ecommerce/ecommerce-platforms/', 'text': 'Coined by Gartner in June 2020, composable commerce is a modular digital commerce solution that replaces the traditional monolithic approach. This is a composable architecture-based solution that uses APIs to individualize the different components of an ecommerce site.'}, {'doc_id': 3, 'source': '9 Best Ecommerce Platforms of 2025 (Know Your Options) - https://www.bigcommerce.com/articles/ecommerce/ecommerce-platforms/', 'text': 'Other platforms, like Salesforce Commerce Cloud, provide support but at a less robust level — as it lacks several essential support teams from its services offering.'}, {'doc_id': 3, 'source': '9 Best Ecommerce Platforms of 2025 (Know Your Options) - https://www.bigcommerce.com/articles/ecommerce/ecommerce-platforms/', 'text': 'Composable commerce offers users the freedom and flexibility to efficiently manage site components to meet their ecommerce needs.'}, {'doc_id': 4, 'source': '10 Best Ecommerce Platforms in 2025 (Reviewed, Compared, and Rated) - https://www.emailvendorselection.com/best-ecommerce-platforms-review/', 'text': 'Sellfy has a 14-day free trial and a 30-day money-back guarantee with the paid plans. You get store design migration in Business and product migration in Premium. ... Sellfy is a specialised ecommerce platform for creators selling digital products and merchandise. It also works well for physical products and if you already have a website. The user interface is very easy to navigate and creating a store is really quick. If you ever need help the help articles cover the whole platform.'}, {'doc_id': 4, 'source': '10 Best Ecommerce Platforms in 2025 (Reviewed, Compared, and Rated) - https://www.emailvendorselection.com/best-ecommerce-platforms-review/', 'text': 'Full blogging platform to publish articles, create lookbooks, get traffic with your blog.'}, {'doc_id': 4, 'source': '10 Best Ecommerce Platforms in 2025 (Reviewed, Compared, and Rated) - https://www.emailvendorselection.com/best-ecommerce-platforms-review/', 'text': 'Directories List of Email service providers Email Marketing agencies Marketing Automation Software Email list building tools Lead Generation Tools Helpful articles Email marketing definitions Gross Profit Calculator © Copyright 2009 - 2025 About us | Contact | Privacy | Methodology'}, {'doc_id': 4, 'source': '10 Best Ecommerce Platforms in 2025 (Reviewed, Compared, and Rated) - https://www.emailvendorselection.com/best-ecommerce-platforms-review/', 'text': \"CJ helps B2B SaaS and tech companies establish online authority, build trust with people, and sell more. He's the founder of The Copy Crusade, a content marketing agency for B2B companies. And has a special love for B2B MarTech, digital marketing, and ecommerce platforms.\"}, {'doc_id': 5, 'source': 'The 6 best eCommerce website building platforms in 2025 - https://zapier.com/blog/best-ecommerce-shopping-cart-software/', 'text': 'While most deals are customized and the specifics kept private, you can expect to pay at least $22,000 per year for a \"basic\" Adobe Commerce (formerly Magneto Enterprise Edition) store with less than $1 million in sales. Shopify Plus starts at $2,500 per month. As you can imagine, neither of these options is a great fit for a small bakery looking to sell a few cookies online, but for a large chain, they\\'re required. ... BigCommerce vs. Shopify: Which is best? This article was originally published in July 2019. The most recent update was in January 2025.'}, {'doc_id': 5, 'source': 'The 6 best eCommerce website building platforms in 2025 - https://zapier.com/blog/best-ecommerce-shopping-cart-software/', 'text': \"His photos have been published on hundreds of sites—mostly without his permission. ... ClickFunnels vs. Shopify: Which is best? [2025] ClickFunnels vs. Shopify: Which is best?... ... How eCommerce automation benefits your... ... Wix vs. Shopify: What's the best eCommerce platform? [2025]\"}, {'doc_id': 5, 'source': 'The 6 best eCommerce website building platforms in 2025 - https://zapier.com/blog/best-ecommerce-shopping-cart-software/', 'text': 'Monthly fee. This is anything from free to a few hundred dollars and goes straight to the platform. For most of the eCommerce services on this list, expect to pay around $30 to $40 per month for a basic plan.'}, {'doc_id': 5, 'source': 'The 6 best eCommerce website building platforms in 2025 - https://zapier.com/blog/best-ecommerce-shopping-cart-software/', 'text': 'Payment gateway fees. These are the fees you pay when you process a credit card charge. The normal fee is around 2.9% plus an additional $0.30, although this goes down with volume and higher upfront payments.'}, {'doc_id': 7, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'Social channels are crucial touchpoints for e-commerce: In fact, by 2030, social commerce revenue is expected to reach $6.2 trillion. When it comes to finding new products, interacting with brands, and authentic product recommendations that consumers trust, social shopping will be a juggernaut for online retailers in 2025.'}, {'doc_id': 7, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'For example, 33% of B2B buyers say they search for products on mobile devices and social platforms more than in the past. AI-driven personalization: From product search to creative email marketing, AI personalization is foundational to e-commerce in 2025.'}, {'doc_id': 7, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'Social shopping makes the customer journey easier and more engaging, especially for digital natives who spend a lot of time on those platforms. For businesses, it’s a shift in how they market products—focusing on creating shoppable content, live-streaming events, and leveraging influencers to reach potential customers will be key to e-commerce in 2025.'}, {'doc_id': 7, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'That may change for e-commerce in 2025, as smartphone usage, messaging apps, and AI become a normal part of the shopping journey within the e-commerce industry. Smart speakers like Amazon Alexa and Google Assistant enable users to search for products, make purchases, and track deliveries using voice commands. The actual experience, however, can feel clunky and unreliable. But with recent advances in natural language capabilities, more e-commerce platforms are optimizing for voice search, giving consumers a hands-free, convenient way to shop'}, {'doc_id': 8, 'source': '11 Best Ecommerce Platforms for Your Business in 2025 - Shopify - https://www.shopify.com/blog/best-ecommerce-platforms', 'text': 'Big Cartel offers limited customization options without coding knowledge, includes a small app marketplace with only about 30 direct integrations, and has no built-in abandoned cart recovery or built-in payment gateway (relies on third-party options like Stripe and PayPal).'}, {'doc_id': 8, 'source': '11 Best Ecommerce Platforms for Your Business in 2025 - Shopify - https://www.shopify.com/blog/best-ecommerce-platforms', 'text': 'Volusion makes it easy to integrate, with more than 30 payment gateways, and provides essential tools for creating an online store without unnecessary complications.'}, {'doc_id': 8, 'source': '11 Best Ecommerce Platforms for Your Business in 2025 - Shopify - https://www.shopify.com/blog/best-ecommerce-platforms', 'text': \"Ecommerce kids' apparel business Character.com wrestled with a complex Adobe Commerce site before migrating to Shopify. Its website contained thousands of products and tons of integrations, making content management exhausting.\"}, {'doc_id': 8, 'source': '11 Best Ecommerce Platforms for Your Business in 2025 - Shopify - https://www.shopify.com/blog/best-ecommerce-platforms', 'text': 'Adobe Commerce is designed for developers and large businesses that want a customizable online store.'}, {'doc_id': 9, 'source': '10 E-Commerce Platforms in 2025 - Sunrise Geek - https://www.sunrisegeek.com/post/10-e-commerce-platforms-in-2025', 'text': 'and to ensure incredible scalability, business owners found themselves in need of the services e-commerce platforms have to offer. \\u200dFinding an e-commerce platform that works for you and your business needs can be tricky and could take time. For this reason, to help you make that decision faster, we put together a list of e-commerce platforms we consider to be the best in 2025.'}, {'doc_id': 9, 'source': '10 E-Commerce Platforms in 2025 - Sunrise Geek - https://www.sunrisegeek.com/post/10-e-commerce-platforms-in-2025', 'text': 'Whether you want to move from another e-commerce site or you are at the beginning of your e-commerce journey, WooCommerce has got you covered. One of WooCommerce’s greatest suits is its high level of flexibility. You can customize your online store to your liking by hiring a developer WooCommerce provides you with.'}, {'doc_id': 9, 'source': '10 E-Commerce Platforms in 2025 - Sunrise Geek - https://www.sunrisegeek.com/post/10-e-commerce-platforms-in-2025', 'text': 'With Salesforce Commerce for B2C, both small and large businesses can transform their customer’s shopping experiences. For that, Salesforce provides a wide range of capabilities, from marketing to artificial intelligence for product recommendations and site searches.'}, {'doc_id': 9, 'source': '10 E-Commerce Platforms in 2025 - Sunrise Geek - https://www.sunrisegeek.com/post/10-e-commerce-platforms-in-2025', 'text': 'Salesforce also provides easy-to-use code code-free page designers so your storefront can attract more customers. Salesforce Commerce for B2C offers three plans you can choose from depending on your needs – Starter, Growth, and Plus. To find out the costs of each of these plans, you need to contact the platform.'}] | ground_truth: The article '6 Best E-commerce Platforms of 2025: My Review' was authored by Bhoomika Pawar. | موجودة؟ False\n",
      "Row 3 => brave_sinp: [{'doc_id': 0, 'source': 'The State of AI in E-Commerce: 2025 Quid Trend Report - https://www.quid.com/knowledge-hub/resource-library/blog/the-state-of-ai-in-e-commerce-2025-quid-trend-report', 'text': 'We equip retail leaders with the clarity to navigate fast-moving markets by analyzing millions of digital conversations in real time. Our technology surfaces the trends gaining traction, the sentiment shaping engagement, and the signals worth acting on before they go mainstream. From product planning to marketing strategy, Quid gives you the insight to move early and with confidence.  · Let’s talk about how we can help you reshape your e-commerce strategy.'}, {'doc_id': 0, 'source': 'The State of AI in E-Commerce: 2025 Quid Trend Report - https://www.quid.com/knowledge-hub/resource-library/blog/the-state-of-ai-in-e-commerce-2025-quid-trend-report', 'text': 'Each trend signals where brands are finding real value—and where the market is headed next.  · One of the most quietly powerful insights in the report was the role of sustainability, which accounted for 8.8% of total conversation. Although it didn’t receive the most mentions, it consistently earned high trust and positive sentiment.'}, {'doc_id': 0, 'source': 'The State of AI in E-Commerce: 2025 Quid Trend Report - https://www.quid.com/knowledge-hub/resource-library/blog/the-state-of-ai-in-e-commerce-2025-quid-trend-report', 'text': 'This blog breaks down the report’s methodology, top trends, key insights, and the sentiment drivers that help brands determine what’s working and what’s next.  · Understanding AI’s impact in retail requires more than a list of buzzwords. Our analysis focused on a year’s worth of digital conversations—from May 2024 to May 2025—across a wide mix of platforms, including global news outlets, industry blogs, social media platforms, Reddit, customer forums, and product review sites.'}, {'doc_id': 0, 'source': 'The State of AI in E-Commerce: 2025 Quid Trend Report - https://www.quid.com/knowledge-hub/resource-library/blog/the-state-of-ai-in-e-commerce-2025-quid-trend-report', 'text': 'In January, Cognizant’s AI assistant “Flo” debuted at NRF 2025, showcasing real-time customer support capabilities. That single post drove more than 7,000 engagements, offering a tangible example of how AI can enhance service delivery.  · Microsoft, NVIDIA, and PYMNTS also contributed to the rise in AI agent conversation with thought leadership content focused on service automation and personalization.  · To understand not just what’s trending, but why people care, we analyzed the drivers behind the sentiment in the AI e-commerce conversation.'}, {'doc_id': 1, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'Voice commerce: Smartphones, messaging apps, and AI are driving conversational commerce to the forefront of the industry in 2025. Augmented reality (AR): AR can ease online shopping anxiety by allowing customers to “try on” clothes or makeup, or see how furniture or paint will look in their space. Sustainability in e-commerce: Eco-friendly packaging, carbon neutral shipping, and sustainable sourcing and production will become more prevalent for commerce brands.'}, {'doc_id': 1, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'According to an IDC study, 46% of consumers believe that a retail brand’s sustainability record is an important deciding factor for whom they’ll do business with. In 2025, e-commerce companies are looking at everything from their product packaging to their manufacturing and warehousing facilities to assess their emissions baseline and identify opportunities to improve.'}, {'doc_id': 1, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'As 85% of single-use plastic packaging ends up in landfills, brands are looking to reduce their environmental impact through sustainable packaging. In 2025, the efficiency and speed of e-commerce operations will heavily rely on supply chain innovations. By integrating technologies like AI, automation, and drones, logistics processes are becoming faster, more precise, and increasingly sustainable.'}, {'doc_id': 1, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'Expect to see sustainability stories take the spotlight in around e-commerce in 2025, as more and more commerce brands adopt eco-friendly practices.'}, {'doc_id': 2, 'source': 'Ecommerce marketing trends in 2025: AI, sustainability and more - https://www.digitalcommerce360.com/2024/12/30/ecommerce-marketing-trends-going-into-2025/', 'text': '“Companies that strategically embrace AI, sustainability, and personalization will emerge as leaders in this transformative era.” · Here are some key ecommerce marketing trends going into 2025. Social commerce growth Social platforms like TikTok and Instagram will drive over 10% of ecommerce by 2025, up from 7%, thanks to improved shopping features. Voice search dominance By 2025, half of online searches will be voice-activated, pushing businesses to adopt conversational AI.'}, {'doc_id': 2, 'source': 'Ecommerce marketing trends in 2025: AI, sustainability and more - https://www.digitalcommerce360.com/2024/12/30/ecommerce-marketing-trends-going-into-2025/', 'text': 'AI shopping agents Personalized product recommendations from AI agents will boost loyalty and conversions. Automation with AI agents AI will handle routine tasks, freeing businesses to focus on growth. Sustainability focus With 70% of consumers valuing sustainable brands, aligning with these priorities will build trust. AR/VR integration Immersive AR/VR experiences will enhance online shopping as the market hits $50 billion by 2025.'}, {'doc_id': 2, 'source': 'Ecommerce marketing trends in 2025: AI, sustainability and more - https://www.digitalcommerce360.com/2024/12/30/ecommerce-marketing-trends-going-into-2025/', 'text': 'The ecommerce landscape is poised for a significant transformation in the coming year, driven by advancements in artificial intelligence (AI), a heightened focus on sustainability, and the push for hyper-personalized customer experiences. According to Udayan Bose, CEO of NetElixir and a veteran in digital marketing, these trends represent a pivotal shift for businesses aiming to stay ahead in an increasingly competitive market.'}, {'doc_id': 3, 'source': \"Jun 04, 2025: DHL's E-Commerce Trends Report 2025: AI and social media reshaping online shopping - DHL Group - https://group.dhl.com/en/media-relations/press-releases/2025/dhl-e-commerce-trends-report-2025.html\", 'text': 'This year’s study includes eight chapters, featuring six shopper types and four generational segments, all highlighting how evolving consumer expectations are reshaping the future of online retail.'}, {'doc_id': 3, 'source': \"Jun 04, 2025: DHL's E-Commerce Trends Report 2025: AI and social media reshaping online shopping - DHL Group - https://group.dhl.com/en/media-relations/press-releases/2025/dhl-e-commerce-trends-report-2025.html\", 'text': 'While the report covers everything from cross-border purchasing to shoppers\\' views on sale days like Black Friday, four findings stand out in particular: the way AI and social commerce are transforming online shopping, the essential role that delivery plays in cart conversion, and sustainability shaping loyalty. \"It\\'s important to recognize that there isn\\'t just one type of online shopper or one type of market. The reasons for cart abandonment can vary widely. Our E-Commerce Trends Report analyzes the trends and developments shaping online shopping worldwide to help our customers grow their businesses.'}, {'doc_id': 3, 'source': \"Jun 04, 2025: DHL's E-Commerce Trends Report 2025: AI and social media reshaping online shopping - DHL Group - https://group.dhl.com/en/media-relations/press-releases/2025/dhl-e-commerce-trends-report-2025.html\", 'text': 'A shift in sustainability: 1 in 3 shoppers drop out due to sustainability concerns · Social commerce takes center stage: 70% of global consumers expect to shop primarily through social media by 2030 - bypassing traditional websites entirely · AI becomes essential: 7 in 10 shoppers want AI-driven shopping tools - from virtual try-ons to voice search - to guide their decisions · Bonn - DHL eCommerce has released its E-Commerce Trends Report 2025, drawing on insights from 24,000 online shoppers across 24 key global markets.'}, {'doc_id': 3, 'source': \"Jun 04, 2025: DHL's E-Commerce Trends Report 2025: AI and social media reshaping online shopping - DHL Group - https://group.dhl.com/en/media-relations/press-releases/2025/dhl-e-commerce-trends-report-2025.html\", 'text': 'By embracing technology, prioritizing sustainability, and understanding the evolving preferences of consumers, businesses can transform challenges into opportunities. Further insights and information as well as the full report are available under the following link: dhl.com/e-commerce-report or dhl.com/reports ... The E-Commerce Trends Report 2025 surveyed 24,000 consumers from Europe, the Americas, Asia-Pacific, Africa, and the Middle East.'}, {'doc_id': 4, 'source': '8 Trends Accelerating the Future of E-commerce in 2025 | Publicis Sapient - https://www.publicissapient.com/insights/future-ecommerce-trends', 'text': 'While consumers are concerned about the negative impact of artificial intelligence, from job loss (42 percent) to misinformation (53 percent), 27 percent of those who are familiar with and have used generative AI tools are excited about its ability to generate personalized product recommendations for them, according to a Publicis Sapient survey. It’s up to e-commerce leaders to perfect their technology to draw consumers in, rather than push them away. In 2025, the potential for increased conversion rates, basket sizes and consumer engagement online through AI will outweigh the risks of getting it wrong, as long as retailers have the right digital expertise and quality assurance practices in place.'}, {'doc_id': 4, 'source': '8 Trends Accelerating the Future of E-commerce in 2025 | Publicis Sapient - https://www.publicissapient.com/insights/future-ecommerce-trends', 'text': 'What challenges and opportunities will emerge in 2025? Our experts offer industry-specific predictions and guidance for what awaits businesses in the year ahead. ... With cost-of-living increases and sustainable purchasing habits on the rise, secondhand marketplaces, rental platforms and resale are going to accelerate more than ever before. According to a survey of consumers in the United Kingdom, over four in 10 (44 percent) buy more secondhand items than they did a year ago, while a further 57 percent say their re-commerce shopping behavior has remained consistent.'}, {'doc_id': 4, 'source': '8 Trends Accelerating the Future of E-commerce in 2025 | Publicis Sapient - https://www.publicissapient.com/insights/future-ecommerce-trends', 'text': 'Despite the fast rise of generative AI technology—particularly large language models (LLMs), through tools like ChatGPT—many organizations are left wondering which use cases provide the most value for their needs, whether or not customers will engage with it on search engines and, frankly, what they need to change to avoid getting left behind. In 2025, many e-commerce websites will continue rolling out generative or conversational search tools.'}, {'doc_id': 4, 'source': '8 Trends Accelerating the Future of E-commerce in 2025 | Publicis Sapient - https://www.publicissapient.com/insights/future-ecommerce-trends', 'text': 'To craft your e-commerce strategy for 2025 and beyond, contact Guy Elliott and Sudip Mazumder below. ... Get a behind-the-scenes look at how and why we created DBT GPT, Publicis Sapient’s new conversational AI chatbot solution.'}, {'doc_id': 5, 'source': '100+ AI Statistics Shaping Business in 2025 - Vena - https://www.venasolutions.com/blog/ai-statistics', 'text': 'Here, we’ll dive into more than 100 artificial intelligence statistics and trends for 2025 that illustrate the current state of AI adoption across multiple industries and its impact on the future of business and work.'}, {'doc_id': 5, 'source': '100+ AI Statistics Shaping Business in 2025 - Vena - https://www.venasolutions.com/blog/ai-statistics', 'text': 'AI adoption is rising, but 20% of finance teams cite AI and machine learning as major skill gaps, according to Vena’s 2025 State of Strategic Finance report.53'}, {'doc_id': 5, 'source': '100+ AI Statistics Shaping Business in 2025 - Vena - https://www.venasolutions.com/blog/ai-statistics', 'text': 'It’s clear that artificial intelligence is rapidly transforming the business landscape, and 2025 promises even greater advancements—but also new challenges. Preparing your business for a future with AI will empower employees to make smarter decisions, connect better with customers and navigate ethical considerations. AI’s ability to analyze vast amounts of data to predict customer behavior, market trends and potential risks will continue to be refined.'}, {'doc_id': 5, 'source': '100+ AI Statistics Shaping Business in 2025 - Vena - https://www.venasolutions.com/blog/ai-statistics', 'text': 'Seventy-six percent of finance professionals have automated their financial reporting, but only 40% have done so for forecasting and 44% for budgeting.53 · Recent banking trends reveal that the operating profits of the U.S.'}, {'doc_id': 6, 'source': 'How Ecommerce AI is Transforming Business in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-ai/', 'text': 'Access to more business and customer data and processing power is enabling ecommerce operators to understand their customers and identify new trends better than ever. In an insight from Accenture, they write, “AI systems can explore highly complex and varied options for customer engagement very quickly, and continuously optimize their performance as more data becomes available. This means marketers can set parameters and allow the AI to optimize and learn to achieve precision.” · According to a report from Emerging Tech Brew, “Machine learning’s predictive powers shine in logistics, helping to forecast transit times, demand levels, and shipment delays.”'}, {'doc_id': 6, 'source': 'How Ecommerce AI is Transforming Business in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-ai/', 'text': 'Personalization is a top priority, according to surveyed retailers, but only 15% say they’ve fully implemented personalization across channels. Stand out from the crowd with a more personalized message and have one-to-one conversations with your customers.'}, {'doc_id': 6, 'source': 'How Ecommerce AI is Transforming Business in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-ai/', 'text': 'Resell ecommerce with Commerce-as-a-Service. ... This in-depth report provides actionable strategies to help you sell more online.'}, {'doc_id': 6, 'source': 'How Ecommerce AI is Transforming Business in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-ai/', 'text': 'Tomorrow’s AI sounds like it’s straight from the movies, but there’s plenty of AI technology today that may look less glamorous improving customer experience, increasing conversion rates, and helping to streamline the way the business is run.'}, {'doc_id': 7, 'source': 'AI Agents Statistics: Usage Insights And Market Trends (2025) | SellersCommerce - https://www.sellerscommerce.com/blog/ai-agents-statistics/', 'text': 'According to the survey, 69% of respondents use AI for data analytics, followed by data processing (57%). Other common AI use cases include natural language processing (47%) and large language models (46%). 62% of Banks in the United States agree that the complexity and risks associated with handling personal data for training AI agents often outweigh the benefits to customer experience.'}, {'doc_id': 7, 'source': 'AI Agents Statistics: Usage Insights And Market Trends (2025) | SellersCommerce - https://www.sellerscommerce.com/blog/ai-agents-statistics/', 'text': 'They can sense and interpret data, reason about it based on their goals, and make decisions that improve their performance. Depending on their design, AI agents can focus on specific tasks (like automating processes or analyzing data) or handle more complex tasks (such as engaging in conversations, solving intricate problems, or working with other agents).'}, {'doc_id': 7, 'source': 'AI Agents Statistics: Usage Insights And Market Trends (2025) | SellersCommerce - https://www.sellerscommerce.com/blog/ai-agents-statistics/', 'text': 'In contrast, AI assistants are specialized tools that assist users with specific tasks, often through conversation.'}, {'doc_id': 7, 'source': 'AI Agents Statistics: Usage Insights And Market Trends (2025) | SellersCommerce - https://www.sellerscommerce.com/blog/ai-agents-statistics/', 'text': 'AI agents are transforming how businesses interact with their customers. 54% of global companies are using conversational AI in some way or the other to provide faster and more personalized service.'}, {'doc_id': 8, 'source': '50 NEW Artificial Intelligence Statistics (July 2025) - https://explodingtopics.com/blog/ai-statistics', 'text': 'This is a list of up-to-date artificial intelligence stats for 2025. From ChatGPT to autonomous vehicles, AI is one of the most exciting (and controversial) technology trends in the 21st century.'}, {'doc_id': 8, 'source': '50 NEW Artificial Intelligence Statistics (July 2025) - https://explodingtopics.com/blog/ai-statistics', 'text': \"Here are five AI startups that are trending right now, based on real-time data from the Exploding Topics engine. ... While the current AI market is sizeable, it's set to grow by nearly 5x over the next few years. During this forecast period, the AI market is predicted to increase by a CAGR of 35.9%. The AI software market's global annual revenue (2018 to 2025):\"}, {'doc_id': 8, 'source': '50 NEW Artificial Intelligence Statistics (July 2025) - https://explodingtopics.com/blog/ai-statistics', 'text': \"This guide explains the trends you need to know about now. ... Our survey of 1,000+ AI users reveals who’s paying, who’s resisting, and why the highest earners fear AI the most. ... The latest information available on the launch of OpenAI's newest model: ChatGPT 5. ... Discover the top 9 AI search engines of 2025.\"}, {'doc_id': 8, 'source': '50 NEW Artificial Intelligence Statistics (July 2025) - https://explodingtopics.com/blog/ai-statistics', 'text': \"AI technology is revolutionizing how stores order products, warehouses store goods, and more. Learn about what's next in the supply chain sector with this complete industry trend report.\"}, {'doc_id': 9, 'source': 'AI In ECommerce Statistics (2025) | SellersCommerce - https://www.sellerscommerce.com/blog/ai-in-ecommerce-statistics/', 'text': 'These technologies are not just the latest trend—they’re essential for improving customer experiences, making operations more efficient, and changing how businesses operate. The use of AI in e-commerce will be valued at $8.65 billion in 2025 and $17.1 billion by 2030.'}, {'doc_id': 9, 'source': 'AI In ECommerce Statistics (2025) | SellersCommerce - https://www.sellerscommerce.com/blog/ai-in-ecommerce-statistics/', 'text': 'eCommerce retailers generate between 10% to 30% of their revenue from suggestive selling in which agentic commerce engines can help a lot. Source: In-house report on AI agents. 33% of B2B eCommerce companies in the United States have fully implemented AI in their operations while 47% say they are evaluating the technology.'}, {'doc_id': 9, 'source': 'AI In ECommerce Statistics (2025) | SellersCommerce - https://www.sellerscommerce.com/blog/ai-in-ecommerce-statistics/', 'text': 'Product recommendations can increase revenue by up to 300%, conversions can go up by 150%, and average order value can shoot up by 50%. Source: Grid Dynamics, Fresh Relevance, Statista, Monetate. 58% of Millennial consumers and over 40% of Gen X and Baby Boomer respondents expressed a desire for more personalized product recommendations in e-commerce.'}, {'doc_id': 9, 'source': 'AI In ECommerce Statistics (2025) | SellersCommerce - https://www.sellerscommerce.com/blog/ai-in-ecommerce-statistics/', 'text': 'Here is a table showing Main advantages of using e-commerce chatbots in the U.S. as per shoppers: ... about 90% of large companies have tried using AI in their supply chains, and 29% say they plan to invest a lot in this area over the next three years. The AI in the supply chain market is projected to reach $11.73 billion in 2025, up from $9.15 billion in 2024.'}] | ground_truth: Sustainability accounted for 8.8% of the total conversation. | موجودة؟ False\n",
      "Row 4 => brave_sinp: [{'doc_id': 0, 'source': 'Council Post: 4 Big Trends For DTC E-Commerce Growth In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/04/17/4-big-trends-for-dtc-e-commerce-growth-in-2025/', 'text': 'Another trend in e-commerce is the growing demand for more and more background detail and information on each product sold. No longer satisfied with just a nice-looking label and some positive star ratings, 70% of online shoppers now say that product content can make or break a sale.'}, {'doc_id': 0, 'source': 'Council Post: 4 Big Trends For DTC E-Commerce Growth In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/04/17/4-big-trends-for-dtc-e-commerce-growth-in-2025/', 'text': 'Based on these four e-commerce trends, savvy online brands should consider the following actions and investments to see strong DTC revenue growth in 2025: 1. Extend their brand experience to TikTok Shop and other social commerce platforms to capitalize on new sales opportunities with new and existing audiences. 2. Go deep with the amount of detail and supporting content provided for each product, including long-form video and regular live selling experiences. 3. Provide a more personalized experience for known and unknown shoppers with modern customer personalization technology that uses AI algorithms instead of cookies.'}, {'doc_id': 0, 'source': 'Council Post: 4 Big Trends For DTC E-Commerce Growth In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/04/17/4-big-trends-for-dtc-e-commerce-growth-in-2025/', 'text': '| Membership (fee-based)Apr 17, 2025, 07:15am EDT ... Diane Keng, CEO & cofounder of Breinify, a leading AI-power predictive personalization platform. Forbes 30 Under 30, Enterprise Technology. ... Direct-to-consumer (DTC) e-commerce brands are always looking for the next lever to pull that can help scale their businesses to new heights. But with the ever-changing nature of consumer trends and emerging tech—and the reality of limited budgets for marketing experimentation—it can be hard for brands to decipher between worthwhile long-term investments and passing fads.'}, {'doc_id': 0, 'source': 'Council Post: 4 Big Trends For DTC E-Commerce Growth In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/04/17/4-big-trends-for-dtc-e-commerce-growth-in-2025/', 'text': 'In this article, I’ll examine four big trends in DTC e-commerce growth that appear to be very much here to stay. The growth of social commerce will continue throughout 2025, with more than $100 billion in revenue projected from social media product purchases, an increase of 22% from 2024.'}, {'doc_id': 1, 'source': 'Top Ecommerce Trends to Watch in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-trends/', 'text': 'With consumers craving more immersive and authentic shopping experiences, livestream commerce will become a major revenue driver in 2025, transforming how brands connect with and convert shoppers online. Perhaps one of the greatest challenges of shopping online is the inability to see, touch, and fully experience a product in-person before buying — enter augmented reality (AR). According to eMarketer, the number of AR users in the US will exceed 100 million by the end of 2025, making up 32% of the population.'}, {'doc_id': 1, 'source': 'Top Ecommerce Trends to Watch in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-trends/', 'text': 'Especially in the fashion and apparel industry, younger shoppers are favoring brands that prioritize ethical and eco-friendly practices over those that don’t. According to a study by Drapers and BigCommerce, Drapers survey found that 57% of Gen Z and Millennials say sustainability is important when it comes to shopping for clothes, accessories or shoes — up from 47% in the 2022 survey.'}, {'doc_id': 1, 'source': 'Top Ecommerce Trends to Watch in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-trends/', 'text': 'Today, major retailers are leveraging AR for virtual try-ons and interactive 3D product views, allowing shoppers to visualize products in their real-world environments, thus increasing buyer confidence and reducing return rates. With 75% of US households owning a smart speaker in 2025, it’s no surprise that voice search is an up and coming trend in the ecommerce space. Voice assistants like Amazon Alexa and Google Assistant have transformed the way that consumers interact with ecommerce platforms — like BigCommerce and Shopify — offering a hands-free, convenient way to shop.'}, {'doc_id': 1, 'source': 'Top Ecommerce Trends to Watch in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-trends/', 'text': 'By simply using a voice command, shoppers can search for products, make purchases, and track orders with ease. In response, many ecommerce businesses are optimizing their sites for voice search, ensuring quick and accurate responses to voice queries. And as voice technology continues to innovate, its integration into the shopping experience will undoubtedly enhance customer convenience and drive significant growth in online sales.'}, {'doc_id': 3, 'source': '14 Online Shopping Trends Shaping 2025 - Shopify - https://www.shopify.com/enterprise/blog/online-shopping-trends-ecommerce', 'text': 'This isn’t the first or last time you’ll hear it: Your product pages sell, even more so as we move into 2025. A 2023 survey found that 70% of online shoppers say product-page content can make or break a sale.'}, {'doc_id': 3, 'source': '14 Online Shopping Trends Shaping 2025 - Shopify - https://www.shopify.com/enterprise/blog/online-shopping-trends-ecommerce', 'text': 'Social media platforms like Facebook and Instagram have become increasingly popular places for consumers to discover, research, and purchase new products.  · Social commerce makes shopping a more convenient and interactive experience, which helps explain why eMarketer projects over $100 billion in social commerce sales in 2025, a 22.4% growth from year prior.'}, {'doc_id': 3, 'source': '14 Online Shopping Trends Shaping 2025 - Shopify - https://www.shopify.com/enterprise/blog/online-shopping-trends-ecommerce', 'text': 'Get access to the data and insights shaping ecommerce and how the biggest brands are driving growth. Download the guide · Mindful shopping practices will increase. More shoppers will head in-store. Shoppers will look for more product details. Green initiatives will continue to be popular—with a caveat. More people will shop through social commerce.'}, {'doc_id': 3, 'source': '14 Online Shopping Trends Shaping 2025 - Shopify - https://www.shopify.com/enterprise/blog/online-shopping-trends-ecommerce', 'text': 'As mobile browsing overtakes desktop––almost 64% of global web traffic came from mobile devices in August 2024––increasing numbers of shoppers are tapping “buy” on their devices. In 2023, retail m-commerce sales hit $2.2 trillion, and now make up 60% of all ecommerce sales around the world. By 2027, analysts expect that number to reach $3.4 trillion.'}, {'doc_id': 4, 'source': 'eCommerce statistics 2025: key findings and shopping trends [latest research] - https://www.hostinger.com/ph/tutorials/ecommerce-statistics', 'text': 'With this uptrend, mobile commerce sales are projected to exceed $3.4 trillion by 2027. To keep up with evolving consumer behavior, online stores must prioritize mobile optimization in mobile-first markets. Start by creating a user-friendly customer journey, from browsing to purchasing products. Global mobile commerce is growing at a rate of 29%, capturing 7% more completed payments than traditional eCommerce. Around 70% of shoppers say mobile commerce is time-saving and convenient for buying on the go.'}, {'doc_id': 4, 'source': 'eCommerce statistics 2025: key findings and shopping trends [latest research] - https://www.hostinger.com/ph/tutorials/ecommerce-statistics', 'text': 'It’s no surprise that brands focusing on environmental, social, and governance (ESG) initiatives saw an average of 28% growth, while those without only grew by 20%. 24/7 availability, convenience, and discount deals make online shopping the go-to choice for 56.6% of consumers. That said, 44.4% still prefer in-store shopping, valuing the hands-on experience and ability to see, touch, and test products before buying. If you have the resources, consider adopting a multichannel business model to cater to both customer preferences. The thriving mobile commerce market makes it easy for people to shop online using only their phones.'}, {'doc_id': 4, 'source': 'eCommerce statistics 2025: key findings and shopping trends [latest research] - https://www.hostinger.com/ph/tutorials/ecommerce-statistics', 'text': 'Global eCommerce revenue is projected to exceed $6.4 trillion by 2029, with an annual growth rate (CAGR) of 9.49% from 2024 to 2029. This growth is consistent with the continued rise of online shopping worldwide. By 2029, the average revenue per user (ARPU) in the eCommerce market is expected to reach $1,620, highlighting the rising spending power of online shoppers.'}, {'doc_id': 4, 'source': 'eCommerce statistics 2025: key findings and shopping trends [latest research] - https://www.hostinger.com/ph/tutorials/ecommerce-statistics', 'text': 'Unexpected or high fees or taxes deterred 16% of shoppers from purchasing, while 14% decided to wait for a sale or discount. Meanwhile, indecisiveness or a change in mood accounted for 14% of abandoned carts. Other reasons for leaving carts include a lengthy or complicated checkout process (4%) and concerns about payment security (3%). High shipping costs and long delivery times are a bigger concern for men, with 59% finding them problematic compared to 41% of women.'}, {'doc_id': 5, 'source': 'DTC e-commerce: How consumer brands can get it right | McKinsey - https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/dtc-e-commerce-how-consumer-brands-can-get-it-right', 'text': 'In a similar vein, 75 percent of online shoppers say they prefer a personalized experience. For example, fashion brands such as Maje, Sandro, and The Kooples offer exclusive online presales to registered online customers. Assortment. Many brands choose to adapt their DTC assortment to the specific requirements of their sector and consumers.'}, {'doc_id': 5, 'source': 'DTC e-commerce: How consumer brands can get it right | McKinsey - https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/dtc-e-commerce-how-consumer-brands-can-get-it-right', 'text': 'During the COVID-19 pandemic, there has been a 70 percent increase in content uploads by users of Lego’s online platforms that help the company engage with consumers and find out what they like, especially in fast-growth markets, such as China.1“Lego builds its brand in China with experiences,” WARC, January 13, 2020, warc.com. Fueling innovation. DTC also provides the platform to test the latest innovation in products and services, giving brands direct access to consumer feedback for evaluation and testing.'}, {'doc_id': 5, 'source': 'DTC e-commerce: How consumer brands can get it right | McKinsey - https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/dtc-e-commerce-how-consumer-brands-can-get-it-right', 'text': 'Just 60 percent of consumer-goods companies, at best, feel even moderately prepared to capture e-commerce growth opportunities. Here are some concerns expressed by top executives globally: “I’m worried about fulfillment. What if we disappoint online shoppers?'}, {'doc_id': 5, 'source': 'DTC e-commerce: How consumer brands can get it right | McKinsey - https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/dtc-e-commerce-how-consumer-brands-can-get-it-right', 'text': 'At the early stages of DTC, brands often outsource logistics to guarantee quality, speed, and the flexibility to scale operations up or down as needed. Consumer brands that have their own retail network often use their stores as e-commerce fulfillment centers. Nike, for example, lets online shoppers pick up their purchases at brick-and-mortar Nike stores.'}, {'doc_id': 6, 'source': 'DTC Ecommerce Trends: What Brands Are Adopting in 2025 - https://webandcrafts.com/blog/dtc-ecommerce-trends', 'text': 'According to the June 2023 Global Consumer Insights Pulse Survey, about 63% of shoppers have purchased products from a brand’s website directly. In the highly competitive market, consumers wish for faster delivery of products, active customer support, personalized products, and a reliable source of information – this is where DTC e-commerce trends prove amazing.'}, {'doc_id': 6, 'source': 'DTC Ecommerce Trends: What Brands Are Adopting in 2025 - https://webandcrafts.com/blog/dtc-ecommerce-trends', 'text': 'Ecommerce retail sales are expected to reach 9.4 trillion U.S. dollars by 2026 on a global scale. Many physical retailers like BestBuy and Target have adopted measures for a major shift towards DTC models. As shoppers become more concerned and expectations grow, brands should find ways to meet the demands, offer value, and build exceptional customer experiences. This blog discusses the significant direct-to-consumer trends that shape the e-commerce sector and gives insights into how retailers should adopt these trends.'}, {'doc_id': 6, 'source': 'DTC Ecommerce Trends: What Brands Are Adopting in 2025 - https://webandcrafts.com/blog/dtc-ecommerce-trends', 'text': 'The global food and beverage market for e-commerce is expected to hit $903465.5 million by 2026. Due to many new players evolving in the space, the DTC segment is also growing. For instance, Magic Spoon is a breakfast cereal on low carb, and ideal for a keto diet. Choosing to implement the DTC model or not, depends heavily on the target audience, product, current sales, and marketing ecosystem.'}, {'doc_id': 6, 'source': 'DTC Ecommerce Trends: What Brands Are Adopting in 2025 - https://webandcrafts.com/blog/dtc-ecommerce-trends', 'text': 'Customer relationships are significant regardless of what method you adopt to sell the products. Considering the DTC sales, you should be aware of the latest trends. A brand should always be careful of the increased competition, advertising expenses, and Customer Acquisition Costs (CAC), and be ready to capitalize on the opportunities revolving around data management, customer experience, and wholesale. As the conventional retail business has been eventually taken over by D2C e-commerce, we can expect more customer-focused initiatives that can take e-commerce business to newer heights.'}, {'doc_id': 7, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'One of the biggest challenges in e-commerce is helping customers visualize the sensory aspects of shopping: how a product will look on them, or work for them in their space. Augmented reality can help ease that anxiety, making online shoppers more likely to click buy.'}, {'doc_id': 7, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'In 2025, companies will continue moving beyond fixed monthly boxes to create flexible subscriptions that allow customers to swap products, adjust delivery frequencies, or receive personalized recommendations based on their browsing and purchasing history. Predictive analytics helps businesses anticipate customer needs before they even realize them. The continued growth of this model shows that while subscriptions may not be new to e-commerce trends, they’re constantly being revamped to boost customer loyalty and create consistent revenue streams for brands.'}, {'doc_id': 7, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'According to an IDC study, 46% of consumers believe that a retail brand’s sustainability record is an important deciding factor for whom they’ll do business with. In 2025, e-commerce companies are looking at everything from their product packaging to their manufacturing and warehousing facilities to assess their emissions baseline and identify opportunities to improve.'}, {'doc_id': 7, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'For online retailers, e-commerce trends in 2025 reflect a hybrid shopping reality. Customers expect to move fluidly between digital and physical purchases with a brand – and the brand better know them well enough to serve up personalized suggestions, great customer service, and an outstanding CX, or else they’ll bail. Last year, global retail e-commerce sales landed around $5.8 trillion. Experts are anticipating ongoing growth, with 2027 projections surpassing $8 trillion by 2027.'}, {'doc_id': 8, 'source': '51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/', 'text': 'Ecommerce sales will surpass $6.8 trillion in 2025. There are over 28 million eCommerce stores globally. 52% of online shoppers look for products internationally. ... This section sheds light on the growth of the eCommerce sector over the years and what are its future projections.'}, {'doc_id': 8, 'source': '51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/', 'text': 'People aged 18 to 34 were the most into buying through social media, with about 73% of them saying they’ve bought something via social media channels. On the other hand, people who are 65 and up were the least likely to buy things through social media, with only about a quarter of them doing it. While people prefer to purchase more Consumer electronics on eCommerce websites, the trend shifts to self-care when it comes to social commerce. 20% of people revealed that they had purchased personal care products eight or more times during the past year.'}, {'doc_id': 8, 'source': '51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/', 'text': '69.4 million people from the United States are expected to shop on Facebook in 2025 making it the most popular social media for social commerce. That’s 20% of the country’s population shopping on the social platforms! Instagram is also favored by 47.5 million shoppers while TikTok is not far behind with 37.8 million expected shoppers.'}, {'doc_id': 8, 'source': '51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/', 'text': 'BNPL is seeing a positive growth trajectory but America is a country where most people use their cards to make payments, there are 3.26 credit cards per capita, compared with just 0.99 debit cards. ... 40% of online shoppers in the United States have shopped at least once using live commerce.'}, {'doc_id': 9, 'source': 'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics', 'text': 'Global social commerce sales are set to reach $1.2 trillion by 2025. And leading this front are millennials and Gen Z online shoppers.  · Gen Z is highly engaged in social media shopping and spending, with 68% searching for products on social media and 22% completing a purchase.'}, {'doc_id': 9, 'source': 'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics', 'text': 'As raw material and transportation costs rise, ecommerce businesses, particularly those dependent on imports, face the challenge of increased product prices.  · This can lead to more price-sensitive consumers, potentially reducing demand and impacting sales and profits.  · For example, Retail Economics and Metapack found that 57% of consumers are worried about inflation, which is the biggest concern for consumers in 2023. Also, 72% of shoppers plan to change their buying behavior as a result, with even the most affluent 61% planning to switch up their habits.'}, {'doc_id': 9, 'source': 'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics', 'text': 'IRP Commerce suggests a positive trend in conversion efficiency globally. While .14% might seem like a small number, it indicates improvements in various factors that influence consumer purchasing decisions, such as website design, user experience, product offerings, pricing, and marketing strategies.  · The global B2C ecommerce market reached $4.8 trillion in 2023 and is expected to grow to $9 trillion by 2032—a growth rate of 7% between 2024 and 2027.'}, {'doc_id': 9, 'source': 'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics', 'text': 'The live commerce market in China was $562 billion in 2023 and is expected to increase to $843 billion in 2025. It made up 19.2% of the retail ecommerce sales in 2023.  · In the US, livestreaming was expected to reach $31 billion in 2023, almost triple the size in 2021. Another new marketing channel coming on the horizon is connected TV (CTV) advertising—which refers to ads you’ll find on platforms like Hulu, Roku, and YouTube.  · The growth of CTV advertising spend in the US is projected to increase from $25 billion in 2023 to nearly $41 billion by 2027, while linear TV ad spend is expected to decline from $61 billion to $56 billion in the same period.'}] | ground_truth: 70% of online shoppers say that product content can make or break a sale. | موجودة؟ False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_brave = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\"\n",
    "df = pd.read_excel(file_brave)\n",
    "\n",
    "# نطبع أول 5 صفوف مع العمودين اللي نحتاجهم\n",
    "print(df[[\"brave_sinp\", \"ground_truth\"]].head())\n",
    "\n",
    "# نطبع نتيجة المقارنة للسطر الأول مثلاً\n",
    "for i in range(5):\n",
    "    sinp = str(df.loc[i, \"brave_sinp\"])\n",
    "    gt = str(df.loc[i, \"ground_truth\"])\n",
    "    print(f\"Row {i} => brave_sinp: {sinp} | ground_truth: {gt} | موجودة؟ {sinp.lower() in gt.lower()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b594ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#كود فصل الروابط \n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def check_need_script(row):\n",
    "    ground_truth = str(row['ground_truth']).lower()\n",
    "    \n",
    "    try:\n",
    "        sinp_list = ast.literal_eval(str(row['brave_sinp']))\n",
    "    except:\n",
    "        return \"Yes\"  # لو صار خطأ نخليها Yes\n",
    "    \n",
    "    for item in sinp_list:\n",
    "        text = str(item.get('text', '')).lower()\n",
    "        # نتحقق إذا فيه تقاطع جزئي\n",
    "        if text in ground_truth or ground_truth in text:\n",
    "            return \"No\"\n",
    "    return \"Yes\"\n",
    "\n",
    "# نضيف العمود الجديد\n",
    "df['need_script'] = df.apply(check_need_script, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74b69ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-2TPndG2NS9PJ7IEW4r6SjAA6 on tokens per min (TPM): Limit 100000, Used 100000, Requested 5523. Please try again in 39h45m56.16s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-2TPndG2NS9PJ7IEW4r6SjAA6 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-2TPndG2NS9PJ7IEW4r6SjAA6 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1027\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\httpx\\_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mYes\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# نخليها Yes احتياط\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# نضيف العمود الجديد\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m file_brave3[\u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfile_brave3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjudge_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer_brave\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     45\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# حفظ النتيجة\u001b[39;00m\n\u001b[32m     48\u001b[39m file_brave3.to_excel(\u001b[33m\"\u001b[39m\u001b[33m./brave_with_need_script.xlsx\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:10381\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10367\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10369\u001b[39m op = frame_apply(\n\u001b[32m  10370\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10371\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10379\u001b[39m     kwargs=kwargs,\n\u001b[32m  10380\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mYes\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# نخليها Yes احتياط\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# نضيف العمود الجديد\u001b[39;00m\n\u001b[32m     42\u001b[39m file_brave3[\u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = file_brave3.apply(\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mjudge_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer_brave\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     44\u001b[39m     axis=\u001b[32m1\u001b[39m\n\u001b[32m     45\u001b[39m )\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# حفظ النتيجة\u001b[39;00m\n\u001b[32m     48\u001b[39m file_brave3.to_excel(\u001b[33m\"\u001b[39m\u001b[33m./brave_with_need_script.xlsx\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mjudge_with_llm\u001b[39m\u001b[34m(gt, ans, snip)\u001b[39m\n\u001b[32m     12\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[33mYou are a judge. Decide if the answer is supported by the snippet.\u001b[39m\n\u001b[32m     14\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m \u001b[33mAnswer only with \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYes\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m if supported, or \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m if not.\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m         response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m         decision = response.choices[\u001b[32m0\u001b[39m].message.content.strip()\n\u001b[32m     33\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33myes\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m decision.lower():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1033\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1032\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1073\u001b[39m, in \u001b[36mSyncAPIClient._sleep_for_retry\u001b[39m\u001b[34m(self, retries_taken, max_retries, options, response)\u001b[39m\n\u001b[32m   1070\u001b[39m timeout = \u001b[38;5;28mself\u001b[39m._calculate_retry_timeout(remaining_retries, options, response.headers \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1071\u001b[39m log.info(\u001b[33m\"\u001b[39m\u001b[33mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m, options.url, timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m time.sleep(timeout)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# تحميل ملف Brave\n",
    "file_brave3 = pd.read_excel(\"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\")\n",
    "\n",
    "# تهيئة OpenAI Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# دالة: نخلي LLM يحكم إذا الجواب مدعوم أم لا\n",
    "def judge_with_llm(gt, ans, snip):\n",
    "    prompt = f\"\"\"\n",
    "You are a judge. Decide if the answer is supported by the snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Answer:\n",
    "{ans}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if supported, or \"No\" if not.\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        decision = response.choices[0].message.content.strip()\n",
    "        if \"yes\" in decision.lower():\n",
    "            return \"No\"   # لا يحتاج سكربت إضافي\n",
    "        else:\n",
    "            return \"Yes\"  # يحتاج سكربت\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # نخليها Yes احتياط\n",
    "\n",
    "# نضيف العمود الجديد\n",
    "file_brave3[\"need_script\"] = file_brave3.apply(\n",
    "    lambda row: judge_with_llm(row[\"ground_truth\"], row[\"answer_brave\"], row[\"brave_sinp\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# حفظ النتيجة\n",
    "file_brave3.to_excel(\"./brave_with_need_script.xlsx\", index=False)\n",
    "\n",
    "print(\"تم إنشاء الملف: brave_with_need_script.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d86784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-2TPndG2NS9PJ7IEW4r6SjAA6 on tokens per min (TPM): Limit 100000, Used 100000, Requested 5083. Please try again in 36h35m51.36s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1027\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\httpx\\_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mYes\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# نخليها Yes احتياط\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# نضيف العمود الجديد\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m file_brave3[\u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfile_brave3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjudge_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer_brave\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     53\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# حفظ النتيجة\u001b[39;00m\n\u001b[32m     56\u001b[39m file_brave3.to_excel(\u001b[33m\"\u001b[39m\u001b[33m./brave_with_need_script_test.xlsx\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:10381\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10367\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10369\u001b[39m op = frame_apply(\n\u001b[32m  10370\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10371\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10379\u001b[39m     kwargs=kwargs,\n\u001b[32m  10380\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mYes\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# نخليها Yes احتياط\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# نضيف العمود الجديد\u001b[39;00m\n\u001b[32m     50\u001b[39m file_brave3[\u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = file_brave3.apply(\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mjudge_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer_brave\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     52\u001b[39m     axis=\u001b[32m1\u001b[39m\n\u001b[32m     53\u001b[39m )\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# حفظ النتيجة\u001b[39;00m\n\u001b[32m     56\u001b[39m file_brave3.to_excel(\u001b[33m\"\u001b[39m\u001b[33m./brave_with_need_script_test.xlsx\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mjudge_with_llm\u001b[39m\u001b[34m(gt, ans, snip)\u001b[39m\n\u001b[32m     16\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[33mYou are a judge. Decide if the answer is supported by the snippet.\u001b[39m\n\u001b[32m     18\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \u001b[33mAnswer only with \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYes\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m if supported, or \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m if not.\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m         response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m         decision = response.choices[\u001b[32m0\u001b[39m].message.content.strip()\n\u001b[32m     38\u001b[39m         \u001b[38;5;66;03m# نضيف تأخير بسيط عشان ما يضرب الحد\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1033\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1032\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1073\u001b[39m, in \u001b[36mSyncAPIClient._sleep_for_retry\u001b[39m\u001b[34m(self, retries_taken, max_retries, options, response)\u001b[39m\n\u001b[32m   1070\u001b[39m timeout = \u001b[38;5;28mself\u001b[39m._calculate_retry_timeout(remaining_retries, options, response.headers \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1071\u001b[39m log.info(\u001b[33m\"\u001b[39m\u001b[33mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m, options.url, timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m time.sleep(timeout)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "# تحميل ملف Brave\n",
    "file_brave3 = pd.read_excel(\"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\")\n",
    "\n",
    "# ناخذ أول 10 صفوف فقط للتجربة\n",
    "file_brave3 = file_brave3.head(10)\n",
    "\n",
    "# تهيئة OpenAI Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# دالة: نخلي LLM يحكم إذا الجواب مدعوم أم لا\n",
    "def judge_with_llm(gt, ans, snip):\n",
    "    prompt = f\"\"\"\n",
    "You are a judge. Decide if the answer is supported by the snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Answer:\n",
    "{ans}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if supported, or \"No\" if not.\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        decision = response.choices[0].message.content.strip()\n",
    "\n",
    "        # نضيف تأخير بسيط عشان ما يضرب الحد\n",
    "        time.sleep(5)\n",
    "\n",
    "        if \"yes\" in decision.lower():\n",
    "            return \"No\"   # لا يحتاج سكربت إضافي\n",
    "        else:\n",
    "            return \"Yes\"  # يحتاج سكربت\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # نخليها Yes احتياط\n",
    "\n",
    "# نضيف العمود الجديد\n",
    "file_brave3[\"need_script\"] = file_brave3.apply(\n",
    "    lambda row: judge_with_llm(row[\"ground_truth\"], row[\"answer_brave\"], row[\"brave_sinp\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# حفظ النتيجة\n",
    "file_brave3.to_excel(\"./brave_with_need_script_test.xlsx\", index=False)\n",
    "\n",
    "print(\"تم إنشاء الملف: brave_with_need_script_test.xlsx (أول 10 صفوف فقط)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b718a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-2TPndG2NS9PJ7IEW4r6SjAA6 on tokens per min (TPM): Limit 100000, Used 100000, Requested 5083. Please try again in 36h35m51.36s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# تحميل ملف Brave\n",
    "file_brave3 = pd.read_excel(\"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\")\n",
    "\n",
    "# ناخذ أول 5 صفوف فقط للتجربة\n",
    "file_brave3 = file_brave3.head(5)\n",
    "\n",
    "# تهيئة OpenAI Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# دالة: نخلي LLM يحكم إذا الجواب مدعوم أم لا\n",
    "def judge_with_llm(gt, ans, snip):\n",
    "    prompt = f\"\"\"\n",
    "You are a judge. Decide if the answer is supported by the snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Answer:\n",
    "{ans}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if supported, or \"No\" if not.\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        decision = response.choices[0].message.content.strip()\n",
    "        if \"yes\" in decision.lower():\n",
    "            return \"No\"   # لا يحتاج سكربت إضافي\n",
    "        else:\n",
    "            return \"Yes\"  # يحتاج سكربت\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # نخليها Yes احتياط\n",
    "\n",
    "# نضيف العمود الجديد\n",
    "file_brave3[\"need_script\"] = file_brave3.apply(\n",
    "    lambda row: judge_with_llm(row[\"ground_truth\"], row[\"answer_brave\"], row[\"brave_sinp\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# حفظ النتيجة\n",
    "file_brave3.to_excel(\"./brave_with_need_script.xlsx\", index=False)\n",
    "\n",
    "print(\"تم إنشاء الملف: brave_with_need_script.xlsx (أول 5 صفوف فقط)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dbf7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم إنشاء الملف: brave_with_need_script_sample.xlsx (أول 3 صفوف فقط)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# تحميل ملف Brave\n",
    "file_brave3 = pd.read_excel(\"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\")\n",
    "\n",
    "# نشتغل فقط على أول 3 صفوف\n",
    "file_brave3 = file_brave3.head(3)\n",
    "\n",
    "# تهيئة OpenAI Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# دالة: نخلي LLM يحكم إذا الجواب مدعوم أم لا\n",
    "def judge_with_llm(gt, ans, snip):\n",
    "    prompt = f\"\"\"\n",
    "You are a judge. Decide if the answer is supported by the snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Answer:\n",
    "{ans}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if supported, or \"No\" if not.\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        decision = response.choices[0].message.content.strip()\n",
    "        if \"yes\" in decision.lower():\n",
    "            return \"No\"   # لا يحتاج سكربت إضافي\n",
    "        else:\n",
    "            return \"Yes\"  # يحتاج سكربت\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # نخليها Yes احتياط\n",
    "\n",
    "# نضيف العمود الجديد\n",
    "file_brave3[\"need_script\"] = file_brave3.apply(\n",
    "    lambda row: judge_with_llm(row[\"ground_truth\"], row[\"answer_brave\"], row[\"brave_sinp\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# حفظ النتيجة\n",
    "file_brave3.to_excel(\"./brave_with_need_script_sample.xlsx\", index=False)\n",
    "\n",
    "print(\"تم إنشاء الملف: brave_with_need_script_sample.xlsx (أول 3 صفوف فقط)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fda97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تحديث الملف: ./brave_with_need_script_sample.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# تحميل الملف السابق اللي فيه أول 3 صفوف\n",
    "file_path = \"./brave_with_need_script_sample.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# تهيئة OpenAI Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# دالة: نخلي LLM يحكم إذا الجواب مدعوم أم لا\n",
    "def judge_with_llm(gt, ans, snip):\n",
    "    prompt = f\"\"\"\n",
    "You are a judge. Decide if the answer is supported by the snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Answer:\n",
    "{ans}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if supported, or \"No\" if not.\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        decision = response.choices[0].message.content.strip()\n",
    "        if \"yes\" in decision.lower():\n",
    "            return \"No\"   # لا يحتاج سكربت إضافي\n",
    "        else:\n",
    "            return \"Yes\"  # يحتاج سكربت\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # نخليها Yes احتياط\n",
    "\n",
    "# نكمل على الصفوف اللي ما فيها need_script\n",
    "batch_size = 5\n",
    "rows_to_process = file_brave3[file_brave3[\"need_script\"].isna()].head(batch_size)\n",
    "\n",
    "for i in rows_to_process.index:\n",
    "    row = file_brave3.loc[i]\n",
    "    file_brave3.at[i, \"need_script\"] = judge_with_llm(row[\"ground_truth\"], row[\"answer_brave\"], row[\"brave_sinp\"])\n",
    "    print(f\"تمت معالجة الصف {i+1}\")\n",
    "    time.sleep(3)  # نوقف شوية عشان نتجنب الحظر\n",
    "\n",
    "# نحفظ فوق نفس الملف\n",
    "file_brave3.to_excel(file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث الملف: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b1850e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم تحديث الملف: brave_with_need_script_sample.xlsx (تمت معالجة 0 صفوف جديدة فقط)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# الملف اللي تشتغلين عليه\n",
    "file_path = \"brave_with_need_script_sample.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "def judge_with_llm(gt, ans, sinp):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that judges if the answer requires a script.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Ground Truth: {gt}\\nAnswer: {ans}\\nSearch Snippet: {sinp}\\n\\nQuestion: Does this answer need a script? Reply Yes or No.\"}\n",
    "            ],\n",
    "            max_tokens=10,\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return \"Yes\" if \"yes\" in result.lower() else \"No\"\n",
    "    except Exception as e:\n",
    "        print(f\"خطأ: {e}\")\n",
    "        return \"No\"\n",
    "\n",
    "# نختار فقط الصفوف اللي ما تعالجت\n",
    "rows_to_process = file_brave3[file_brave3[\"need_script\"].isna()].head(10)\n",
    "\n",
    "\n",
    "for idx, row in rows_to_process.iterrows():\n",
    "    print(f\"جاري معالجة الصف {idx+1} ...\")\n",
    "    file_brave3.at[idx, \"need_script\"] = judge_with_llm(\n",
    "        row[\"ground_truth\"], row[\"answer_brave\"], row[\"brave_sinp\"]\n",
    "    )\n",
    "    time.sleep(2)  # تأخير بسيط لتقليل الضغط على API\n",
    "\n",
    "# نحفظ التحديث\n",
    "file_brave3.to_excel(file_path, index=False)\n",
    "print(f\"تم تحديث الملف: {file_path} (تمت معالجة {len(rows_to_process)} صفوف جديدة فقط)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f38ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تحديث الملف: تمت معالجة 0 صفوف جديدة فقط\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# تحميل ملف Brave\n",
    "file_path = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# تهيئة OpenAI Client\n",
    "lient = OpenAI(api_key=\"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\")\n",
    "# دالة: نخلي LLM يحكم إذا الجواب مدعوم أم لا\n",
    "def judge_with_llm(gt, ans, snip):\n",
    "    prompt = f\"\"\"\n",
    "You are a judge. Decide if the answer is supported by the snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Answer:\n",
    "{ans}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if supported, or \"No\" if not.\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        decision = response.choices[0].message.content.strip()\n",
    "        if \"yes\" in decision.lower():\n",
    "            return \"No\"   # لا يحتاج سكربت إضافي\n",
    "        else:\n",
    "            return \"Yes\"  # يحتاج سكربت\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # نخليها Yes احتياط\n",
    "\n",
    "# إذا العمود غير موجود نضيفه\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "\n",
    "# نحدد الصفوف اللي محتاجة إعادة تقييم (القيمة = \"Yes\")\n",
    "rows_to_update = file_brave3[file_brave3[\"need_script\"] == \"Yes\"]\n",
    "\n",
    "# ناخذ أول 10 صفوف فقط\n",
    "rows_to_update = rows_to_update.head(10)\n",
    "\n",
    "# نحدث القيم\n",
    "for i, row in rows_to_update.iterrows():\n",
    "    file_brave3.at[i, \"need_script\"] = judge_with_llm(\n",
    "        row[\"ground_truth\"], row[\"answer_brave\"], row[\"brave_sinp\"]\n",
    "    )\n",
    "\n",
    "# حفظ النتيجة في نفس الملف\n",
    "file_brave3.to_excel(file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث الملف: تمت معالجة {len(rows_to_update)} صفوف جديدة فقط\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b10272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ لا يوجد صفوف Yes جديدة لمعالجتها\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# تحميل الملف الأصلي\n",
    "file_path = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# تهيئة OpenAI Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# دالة الحكم بالـ LLM\n",
    "def judge_with_llm(gt, ans, snip):\n",
    "    prompt = f\"\"\"\n",
    "You are a judge. Decide if the answer is supported by the snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Answer:\n",
    "{ans}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if supported, or \"No\" if not.\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        decision = response.choices[0].message.content.strip()\n",
    "        if \"yes\" in decision.lower():\n",
    "            return \"No\"   # لا يحتاج سكربت إضافي\n",
    "        else:\n",
    "            return \"Yes\"  # يحتاج سكربت\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"\n",
    "\n",
    "# نختار فقط أول 10 صفوف من اللي قيمتها Yes\n",
    "rows_to_update = df[df[\"need_script\"] == \"Yes\"].head(10)\n",
    "\n",
    "# لو في صفوف لازم تتحدث\n",
    "if not rows_to_update.empty:\n",
    "    for idx, row in rows_to_update.iterrows():\n",
    "        df.at[idx, \"need_script\"] = judge_with_llm(row[\"ground_truth\"], row[\"answer_brave\"], row[\"brave_sinp\"])\n",
    "\n",
    "    # نحفظ التحديث على نفس الملف\n",
    "    df.to_excel(file_path, index=False)\n",
    "    print(f\"✅ تم تحديث الملف: تمت معالجة {len(rows_to_update)} صفوف جديدة\")\n",
    "else:\n",
    "    print(\"✅ لا يوجد صفوف Yes جديدة لمعالجتها\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b0486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 عدد الصفوف المطلوب معالجتها: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SarahAlqahtani\\AppData\\Local\\Temp\\ipykernel_34032\\3491464396.py:51: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'No' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  file_brave3.at[idx, \"need_script\"] = judge_with_llm(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1027\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\httpx\\_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m🔄 عدد الصفوف المطلوب معالجتها: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(rows_to_process)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m rows_to_process.iterrows():\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     file_brave3.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mjudge_with_llm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer_brave\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# حفظ النتيجة\u001b[39;00m\n\u001b[32m     56\u001b[39m file_brave3.to_excel(\u001b[33m\"\u001b[39m\u001b[33mC:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean_with_need_script.xlsx\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mjudge_with_llm\u001b[39m\u001b[34m(gt, ans, snip)\u001b[39m\n\u001b[32m     11\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33mYou are a judge. Decide if the answer is supported by the snippet.\u001b[39m\n\u001b[32m     13\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \u001b[33mAnswer only with \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYes\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m if supported, or \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m if not.\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m         decision = response.choices[\u001b[32m0\u001b[39m].message.content.strip()\n\u001b[32m     32\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33myes\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m decision.lower():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1033\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1032\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1073\u001b[39m, in \u001b[36mSyncAPIClient._sleep_for_retry\u001b[39m\u001b[34m(self, retries_taken, max_retries, options, response)\u001b[39m\n\u001b[32m   1070\u001b[39m timeout = \u001b[38;5;28mself\u001b[39m._calculate_retry_timeout(remaining_retries, options, response.headers \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1071\u001b[39m log.info(\u001b[33m\"\u001b[39m\u001b[33mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m, options.url, timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# تحميل ملف Brave الأصلي\n",
    "file_brave3 = pd.read_excel(\"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\")\n",
    "\n",
    "# تهيئة OpenAI Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "# دالة: نخلي LLM يحكم إذا الجواب مدعوم أم لا\n",
    "def judge_with_llm(gt, ans, snip):\n",
    "    prompt = f\"\"\"\n",
    "You are a judge. Decide if the answer is supported by the snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Answer:\n",
    "{ans}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if supported, or \"No\" if not.\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        decision = response.choices[0].message.content.strip()\n",
    "        if \"yes\" in decision.lower():\n",
    "            return \"No\"   # لا يحتاج سكربت إضافي\n",
    "        else:\n",
    "            return \"Yes\"  # يحتاج سكربت\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # نخليها Yes احتياط\n",
    "\n",
    "# نضيف العمود لو مو موجود\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "\n",
    "# نشتغل فقط على الصفوف اللي العمود عندها فاضي\n",
    "mask = file_brave3[\"need_script\"].isna()\n",
    "rows_to_process = file_brave3[mask]\n",
    "\n",
    "print(f\"🔄 عدد الصفوف المطلوب معالجتها: {len(rows_to_process)}\")\n",
    "\n",
    "for idx, row in rows_to_process.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = judge_with_llm(\n",
    "        row[\"ground_truth\"], row[\"answer_brave\"], row[\"brave_sinp\"]\n",
    "    )\n",
    "\n",
    "# حفظ النتيجة\n",
    "file_brave3.to_excel(\"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean_with_need_script.xlsx\", index=False)\n",
    "\n",
    "print(\"✅ تم تحديث الملف: brave_sec_t2_clean_with_need_script.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ccd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SarahAlqahtani\\AppData\\Local\\Temp\\ipykernel_34032\\2703076567.py:52: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'No' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  file_brave3.at[idx, \"need_script\"] = judge_with_llm(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-pPdNrNZiZid9ZDDasYArYD89 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-pPdNrNZiZid9ZDDasYArYD89 on tokens per min (TPM): Limit 100000, Used 99320, Requested 4412. Please try again in 26h52m13.44s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-pPdNrNZiZid9ZDDasYArYD89 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# تحميل ملف Brave\n",
    "file_path = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# تهيئة OpenAI Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "# دالة: نخلي LLM يحكم إذا الجواب مدعوم أم لا\n",
    "\n",
    "# دالة: نخلي LLM يحكم إذا الجواب مدعوم أم لا\n",
    "def judge_with_llm(gt, ans, snip):\n",
    "    prompt = f\"\"\"\n",
    "You are a judge. Decide if the answer is supported by the snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Answer:\n",
    "{ans}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if supported, or \"No\" if not.\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        decision = response.choices[0].message.content.strip()\n",
    "        if \"yes\" in decision.lower():\n",
    "            return \"No\"   # لا يحتاج سكربت إضافي\n",
    "        else:\n",
    "            return \"Yes\"  # يحتاج سكربت\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # نخليها Yes احتياط\n",
    "\n",
    "# لو العمود مو موجود نضيفه\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "\n",
    "# نحدد الصفوف الفاضية بس\n",
    "rows_to_process = file_brave3[file_brave3[\"need_script\"].isna()].head(10)\n",
    "\n",
    "# نعالج 10 صفوف فقط\n",
    "for idx, row in rows_to_process.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = judge_with_llm(\n",
    "        row[\"ground_truth\"], row[\"answer_brave\"], row[\"brave_sinp\"]\n",
    "    )\n",
    "\n",
    "# حفظ الملف بعد التحديث\n",
    "file_brave3.to_excel(file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث الملف: تمت معالجة {len(rows_to_process)} صفوف جديدة فقط\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8f925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-pPdNrNZiZid9ZDDasYArYD89 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SarahAlqahtani\\AppData\\Local\\Temp\\ipykernel_34240\\558551787.py:52: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Yes' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  file_brave3.at[idx, \"need_script\"] = judge_with_llm(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m rows_to_process.iterrows():\n\u001b[32m     52\u001b[39m     file_brave3.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = judge_with_llm(\n\u001b[32m     53\u001b[39m         row[\u001b[33m\"\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m\"\u001b[39m], row[\u001b[33m\"\u001b[39m\u001b[33manswer_brave\u001b[39m\u001b[33m\"\u001b[39m], row[\u001b[33m\"\u001b[39m\u001b[33mbrave_sinp\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     54\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# نرتاح 20 ثانية بين كل طلب\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# حفظ التحديث\u001b[39;00m\n\u001b[32m     58\u001b[39m file_brave3.to_excel(file_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "# تحميل الملف\n",
    "file_path = \"C:/Users/SarahAlqahtani/Documents/code/brave_sec_t2_clean.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# تهيئة OpenAI Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# لو العمود مو موجود نضيفه بنوع نصي\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = pd.Series([None] * len(file_brave3), dtype=\"object\")\n",
    "\n",
    "# دالة: نخلي LLM يحكم إذا الجواب مدعوم أم لا\n",
    "def judge_with_llm(gt, ans, snip):\n",
    "    prompt = f\"\"\"\n",
    "You are a judge. Decide if the answer is supported by the snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Answer:\n",
    "{ans}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if supported, or \"No\" if not.\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",   # ممكن تغييره لـ gpt-3.5-turbo لتخفيف الضغط\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        decision = response.choices[0].message.content.strip()\n",
    "        if \"yes\" in decision.lower():\n",
    "            return \"No\"\n",
    "        else:\n",
    "            return \"Yes\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"\n",
    "\n",
    "# نحدد الصفوف الفاضية فقط\n",
    "rows_to_process = file_brave3[file_brave3[\"need_script\"].isna()].head(10)\n",
    "\n",
    "# نعالج على دفعات بطيئة عشان ما ينحظر\n",
    "for idx, row in rows_to_process.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = judge_with_llm(\n",
    "        row[\"ground_truth\"], row[\"answer_brave\"], row[\"brave_sinp\"]\n",
    "    )\n",
    "    time.sleep(20)  # نرتاح 20 ثانية بين كل طلب\n",
    "\n",
    "# حفظ التحديث\n",
    "file_brave3.to_excel(file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث الملف: تمت معالجة {len(rows_to_process)} صفوف جديدة فقط\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1cf0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_brave3[\"need_script\"] = None  # إعادة التعيين\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374ed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تحديث الملف: تمت معالجة 0 صفوف\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "# تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# لو العمود مو موجود نضيفه بنوع نصي\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = pd.Series([None] * len(file_brave3), dtype=\"object\")\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# تهيئة OpenAI Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# دالة: تستخدم LLM للتحقق من وجود Ground Truth داخل Snippet\n",
    "def check_with_llm(gt, snip):\n",
    "    prompt = f\"\"\"\n",
    "You are an assistant. Check if the Ground Truth is present in the Snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if Ground Truth is NOT present in Snippet (script needed), or \"No\" if it IS present (script not needed).\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        decision = response.choices[0].message.content.strip()\n",
    "        # تنظيف الرد، تأكد يكون Yes أو No فقط\n",
    "        if \"yes\" in decision.lower():\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # افتراضياً نعتبر محتاج سكربت لو فيه خطأ\n",
    "\n",
    "# نأخذ الصفوف غير المعالجة\n",
    "rows_to_process = file_brave3[file_brave3[\"need_script\"].isna()]\n",
    "\n",
    "# نطبق التقييم باستخدام LLM\n",
    "for idx, row in rows_to_process.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = check_with_llm(\n",
    "        row[\"ground_truth\"], row[\"brave_sinp\"]\n",
    "    )\n",
    "    time.sleep(20)  # وقت انتظار لتجنب الحظر\n",
    "\n",
    "# نحفظ الملف بعد التحديث\n",
    "file_brave3.to_excel(file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث الملف: تمت معالجة {len(rows_to_process)} صفوف\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd8a13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أسماء الأعمدة في الملف:\n",
      "['e', 'answer_brave', 'ground_truth', 'brave_source', 'brave_sinp', 'subject', 'verdict', 'error_type', 'explanation', 'reasoning', 'pass_bool', 'url', 'links', 'need_script']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_with_need_script_sample.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "print(\"أسماء الأعمدة في الملف:\")\n",
    "print(file_brave3.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b23aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تحديث need_script لجميع الصفوف وحفظ الملف الجديد: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_with_need_script_sample_updated.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# إعادة تعيين العمود need_script ليكون فارغ\n",
    "file_brave3[\"need_script\"] = None\n",
    "\n",
    "# دالة نصية بسيطة للتحقق\n",
    "def check_ground_in_snippet(gt, snip):\n",
    "    if pd.isna(gt) or pd.isna(snip):\n",
    "        return \"Yes\"  # لو فارغ، نعتبر نحتاج سكربت\n",
    "    return \"No\" if str(gt).strip() in str(snip) else \"Yes\"\n",
    "\n",
    "# معالجة كل الصفوف\n",
    "for idx, row in file_brave3.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = check_ground_in_snippet(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "\n",
    "# حفظ الملف\n",
    "new_file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_with_need_script_sample_updated.xlsx\"\n",
    "file_brave3.to_excel(new_file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف وحفظ الملف الجديد: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b2003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تحديث 240 صفوف\n"
     ]
    }
   ],
   "source": [
    "updated_count = file_brave3[\"need_script\"].notna().sum()\n",
    "print(f\"✅ تم تحديث {updated_count} صفوف\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02386dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from accelerate) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from accelerate) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
      "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from ipywidgets) (9.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.2 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 2.8 MB/s  0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   ---------------------------------------- 3/3 [ipywidgets]\n",
      "\n",
      "Successfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Access is denied.\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2a7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# ========================\n",
    "# تجاهل كل التحذيرات\n",
    "# ========================\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "\n",
    "# ========================\n",
    "# تحميل الملف\n",
    "# ========================\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# ========================\n",
    "# تهيئة مودل صغير للـ CPU\n",
    "# ========================\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"  # مودل خفيف جدًا على CPU\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map={\"\": \"cpu\"},\n",
    "    dtype=torch.float16\n",
    ")\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# ========================\n",
    "# دالة سريعة للتحقق من need_script\n",
    "# ========================\n",
    "def fast_check_need_script(row):\n",
    "    gt = row[\"ground_truth\"]\n",
    "    snip = row[\"brave_sinp\"]\n",
    "    prompt = (\n",
    "        f\"Ground Truth: {gt}\\n\"\n",
    "        f\"Snippet: {snip}\\n\"\n",
    "        \"Answer only 'Yes' if Ground Truth is NOT present (script needed), or 'No' if it IS present.\"\n",
    "    )\n",
    "    try:\n",
    "        # max_new_tokens صغير جدًا لتسريع التقييم\n",
    "        result = generator(\n",
    "            prompt,\n",
    "            max_new_tokens=10,  # توليد قصير جداً لتسريع التنفيذ\n",
    "            truncation=True,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id  # لتجنب التحذيرات\n",
    "        )[0]['generated_text']\n",
    "\n",
    "        return \"Yes\" if \"yes\" in result.lower() else \"No\"\n",
    "    except:\n",
    "        return \"Yes\"  # افتراضياً نعتبر محتاج سكربت لو حدث خطأ\n",
    "\n",
    "# ========================\n",
    "# تطبيق على كل الصفوف\n",
    "# ========================\n",
    "file_brave3[\"need_script\"] = file_brave3.apply(fast_check_need_script, axis=1)\n",
    "\n",
    "# ========================\n",
    "# حفظ الملف بعد التحديث\n",
    "# ========================\n",
    "updated_file_path = file_path.replace(\".xlsx\", \"_fast_no_warnings.xlsx\")\n",
    "file_brave3.to_excel(updated_file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف بسرعة عالية بدون أي تحذيرات\\nالملف الجديد: {updated_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ab780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a306136f9b49c98d34a75167edd72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56f069fde6441bda0406bac1d790406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00006.safetensors:   0%|          | 21.0M/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db317e8a27674d2ab4fb2e05c10eafbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00006.safetensors:   1%|1         | 62.9M/4.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9be3c4489f44535966c85213d84fc7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00006.safetensors:   1%|1         | 52.4M/4.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885c544ba33c44c78aa3790fe5fe528c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00006.safetensors:   2%|1         | 83.9M/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4d4453864e484c9b59e885d61a24df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00006.safetensors:   1%|          | 31.5M/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f2bb724ff24b1da655188e556b2c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00006.safetensors:   0%|          | 10.5M/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# ========================\n",
    "# تجاهل كل التحذيرات\n",
    "# ========================\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "\n",
    "# ========================\n",
    "# تحميل الملف\n",
    "# ========================\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# ========================\n",
    "# تهيئة مودل Phi-4\n",
    "# ========================\n",
    "model_name = \"microsoft/phi-4\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map={\"\": \"cpu\"},\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# ========================\n",
    "# دالة سريعة للتحقق من need_script\n",
    "# ========================\n",
    "def fast_check_need_script(row):\n",
    "    gt = row[\"ground_truth\"]\n",
    "    snip = row[\"brave_sinp\"]\n",
    "    prompt = (\n",
    "        f\"Ground Truth: {gt}\\n\"\n",
    "        f\"Snippet: {snip}\\n\"\n",
    "        \"Answer only 'Yes' if Ground Truth is NOT present (script needed), or 'No' if it IS present.\"\n",
    "    )\n",
    "    try:\n",
    "        # max_new_tokens صغير جدًا لتسريع التقييم\n",
    "        result = generator(\n",
    "            prompt,\n",
    "            max_new_tokens=10,  # توليد قصير جداً لتسريع التنفيذ\n",
    "            truncation=True,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id  # لتجنب التحذيرات\n",
    "        )[0]['generated_text']\n",
    "\n",
    "        return \"Yes\" if \"yes\" in result.lower() else \"No\"\n",
    "    except:\n",
    "        return \"Yes\"  # افتراضياً نعتبر محتاج سكربت لو حدث خطأ\n",
    "\n",
    "# ========================\n",
    "# تطبيق على كل الصفوف\n",
    "# ========================\n",
    "file_brave3[\"need_script\"] = file_brave3.apply(fast_check_need_script, axis=1)\n",
    "\n",
    "# ========================\n",
    "# حفظ الملف بعد التحديث\n",
    "# ========================\n",
    "updated_file_path = file_path.replace(\".xlsx\", \"_phi4_no_warnings.xlsx\")\n",
    "file_brave3.to_excel(updated_file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف بسرعة عالية بدون أي تحذيرات\\nالملف الجديد: {updated_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e82ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hf_xet in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (1.1.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hf_xet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d529c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15ec6c23a66440e9819e75b0246f5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585bceadd8e54b94bddd36c63a4200f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00006.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8991832809b477eb563c966dc97fc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00006.safetensors:   0%|          | 0.00/4.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3649774f684f91b9d09895deea79e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00006.safetensors:   0%|          | 0.00/4.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47cfbd297424412088ee84cb80b1ed38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00006.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdd101da1f646b8b2922df685a8272a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00006.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa550daa2ef74b66960b10202b0ea826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00006.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# ========================\n",
    "# تجاهل كل التحذيرات\n",
    "# ========================\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "\n",
    "# ========================\n",
    "# تحميل الملف\n",
    "# ========================\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# ========================\n",
    "# تهيئة مودل Phi-4\n",
    "# ========================\n",
    "model_name = \"microsoft/phi-4\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map={\"\": \"cpu\"},\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# ========================\n",
    "# دالة سريعة للتحقق من need_script\n",
    "# ========================\n",
    "def fast_check_need_script(row):\n",
    "    gt = row[\"ground_truth\"]\n",
    "    snip = row[\"brave_sinp\"]\n",
    "    prompt = (\n",
    "        f\"Ground Truth: {gt}\\n\"\n",
    "        f\"Snippet: {snip}\\n\"\n",
    "        \"Answer only 'Yes' if Ground Truth is NOT present (script needed), or 'No' if it IS present.\"\n",
    "    )\n",
    "    try:\n",
    "        # max_new_tokens صغير جدًا لتسريع التقييم\n",
    "        result = generator(\n",
    "            prompt,\n",
    "            max_new_tokens=10,  # توليد قصير جداً لتسريع التنفيذ\n",
    "            truncation=True,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id  # لتجنب التحذيرات\n",
    "        )[0]['generated_text']\n",
    "\n",
    "        return \"Yes\" if \"yes\" in result.lower() else \"No\"\n",
    "    except:\n",
    "        return \"Yes\"  # افتراضياً نعتبر محتاج سكربت لو حدث خطأ\n",
    "\n",
    "# ========================\n",
    "# تطبيق على كل الصفوف\n",
    "# ========================\n",
    "file_brave3[\"need_script\"] = file_brave3.apply(fast_check_need_script, axis=1)\n",
    "\n",
    "# ========================\n",
    "# حفظ الملف بعد التحديث\n",
    "# ========================\n",
    "updated_file_path = file_path.replace(\".xlsx\", \"_phi4_no_warnings.xlsx\")\n",
    "file_brave3.to_excel(updated_file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف بسرعة عالية بدون أي تحذيرات\\nالملف الجديد: {updated_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f0436",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2b.\n401 Client Error. (Request ID: Root=1-68d51ea6-1c48db3c7a1d4070209c347b;a83bf9b5-c268-4d3c-b327-110d0568c8e5)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2b/resolve/main/config.json.\nAccess to model google/gemma-2b is restricted. You must have access to it and be authenticated to access it. Please log in.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/google/gemma-2b/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mGatedRepoError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:478\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1117\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1658\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1655\u001b[39m ):\n\u001b[32m   1656\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1657\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1658\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1659\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1660\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1545\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:310\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    309\u001b[39m response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(\u001b[32m429\u001b[39m,))\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:426\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    423\u001b[39m     message = (\n\u001b[32m    424\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    425\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_message == \u001b[33m\"\u001b[39m\u001b[33mAccess to this resource is disabled.\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mGatedRepoError\u001b[39m: 401 Client Error. (Request ID: Root=1-68d51ea6-1c48db3c7a1d4070209c347b;a83bf9b5-c268-4d3c-b327-110d0568c8e5)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2b/resolve/main/config.json.\nAccess to model google/gemma-2b is restricted. You must have access to it and be authenticated to access it. Please log in.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# تحميل الموديل والـ tokenizer\u001b[39;00m\n\u001b[32m      4\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mgoogle/gemma-2b\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m model = AutoModelForCausalLM.from_pretrained(model_name)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# تهيئة الـ pipeline\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:1078\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1076\u001b[39m         config = AutoConfig.for_model(**config_dict)\n\u001b[32m   1077\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m         config = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m config_tokenizer_class = config.tokenizer_class\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoTokenizer\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config.auto_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1288\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1285\u001b[39m trust_remote_code = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1286\u001b[39m code_revision = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1288\u001b[39m config_dict, unused_kwargs = \u001b[43mPretrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1289\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1290\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:662\u001b[39m, in \u001b[36mPretrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    660\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    661\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    664\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:721\u001b[39m, in \u001b[36mPretrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    717\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    720\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m721\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:321\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    264\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    265\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    266\u001b[39m     **kwargs,\n\u001b[32m    267\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    270\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:542\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    540\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[32m    541\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m542\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    543\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMake sure to have access to it at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    544\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    545\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, LocalEntryNotFoundError):\n\u001b[32m    547\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n",
      "\u001b[31mOSError\u001b[39m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2b.\n401 Client Error. (Request ID: Root=1-68d51ea6-1c48db3c7a1d4070209c347b;a83bf9b5-c268-4d3c-b327-110d0568c8e5)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2b/resolve/main/config.json.\nAccess to model google/gemma-2b is restricted. You must have access to it and be authenticated to access it. Please log in."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# تحميل الموديل والـ tokenizer\n",
    "model_name = \"google/gemma-2b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# تهيئة الـ pipeline\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# دالة لتحديد الحاجة إلى سكربت\n",
    "def check_need_script(ground_truth, snippet):\n",
    "    prompt = f\"هل يحتاج السكربت التالي إلى سكربت؟\\n\\n{snippet}\\n\\nالجواب بـ 'نعم' أو 'لا'.\"\n",
    "    result = generator(prompt, max_new_tokens=10)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "# اختبار الدالة\n",
    "ground_truth = \"...\"\n",
    "snippet = \"...\"\n",
    "print(check_need_script(ground_truth, snippet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af43295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (0.34.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->huggingface_hub) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->huggingface_hub) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef16f5ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "TheBloke/phi-1_5-7b is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/TheBloke/phi-1_5-7b/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:478\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1117\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1658\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1655\u001b[39m ):\n\u001b[32m   1656\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1657\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1658\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1659\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1660\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1545\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:310\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    309\u001b[39m response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(\u001b[32m429\u001b[39m,))\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:459\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    450\u001b[39m     message = (\n\u001b[32m    451\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    452\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m400\u001b[39m:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m: 401 Client Error. (Request ID: Root=1-68d51ef7-2def24795660dea4568566c6;f9ebb90a-6217-4727-b781-eb93425f4635)\n\nRepository Not Found for url: https://huggingface.co/TheBloke/phi-1_5-7b/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# تهيئة الموديل المفتوح المصدر Phi\u001b[39;00m\n\u001b[32m     21\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mTheBloke/phi-1_5-7b\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m model = AutoModelForCausalLM.from_pretrained(\n\u001b[32m     24\u001b[39m     model_name,\n\u001b[32m     25\u001b[39m     device_map=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m     torch_dtype=torch.float16\n\u001b[32m     27\u001b[39m )\n\u001b[32m     28\u001b[39m generator = pipeline(\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=model, tokenizer=tokenizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:1058\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n\u001b[32m   1057\u001b[39m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m tokenizer_config = \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[32m   1060\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = tokenizer_config[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:890\u001b[39m, in \u001b[36mget_tokenizer_config\u001b[39m\u001b[34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[39m\n\u001b[32m    887\u001b[39m     token = use_auth_token\n\u001b[32m    889\u001b[39m commit_hash = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    907\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:321\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    264\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    265\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    266\u001b[39m     **kwargs,\n\u001b[32m    267\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    270\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:510\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    508\u001b[39m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    511\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a local folder and is not a valid model identifier \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    512\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlisted on \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/models\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhaving permission to this repo either by logging in with `hf auth login` or by passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`token=<your_token>`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RevisionNotFoundError):\n\u001b[32m    517\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    518\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    519\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfor this model name. Check the model page at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    520\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m for available revisions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    521\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: TheBloke/phi-1_5-7b is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# تجاهل التحذيرات\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# تهيئة الموديل المفتوح المصدر Phi\n",
    "model_name = \"TheBloke/phi-1_5-7b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# دالة لتحديد need_script\n",
    "def check_with_phi(gt, snip):\n",
    "    prompt = f\"\"\"\n",
    "Check if the Ground Truth is present in the Snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if Ground Truth is NOT present (script needed), or \"No\" if it IS present (script not needed).\n",
    "\"\"\"\n",
    "    try:\n",
    "        result = generator(prompt, max_new_tokens=50, do_sample=False)[0]['generated_text']\n",
    "        if \"yes\" in result.lower():\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # إذا حدث خطأ نعتبر محتاج سكربت\n",
    "\n",
    "# إعادة حساب need_script لكل الصفوف\n",
    "for idx, row in file_brave3.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = check_with_phi(\n",
    "        row[\"ground_truth\"], row[\"brave_sinp\"]\n",
    "    )\n",
    "    time.sleep(1)  # لتخفيف الحمل على الموديل\n",
    "\n",
    "# حفظ الملف بعد التحديث\n",
    "file_brave3.to_excel(file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف باستخدام موديل Phi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbf38a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "TheBloke/phi-1_5-7b is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 404 Client Error: Not Found for url: https://huggingface.co/TheBloke/phi-1_5-7b/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:478\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1117\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1658\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1655\u001b[39m ):\n\u001b[32m   1656\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1657\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1658\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1659\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1660\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1545\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:310\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    309\u001b[39m response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(\u001b[32m429\u001b[39m,))\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:459\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    450\u001b[39m     message = (\n\u001b[32m    451\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    452\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m400\u001b[39m:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m: 404 Client Error. (Request ID: Root=1-68d521d8-656db797595cee0345238891;5d45da54-a78c-4d3b-b6aa-ad8a75a18feb)\n\nRepository Not Found for url: https://huggingface.co/TheBloke/phi-1_5-7b/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 3️⃣ تحميل موديل Phi\u001b[39;00m\n\u001b[32m     28\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mTheBloke/phi-1_5-7b\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m model = AutoModelForCausalLM.from_pretrained(\n\u001b[32m     32\u001b[39m     model_name,\n\u001b[32m     33\u001b[39m     device_map=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,        \u001b[38;5;66;03m# استخدام كل ال GPUs أو CPU\u001b[39;00m\n\u001b[32m     34\u001b[39m     torch_dtype=torch.float16,\n\u001b[32m     35\u001b[39m     use_auth_token=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     36\u001b[39m )\n\u001b[32m     38\u001b[39m generator = pipeline(\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=model, tokenizer=tokenizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:1058\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n\u001b[32m   1057\u001b[39m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m tokenizer_config = \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[32m   1060\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = tokenizer_config[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:890\u001b[39m, in \u001b[36mget_tokenizer_config\u001b[39m\u001b[34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[39m\n\u001b[32m    887\u001b[39m     token = use_auth_token\n\u001b[32m    889\u001b[39m commit_hash = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    907\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:321\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    264\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    265\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    266\u001b[39m     **kwargs,\n\u001b[32m    267\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    270\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:510\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    508\u001b[39m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    511\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a local folder and is not a valid model identifier \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    512\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlisted on \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/models\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhaving permission to this repo either by logging in with `hf auth login` or by passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`token=<your_token>`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RevisionNotFoundError):\n\u001b[32m    517\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    518\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    519\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfor this model name. Check the model page at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    520\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m for available revisions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    521\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: TheBloke/phi-1_5-7b is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "\n",
    "# ---------------------------\n",
    "# 1️⃣ تسجيل الدخول بتوكن Hugging Face\n",
    "# ضع التوكن الخاص بك هنا\n",
    "model_name = \"https://huggingface.co/microsoft/Phi-3-mini-4k-instruct\"\n",
    "login(token=\"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\")\n",
    "# ---------------------------\n",
    "\n",
    "# ---------------------------\n",
    "# 2️⃣ تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "# ---------------------------\n",
    "\n",
    "# ---------------------------\n",
    "# 3️⃣ تحميل موديل Phi\n",
    "model_name = \"TheBloke/phi-1_5-7b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",        # استخدام كل ال GPUs أو CPU\n",
    "    torch_dtype=torch.float16,\n",
    "    use_auth_token=True\n",
    ")\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "# ---------------------------\n",
    "\n",
    "# ---------------------------\n",
    "# 4️⃣ دالة لتحديد need_script\n",
    "def check_with_llm(gt, snip):\n",
    "    prompt = f\"\"\"\n",
    "Check if the Ground Truth is present in the Snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if Ground Truth is NOT present (script needed), or \"No\" if it IS present (script not needed).\n",
    "\"\"\"\n",
    "    try:\n",
    "        result = generator(prompt, max_new_tokens=50, do_sample=False)[0]['generated_text']\n",
    "        if \"yes\" in result.lower():\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"\n",
    "# ---------------------------\n",
    "\n",
    "# ---------------------------\n",
    "# 5️⃣ تطبيق على كل الصفوف\n",
    "for idx, row in file_brave3.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = check_with_llm(\n",
    "        row[\"ground_truth\"], row[\"brave_sinp\"]\n",
    "    )\n",
    "    time.sleep(2)  # تخفيف الضغط على الموديل\n",
    "\n",
    "# حفظ الملف بعد التحديث\n",
    "file_brave3.to_excel(file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف باستخدام موديل Phi\")\n",
    "# ---------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ac29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c9f30370e14da4b0e40c558345f7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb6500358fe43d0926ceb8d0cefd197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbc5314403e42a68d7215d3d32d4a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc53aeb90f484b6d8229d8a4d61343a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff365879a38c43609c2ab3959fd41821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3fab8d837a4fb8bf33e278e515cff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f0dd6d36334c8c954eaf9c3d42ef61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1042c2aa2948c1a5579629470c98e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d302b4364f64949ab47a6ab16902cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1298c66629a7451997b3b466c92277ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22f60444c0b4392ae2c85384a7780aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a688de5008449dab83d261acf680af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9137079b1b6425ca4559e8775796046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96dfad030b66436ba1d8558b758d0713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6131 > 4096). Running this sequence through the model will result in indexing errors\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تحديث need_script لجميع الصفوف باستخدام Phi-3-mini\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import pipeline\n",
    "\n",
    "# تحميل ملف Excel\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# إعداد الـ pipeline مع موديل Phi-3-mini\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# دالة لتحديد need_script باستخدام pipeline الجديد\n",
    "def check_with_llm(gt, snip):\n",
    "    prompt = f\"\"\"\n",
    "Check if the Ground Truth is present in the Snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if Ground Truth is NOT present (script needed), or \"No\" if it IS present (script not needed).\n",
    "\"\"\"\n",
    "    try:\n",
    "        # استخدم pipe بدل generator\n",
    "        result = pipe(prompt, max_new_tokens=50, do_sample=False)[0]['generated_text']\n",
    "        if \"yes\" in result.lower():\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "    except:\n",
    "        return \"Yes\"  # افتراضياً محتاج سكربت عند الخطأ\n",
    "\n",
    "# تطبيق على كل الصفوف\n",
    "for idx, row in file_brave3.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = check_with_llm(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    time.sleep(1)  # لتخفيف الحمل\n",
    "\n",
    "# حفظ الملف بعد التحديث\n",
    "file_brave3.to_excel(file_path, index=False)\n",
    "print(\"✅ تم تحديث need_script لجميع الصفوف باستخدام Phi-3-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e328e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26bd39a740e45969d87b79312f1049c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m file_brave3.iterrows():\n\u001b[32m     58\u001b[39m     file_brave3.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = check_with_phi(row[\u001b[33m\"\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m\"\u001b[39m], row[\u001b[33m\"\u001b[39m\u001b[33mbrave_sinp\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# لتخفيف الحمل على المودل\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# حفظ الملف بعد التحديث باسم نسخة ثالثة\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     64\u001b[39m third_file_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSarahAlqahtani\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbrave_sec_t2_with_script_copy3.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف الأصلي\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# -------------------------\n",
    "# تهيئة المودل والمُرمّز\n",
    "# -------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")  # تشغيل على CPU\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق من need_script\n",
    "# -------------------------\n",
    "def check_with_phi(gt, snip):\n",
    "    prompt_text = f\"Ground Truth:\\n{gt}\\n\\nSnippet:\\n{snip}\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"\n",
    "    \n",
    "    try:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True  # يقتصر على طول المودل\n",
    "        ).to(model.device)\n",
    "\n",
    "        outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "        answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "        \n",
    "        if \"yes\" in answer.lower():\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # افتراضياً محتاج سكربت لو صار خطأ\n",
    "\n",
    "# -------------------------\n",
    "# معالجة كل الصفوف\n",
    "# -------------------------\n",
    "for idx, row in file_brave3.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = check_with_phi(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    time.sleep(1)  # لتخفيف الحمل على المودل\n",
    "\n",
    "# -------------------------\n",
    "# حفظ الملف بعد التحديث باسم نسخة ثالثة\n",
    "# -------------------------\n",
    "third_file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_copy3.xlsx\"\n",
    "file_brave3.to_excel(third_file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف وحفظ نسخة ثالثة: {third_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab90dc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b191978b9cd49d4aa83c1689cde7521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم معالجة الصفوف 1 إلى 5\n",
      "✅ تم معالجة الصفوف 6 إلى 10\n",
      "✅ تم معالجة الصفوف 11 إلى 15\n",
      "✅ تم معالجة الصفوف 16 إلى 20\n",
      "✅ تم معالجة الصفوف 21 إلى 25\n",
      "✅ تم معالجة الصفوف 26 إلى 30\n",
      "✅ تم معالجة الصفوف 31 إلى 35\n",
      "✅ تم معالجة الصفوف 36 إلى 40\n",
      "✅ تم معالجة الصفوف 41 إلى 45\n",
      "✅ تم معالجة الصفوف 46 إلى 50\n",
      "✅ تم معالجة الصفوف 51 إلى 55\n",
      "✅ تم معالجة الصفوف 56 إلى 60\n",
      "✅ تم معالجة الصفوف 61 إلى 65\n",
      "✅ تم معالجة الصفوف 66 إلى 70\n",
      "✅ تم معالجة الصفوف 71 إلى 75\n",
      "✅ تم معالجة الصفوف 76 إلى 80\n",
      "✅ تم معالجة الصفوف 81 إلى 85\n",
      "✅ تم معالجة الصفوف 86 إلى 90\n",
      "✅ تم معالجة الصفوف 91 إلى 95\n",
      "✅ تم معالجة الصفوف 96 إلى 100\n",
      "✅ تم معالجة الصفوف 101 إلى 105\n",
      "✅ تم معالجة الصفوف 106 إلى 110\n",
      "✅ تم معالجة الصفوف 111 إلى 115\n",
      "✅ تم معالجة الصفوف 116 إلى 120\n",
      "✅ تم معالجة الصفوف 121 إلى 125\n",
      "✅ تم معالجة الصفوف 126 إلى 130\n",
      "✅ تم معالجة الصفوف 131 إلى 135\n",
      "✅ تم معالجة الصفوف 136 إلى 140\n",
      "✅ تم معالجة الصفوف 141 إلى 145\n",
      "✅ تم معالجة الصفوف 146 إلى 150\n",
      "✅ تم معالجة الصفوف 151 إلى 155\n",
      "✅ تم معالجة الصفوف 156 إلى 160\n",
      "✅ تم معالجة الصفوف 161 إلى 165\n",
      "✅ تم معالجة الصفوف 166 إلى 170\n",
      "✅ تم معالجة الصفوف 171 إلى 175\n",
      "✅ تم معالجة الصفوف 176 إلى 180\n",
      "✅ تم معالجة الصفوف 181 إلى 185\n",
      "✅ تم معالجة الصفوف 186 إلى 190\n",
      "✅ تم معالجة الصفوف 191 إلى 195\n",
      "✅ تم معالجة الصفوف 196 إلى 200\n",
      "✅ تم معالجة الصفوف 201 إلى 205\n",
      "✅ تم معالجة الصفوف 206 إلى 210\n",
      "✅ تم معالجة الصفوف 211 إلى 215\n",
      "✅ تم معالجة الصفوف 216 إلى 220\n",
      "✅ تم معالجة الصفوف 221 إلى 225\n",
      "✅ تم معالجة الصفوف 226 إلى 230\n",
      "✅ تم معالجة الصفوف 231 إلى 235\n",
      "✅ تم معالجة الصفوف 236 إلى 240\n",
      "✅ تم تحديث need_script لجميع الصفوف وحفظ نسخة ثالثة: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_copy3.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# -------------------------\n",
    "# تجاهل تحذيرات Transformers\n",
    "# -------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف الأصلي\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# -------------------------\n",
    "# تهيئة المودل والمُرمّز\n",
    "# -------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")  # تشغيل على CPU\n",
    "\n",
    "MAX_INPUT_TOKENS = 4000  # تقطيع النصوص الطويلة\n",
    "BATCH_SIZE = 5  # معالجة 5 صفوف في كل batch\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق من need_script لدفعة من الصفوف\n",
    "# -------------------------\n",
    "def check_batch(batch_rows):\n",
    "    answers = []\n",
    "    for row in batch_rows:\n",
    "        try:\n",
    "            snippet_tokens = tokenizer.encode(row[\"brave_sinp\"])\n",
    "            parts = [snippet_tokens[i:i+MAX_INPUT_TOKENS] for i in range(0, len(snippet_tokens), MAX_INPUT_TOKENS)]\n",
    "            answer = \"No\"\n",
    "            for part in parts:\n",
    "                prompt_text = f\"Ground Truth:\\n{row['ground_truth']}\\n\\nSnippet:\\n{tokenizer.decode(part)}\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"\n",
    "                messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "                inputs = tokenizer.apply_chat_template(\n",
    "                    messages,\n",
    "                    add_generation_prompt=True,\n",
    "                    tokenize=True,\n",
    "                    return_dict=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True\n",
    "                ).to(model.device)\n",
    "                outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "                part_answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "                if \"yes\" in part_answer.lower():\n",
    "                    answer = \"Yes\"\n",
    "                    break\n",
    "            answers.append(answer)\n",
    "        except Exception:\n",
    "            answers.append(\"Yes\")\n",
    "    return answers\n",
    "\n",
    "# -------------------------\n",
    "# معالجة الصفوف على دفعات\n",
    "# -------------------------\n",
    "total_rows = len(file_brave3)\n",
    "for start_idx in range(0, total_rows, BATCH_SIZE):\n",
    "    end_idx = min(start_idx + BATCH_SIZE, total_rows)\n",
    "    batch_rows = file_brave3.iloc[start_idx:end_idx]\n",
    "    batch_answers = check_batch(batch_rows.to_dict('records'))\n",
    "    file_brave3.loc[start_idx:end_idx-1, \"need_script\"] = batch_answers\n",
    "    print(f\"✅ تم معالجة الصفوف {start_idx+1} إلى {end_idx}\")\n",
    "    time.sleep(1)  # لتخفيف الحمل على المودل\n",
    "\n",
    "# -------------------------\n",
    "# حفظ الملف بعد التحديث باسم نسخة ثالثة\n",
    "# -------------------------\n",
    "third_file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_copy3.xlsx\"\n",
    "file_brave3.to_excel(third_file_path, index=False)\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف وحفظ نسخة ثالثة: {third_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2e525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b987cdee0644650b5fc1ed840cebf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 1 إلى 5\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     70\u001b[39m     ans = check_with_phi(row[\u001b[33m\"\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m\"\u001b[39m], row[\u001b[33m\"\u001b[39m\u001b[33mbrave_sinp\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     71\u001b[39m     batch_answers.append(ans)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     time.sleep(\u001b[32m0.5\u001b[39m)  \u001b[38;5;66;03m# لتخفيف الحمل\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# تحديث العمود بشكل مؤكد\u001b[39;00m\n\u001b[32m     75\u001b[39m file_brave3.loc[start_idx:end_idx-\u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = batch_answers\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف الأصلي\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# إعادة ضبط الـ index لتجنب مشاكل تحديث العمود\n",
    "file_brave3 = file_brave3.reset_index(drop=True)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# -------------------------\n",
    "# تهيئة المودل والمُرمّز\n",
    "# -------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")  # تشغيل على CPU\n",
    "\n",
    "MAX_INPUT_TOKENS = 4000  # لتجنب تجاوز طول المودل\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق من need_script مع تقسيم النصوص الطويلة\n",
    "# -------------------------\n",
    "def check_with_phi(gt, snip):\n",
    "    prompt_text = f\"Ground Truth:\\n{gt}\\n\\nSnippet:\\n{snip}\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"\n",
    "    try:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True\n",
    "        ).to(model.device)\n",
    "\n",
    "        outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "        answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "        \n",
    "        if \"yes\" in answer.lower():\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # افتراضياً محتاج سكربت لو صار خطأ\n",
    "\n",
    "# -------------------------\n",
    "# معالجة كل الصفوف على دفعات صغيرة\n",
    "# -------------------------\n",
    "BATCH_SIZE = 5  # عدد الصفوف في كل batch لتخفيف الحمل\n",
    "\n",
    "total_rows = len(file_brave3)\n",
    "for start_idx in range(0, total_rows, BATCH_SIZE):\n",
    "    end_idx = min(start_idx + BATCH_SIZE, total_rows)\n",
    "    batch_rows = file_brave3.iloc[start_idx:end_idx]\n",
    "\n",
    "    batch_answers = []\n",
    "    for _, row in batch_rows.iterrows():\n",
    "        ans = check_with_phi(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "        batch_answers.append(ans)\n",
    "        time.sleep(0.5)  # لتخفيف الحمل\n",
    "\n",
    "    # تحديث العمود بشكل مؤكد\n",
    "    file_brave3.loc[start_idx:end_idx-1, \"need_script\"] = batch_answers\n",
    "    print(f\"✅ تم معالجة الصفوف {start_idx+1} إلى {end_idx}\")\n",
    "\n",
    "# -------------------------\n",
    "# حفظ الملف بعد التحديث باسم نسخة ثالثة\n",
    "# -------------------------\n",
    "third_file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_copy3.xlsx\"\n",
    "file_brave3.to_excel(third_file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف وحفظ نسخة ثالثة: {third_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4108e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22595cb7535e4d3ba900f7801871af72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم معالجة الصفوف 1 إلى 5\n",
      "✅ تم معالجة الصفوف 6 إلى 10\n",
      "✅ تم معالجة الصفوف 11 إلى 15\n",
      "✅ تم معالجة الصفوف 16 إلى 20\n",
      "✅ تم معالجة الصفوف 21 إلى 25\n",
      "✅ تم معالجة الصفوف 26 إلى 30\n",
      "✅ تم معالجة الصفوف 31 إلى 35\n",
      "✅ تم معالجة الصفوف 36 إلى 40\n",
      "✅ تم معالجة الصفوف 41 إلى 45\n",
      "✅ تم معالجة الصفوف 46 إلى 50\n",
      "✅ تم معالجة الصفوف 51 إلى 55\n",
      "✅ تم معالجة الصفوف 56 إلى 60\n",
      "✅ تم معالجة الصفوف 61 إلى 65\n",
      "✅ تم معالجة الصفوف 66 إلى 70\n",
      "✅ تم معالجة الصفوف 71 إلى 75\n",
      "✅ تم معالجة الصفوف 76 إلى 80\n",
      "✅ تم معالجة الصفوف 81 إلى 85\n",
      "✅ تم معالجة الصفوف 86 إلى 90\n",
      "✅ تم معالجة الصفوف 91 إلى 95\n",
      "✅ تم معالجة الصفوف 96 إلى 100\n",
      "✅ تم معالجة الصفوف 101 إلى 105\n",
      "✅ تم معالجة الصفوف 106 إلى 110\n",
      "✅ تم معالجة الصفوف 111 إلى 115\n",
      "✅ تم معالجة الصفوف 116 إلى 120\n",
      "✅ تم معالجة الصفوف 121 إلى 125\n",
      "✅ تم معالجة الصفوف 126 إلى 130\n",
      "✅ تم معالجة الصفوف 131 إلى 135\n",
      "✅ تم معالجة الصفوف 136 إلى 140\n",
      "✅ تم معالجة الصفوف 141 إلى 145\n",
      "✅ تم معالجة الصفوف 146 إلى 150\n",
      "✅ تم معالجة الصفوف 151 إلى 155\n",
      "✅ تم معالجة الصفوف 156 إلى 160\n",
      "✅ تم معالجة الصفوف 161 إلى 165\n",
      "✅ تم معالجة الصفوف 166 إلى 170\n",
      "✅ تم معالجة الصفوف 171 إلى 175\n",
      "✅ تم معالجة الصفوف 176 إلى 180\n",
      "✅ تم معالجة الصفوف 181 إلى 185\n",
      "✅ تم معالجة الصفوف 186 إلى 190\n",
      "✅ تم معالجة الصفوف 191 إلى 195\n",
      "✅ تم معالجة الصفوف 196 إلى 200\n",
      "✅ تم معالجة الصفوف 201 إلى 205\n",
      "✅ تم معالجة الصفوف 206 إلى 210\n",
      "✅ تم معالجة الصفوف 211 إلى 215\n",
      "✅ تم معالجة الصفوف 216 إلى 220\n",
      "✅ تم معالجة الصفوف 221 إلى 225\n",
      "✅ تم معالجة الصفوف 226 إلى 230\n",
      "✅ تم معالجة الصفوف 231 إلى 235\n",
      "✅ تم معالجة الصفوف 236 إلى 240\n",
      "✅ تم تحديث need_script لجميع الصفوف وحفظ نسخة ثالثة: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_copy3_new.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف الأصلي\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# -------------------------\n",
    "# تهيئة المودل والمُرمّز\n",
    "# -------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")  # تشغيل على CPU\n",
    "model.eval()     # وضع المودل في evaluation mode لتجنب أي تحديثات\n",
    "\n",
    "MAX_INPUT_TOKENS = 4000\n",
    "BATCH_SIZE = 5  # يمكن تعديلها لتقليل الحمل\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق من need_script مع تجاهل تحذيرات DynamicCache\n",
    "# -------------------------\n",
    "def check_with_phi(gt, snip):\n",
    "    prompt_text = f\"Ground Truth:\\n{gt}\\n\\nSnippet:\\n{snip}\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"\n",
    "    \n",
    "    try:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.no_grad():  # لمنع أي تحديثات وحماية الذاكرة\n",
    "            outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "        \n",
    "        answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "        return \"Yes\" if \"yes\" in answer.lower() else \"No\"\n",
    "\n",
    "    except Exception:\n",
    "        # أي خطأ يعتبر \"Yes\" افتراضيًا\n",
    "        return \"Yes\"\n",
    "\n",
    "# -------------------------\n",
    "# معالجة الصفوف دفعة بدفعة\n",
    "# -------------------------\n",
    "total_rows = len(file_brave3)\n",
    "for start_idx in range(0, total_rows, BATCH_SIZE):\n",
    "    end_idx = min(start_idx + BATCH_SIZE, total_rows)\n",
    "    for idx in range(start_idx, end_idx):\n",
    "        row = file_brave3.iloc[idx]\n",
    "        file_brave3.at[idx, \"need_script\"] = check_with_phi(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    print(f\"✅ تم معالجة الصفوف {start_idx + 1} إلى {end_idx}\")\n",
    "    time.sleep(1)  # لتخفيف الضغط على المودل\n",
    "\n",
    "# -------------------------\n",
    "# حفظ الملف بعد التحديث باسم نسخة ثالثة\n",
    "# -------------------------\n",
    "third_file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_copy3_new.xlsx\"\n",
    "file_brave3.to_excel(third_file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف وحفظ نسخة ثالثة: {third_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff4ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تحديث need_script لجميع الصفوف وحفظ نسخة ثالثة: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_copy4.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف الأصلي\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق النصي من need_script\n",
    "# -------------------------\n",
    "def check_ground_truth(gt, snip):\n",
    "    \"\"\"\n",
    "    تعطي 'No' إذا كان الـGround Truth موجود داخل الـSnippet\n",
    "    تعطي 'Yes' إذا لم يكن موجود\n",
    "    \"\"\"\n",
    "    return \"No\" if gt in snip else \"Yes\"\n",
    "\n",
    "# -------------------------\n",
    "# معالجة كل الصفوف\n",
    "# -------------------------\n",
    "for idx, row in file_brave3.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = check_ground_truth(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "\n",
    "# -------------------------\n",
    "# حفظ الملف بعد التحديث باسم نسخة ثالثة\n",
    "# -------------------------\n",
    "third_file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_copy4.xlsx\"\n",
    "file_brave3.to_excel(third_file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف وحفظ نسخة ثالثة: {third_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a58310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a782c925674e95a4b5beca91587fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تحديث need_script لجميع الصفوف باستخدام LLM وحفظ نسخة ثالثة: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_copy5.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف الأصلي\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "\n",
    "# -------------------------\n",
    "# تهيئة المودل والمُرمّز\n",
    "# -------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")  # أو \"cuda\" لو عندك GPU\n",
    "model.eval()\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق من need_script باستخدام LLM\n",
    "# -------------------------\n",
    "def check_with_phi(gt, snip):\n",
    "    prompt_text = f\"Ground Truth:\\n{gt}\\n\\nSnippet:\\n{snip}\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"\n",
    "    \n",
    "    try:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "        \n",
    "        answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "        return \"Yes\" if \"yes\" in answer.lower() else \"No\"\n",
    "\n",
    "    except Exception:\n",
    "        # أي خطأ يعتبر \"Yes\" افتراضيًا\n",
    "        return \"Yes\"\n",
    "\n",
    "# -------------------------\n",
    "# معالجة الصفوف\n",
    "# -------------------------\n",
    "for idx, row in file_brave3.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = check_with_phi(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    time.sleep(1)  # لتخفيف الضغط على المودل\n",
    "\n",
    "# -------------------------\n",
    "# حفظ الملف باسم نسخة ثالثة\n",
    "# -------------------------\n",
    "third_file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_copy5.xlsx\"\n",
    "file_brave3.to_excel(third_file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف باستخدام LLM وحفظ نسخة ثالثة: {third_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80201334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604d6f5dfdd8406e97a4b836ca0debea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 1 إلى 5\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 6 إلى 10\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 11 إلى 15\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 16 إلى 20\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 21 إلى 25\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 26 إلى 30\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 31 إلى 35\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 36 إلى 40\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 41 إلى 45\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 46 إلى 50\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 51 إلى 55\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 56 إلى 60\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 61 إلى 65\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 66 إلى 70\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 71 إلى 75\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 76 إلى 80\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 81 إلى 85\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 86 إلى 90\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 91 إلى 95\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 96 إلى 100\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 101 إلى 105\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 106 إلى 110\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 111 إلى 115\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 116 إلى 120\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 121 إلى 125\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 126 إلى 130\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 131 إلى 135\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 136 إلى 140\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 141 إلى 145\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 146 إلى 150\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 151 إلى 155\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 156 إلى 160\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 161 إلى 165\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 166 إلى 170\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 171 إلى 175\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 176 إلى 180\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 181 إلى 185\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 186 إلى 190\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 191 إلى 195\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 196 إلى 200\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 201 إلى 205\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 206 إلى 210\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 211 إلى 215\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 216 إلى 220\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 221 إلى 225\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 226 إلى 230\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 231 إلى 235\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "✅ تم معالجة الصفوف 236 إلى 240\n",
      "✅ تم تحديث need_script وحفظ النسخة: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_llm.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف الأصلي\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "\n",
    "# -------------------------\n",
    "# تهيئة المودل والمُرمّز\n",
    "# -------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")  # أو \"cuda\" لو عندك GPU\n",
    "model.eval()      # evaluation mode لتقليل الأخطاء\n",
    "\n",
    "MAX_INPUT_TOKENS = 4000  # الحد الأقصى للـtokens لكل استدعاء\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق من need_script باستخدام LLM\n",
    "# -------------------------\n",
    "def check_with_llm(gt, snip):\n",
    "    if pd.isna(gt) or pd.isna(snip):\n",
    "        print(\"hi\")\n",
    "        return \"True\"  # افتراضياً نحتاج سكربت إذا أي حقل فارغ\n",
    "\n",
    "    prompt_text = f\"Ground Truth:\\n{gt}\\n\\nSnippet:\\n{snip}\\n\\nAnswer ONLY with 'Yes' if Ground Truth is NOT present in the Snippet, or 'No' if it IS present.\"\n",
    "\n",
    "    try:\n",
    "        # تحويل النصوص لتوكنز مع القص إذا تجاوز الحد\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            [{\"role\": \"user\", \"content\": prompt_text}],\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=50\n",
    "            )\n",
    "\n",
    "        answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "        return \"Yes\" if \"yes\" in answer.lower() else \"No\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # افتراضياً لو صار أي خطأ\n",
    "\n",
    "# -------------------------\n",
    "# معالجة كل الصفوف\n",
    "# -------------------------\n",
    "BATCH_SIZE = 5  # لتخفيف الضغط على المودل\n",
    "total_rows = len(file_brave3)\n",
    "\n",
    "for start_idx in range(0, total_rows, BATCH_SIZE):\n",
    "    end_idx = min(start_idx + BATCH_SIZE, total_rows)\n",
    "    for idx in range(start_idx, end_idx):\n",
    "        row = file_brave3.iloc[idx]\n",
    "        file_brave3.at[idx, \"need_script\"] = check_with_llm(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    print(f\"✅ تم معالجة الصفوف {start_idx + 1} إلى {end_idx}\")\n",
    "    time.sleep(1)  # لتخفيف الحمل\n",
    "\n",
    "# -------------------------\n",
    "# حفظ النسخة الجديدة\n",
    "# -------------------------\n",
    "file_path_6 = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_llm.xlsx\"\n",
    "file_brave3.to_excel(file_path_6, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script وحفظ النسخة: {file_path_6}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eaee7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0b7f560a564a4b9c22cd245d784e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6104 > 4096). Running this sequence through the model will result in indexing errors\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mYes\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     58\u001b[39m         file_brave3.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = recheck_yes(row[\u001b[33m\"\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m\"\u001b[39m], row[\u001b[33m\"\u001b[39m\u001b[33mbrave_sinp\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     time.sleep(\u001b[32m1\u001b[39m)\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# حفظ نسخة جديدة من الملف\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     64\u001b[39m new_file_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSarahAlqahtani\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbrave_sec_t2_with_need_script_v6.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "# تجاهل التحذيرات\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف القديم\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# -------------------------\n",
    "# تهيئة المودل والمُرمّز\n",
    "# -------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")  # تشغيل على CPU\n",
    "\n",
    "MAX_TOKENS = 4000\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق من need_script مع تقسيم النصوص الطويلة\n",
    "# -------------------------\n",
    "def recheck_yes(gt, snip):\n",
    "    prompt_text = f\"Ground Truth:\\n{gt}\\n\\nSnippet:\\n{snip}\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"\n",
    "    \n",
    "    try:\n",
    "        input_ids = tokenizer(prompt_text, return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "        chunks = [input_ids[i:i+MAX_TOKENS] for i in range(0, len(input_ids), MAX_TOKENS)]\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            chunk = chunk.unsqueeze(0)\n",
    "            outputs = model.generate(chunk, max_new_tokens=50)\n",
    "            answer = tokenizer.decode(outputs[0][chunk.shape[-1]:])\n",
    "            if \"yes\" in answer.lower():\n",
    "                return \"Yes\"\n",
    "        return \"No\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"\n",
    "\n",
    "# -------------------------\n",
    "# إعادة معالجة كل الصفوف التي كانت Yes سابقًا\n",
    "# -------------------------\n",
    "for idx, row in file_brave3.iterrows():\n",
    "    if row[\"need_script\"] == \"Yes\":\n",
    "        file_brave3.at[idx, \"need_script\"] = recheck_yes(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    time.sleep(1)\n",
    "\n",
    "# -------------------------\n",
    "# حفظ نسخة جديدة من الملف\n",
    "# -------------------------\n",
    "new_file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_v6.xlsx\"\n",
    "file_brave3.to_excel(new_file_path, index=False)\n",
    "print(f\"✅ تم إعادة التحقق من 'Yes' وحفظ نسخة جديدة: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81018cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b42924b5d7f4129bb47e5162d8ce574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6047 > 4096). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n",
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n",
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n",
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n",
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n",
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n",
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m file_brave3.iterrows():\n\u001b[32m     70\u001b[39m     file_brave3.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = check_with_phi_split(row[\u001b[33m\"\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m\"\u001b[39m], row[\u001b[33m\"\u001b[39m\u001b[33mbrave_sinp\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# لتخفيف الحمل على المودل\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# حفظ نسخة جديدة من الملف باسم مختلف\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     76\u001b[39m new_file_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSarahAlqahtani\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbrave_sec_t2_with_need_script_split.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف الأصلي\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# -------------------------\n",
    "# التأكد من وجود العمود need_script\n",
    "# -------------------------\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# -------------------------\n",
    "# تهيئة المودل والمُرمّز\n",
    "# -------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")  # تشغيل على CPU\n",
    "\n",
    "MAX_INPUT_TOKENS = 4000  # أقصى عدد توكنات قبل القص\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق من need_script وتقسيم النصوص الطويلة\n",
    "# -------------------------\n",
    "def check_with_phi_split(gt, snip):\n",
    "    # تقسيم النص إلى أجزاء إذا تجاوز الحد\n",
    "    snippet_tokens = tokenizer.encode(snip)\n",
    "    parts = [snippet_tokens[i:i+MAX_INPUT_TOKENS] for i in range(0, len(snippet_tokens), MAX_INPUT_TOKENS)]\n",
    "    \n",
    "    try:\n",
    "        for part_tokens in parts:\n",
    "            part_text = tokenizer.decode(part_tokens)\n",
    "            prompt_text = f\"Ground Truth:\\n{gt}\\n\\nSnippet:\\n{part_text}\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"\n",
    "            \n",
    "            messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "            inputs = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=True,\n",
    "                return_dict=True,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True\n",
    "            ).to(model.device)\n",
    "            \n",
    "            attention_mask = inputs.get(\"attention_mask\", None)\n",
    "            outputs = model.generate(**inputs, attention_mask=attention_mask, max_new_tokens=50)\n",
    "            answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "            \n",
    "            if \"yes\" in answer.lower():\n",
    "                return \"Yes\"  # أي جزء يحتاج سكربت → الصف يحتاج سكربت\n",
    "\n",
    "        return \"No\"  # جميع الأجزاء تحتوي على GT → لا يحتاج سكربت\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # افتراضيًا محتاج سكربت لو حصل خطأ\n",
    "\n",
    "# -------------------------\n",
    "# معالجة كل الصفوف\n",
    "# -------------------------\n",
    "for idx, row in file_brave3.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = check_with_phi_split(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    time.sleep(1)  # لتخفيف الحمل على المودل\n",
    "\n",
    "# -------------------------\n",
    "# حفظ نسخة جديدة من الملف باسم مختلف\n",
    "# -------------------------\n",
    "new_file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_split.xlsx\"\n",
    "file_brave3.to_excel(new_file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف في النسخة الجديدة: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d9607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b86c3e37574e97ae8a7c9c90a99894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mmicrosoft/Phi-3-mini-4k-instruct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m model.to(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# تشغيل على CPU\u001b[39;00m\n\u001b[32m     20\u001b[39m MAX_INPUT_TOKENS = \u001b[32m4000\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:597\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    595\u001b[39m         model_class.register_for_auto_class(auto_class=\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m    596\u001b[39m     model_class = add_generation_mixin_to_remote_model(model_class)\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping:\n\u001b[32m    601\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:288\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    290\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:5176\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5167\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   5169\u001b[39m     (\n\u001b[32m   5170\u001b[39m         model,\n\u001b[32m   5171\u001b[39m         missing_keys,\n\u001b[32m   5172\u001b[39m         unexpected_keys,\n\u001b[32m   5173\u001b[39m         mismatched_keys,\n\u001b[32m   5174\u001b[39m         offload_index,\n\u001b[32m   5175\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m5176\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5182\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5185\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5188\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5192\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5193\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   5194\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:5639\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5636\u001b[39m         args_list = logging.tqdm(args_list, desc=\u001b[33m\"\u001b[39m\u001b[33mLoading checkpoint shards\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5638\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[32m-> \u001b[39m\u001b[32m5639\u001b[39m         _error_msgs, disk_offload_index, cpu_offload_index = \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5640\u001b[39m         error_msgs += _error_msgs\n\u001b[32m   5642\u001b[39m \u001b[38;5;66;03m# Adjust offloaded weights name and save if needed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:946\u001b[39m, in \u001b[36mload_shard_file\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[32m    945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m     disk_offload_index, cpu_offload_index = \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index, cpu_offload_index\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:815\u001b[39m, in \u001b[36m_load_state_dict_into_meta_model\u001b[39m\u001b[34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[39m\n\u001b[32m    813\u001b[39m param = param[...]\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m casting_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m     param = \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasting_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m to_contiguous:\n\u001b[32m    817\u001b[39m     param = param.contiguous()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")  # تشغيل على CPU\n",
    "\n",
    "MAX_INPUT_TOKENS = 4000\n",
    "\n",
    "def check_with_phi_split(gt, snip):\n",
    "    snippet_tokens = tokenizer.encode(snip)\n",
    "    parts = [snippet_tokens[i:i+MAX_INPUT_TOKENS] for i in range(0, len(snippet_tokens), MAX_INPUT_TOKENS)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776ee183",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94b00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71bb558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228b640c139c42de81f2f8470d372e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Ground Truth:\\nTikTok launched its US shopping platform in September 2023.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok\\', \\'text\\': \\'In October 2020, the e-commerce platform Shopify added TikTok to its portfolio of social media platforms, allowing online merchants to sell their products directly to consumers on TikTok. Some small businesses have used TikTok to advertise and to reach an audience wider than the geographical region they would normally serve.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok\\', \\'text\\': \\'In September 2021, TikTok reported that it had reached 1 billion users. In 2021, TikTok earned $4 billion in advertising revenue. In October 2022, TikTok was reported to be planning an expansion into the e-commerce market in the US, following the launch of TikTok Shop in the United Kingdom.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok\\', \\'text\\': \"TikTok, known in mainland China and Hong Kong as Douyin (Chinese: 抖音; pinyin: Dǒuyīn; lit. \\'Shaking Sound\\'), is a social media and short-form online video platform owned by Chinese Internet company ByteDance. It hosts user-submitted videos, which may range in duration from three seconds to 60 minutes. It can be accessed through a mobile app or through its website. Since its launch, TikTok has become one of the world\\'s most popular social media platforms, using recommendation algorithms to connect content creators and influencers with new audiences.\"}, {\\'doc_id\\': 0, \\'source\\': \\'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok\\', \\'text\\': \\'TikTok says that since 2020, its US-based CEO is responsible for making important decisions, and has downplayed its China connection. Douyin was launched on September 20, 2016, by ByteDance, originally under the name A.me, before rebranding to Douyin (抖音) in December 2016. Douyin was developed in 200 days and within a year had 100 million users, with more than one billion videos viewed every day. While TikTok and Douyin share a similar user interface, the platforms operate separately.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'TikTok - Wikipedia - https://en.wikipedia.org/wiki/TikTok\\', \\'text\\': \\'ByteDance said its early guidelines were global and aimed at reducing online harassment and divisiveness when its platforms were still growing. They have been replaced by versions customized by local teams for users in different regions. A March 2021 study by the Citizen Lab found that TikTok did not censor searches politically but was inconclusive about whether posts are.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Introducing TikTok Shop - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/introducing-tiktok-shop\\', \\'text\\': \"US users\\' payment information is managed by USDS and we work with third party payment platforms to facilitate transactions on TikTok Shop. In addition, all product listings must adhere to TikTok Shop policies and Community Guidelines. We use a combination of technology and manual moderation to enforce our policies and will remove merchants and products we find break our rules. There\\'s no finish line when it comes to protecting our community, and we\\'ll continually strengthen our policies, processes, and features.\"}, {\\'doc_id\\': 1, \\'source\\': \\'Introducing TikTok Shop - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/introducing-tiktok-shop\\', \\'text\\': \\'Secure Checkout: TikTok works with trusted third party payment platforms to facilitate transactions on TikTok Shop, to ensure a quick, smooth, and secure checkout process. All TikTok protected US user data is stored in the US and managed by USDS.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Introducing TikTok Shop - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/introducing-tiktok-shop\\', \\'text\\': \"Across the US, over 150 million people turn to TikTok to be entertained and inspired by content they find from their favorite creators -- including the latest trends, fashion and beauty tips, recipes, and more. Today, we\\'re excited to announce a new way for people to now find and shop for their favorite products with the full launch of TikTok Shop in the US.\"}, {\\'doc_id\\': 1, \\'source\\': \\'Introducing TikTok Shop - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/introducing-tiktok-shop\\', \\'text\\': \\'Shopify merchants can manage their TikTok Shop directly from Shopify through the TikTok for Shopify App. TikTok also offers direct integrations and connectors with WooCommerce, Salesforce Commerce Cloud, BigCommerce, Magento and other leading commerce platforms.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'TikTok Shop - Wikipedia - https://en.wikipedia.org/wiki/TikTok_Shop\\', \\'text\\': \\'Officially launched in September 2023, the feature enables users interested in starting a business and generating income to upload their curated products on TikTok for others to discover and purchase. Daily sales averaged approximately US$7 million in October 2023. In October 2019, TikTok announced its partnership with Shopify for a feature called TikTok: For Business. In November 2022, ByteDance commenced beta testing of the platform in the United Kingdom and several Southeast Asian countries.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'TikTok Shop - Wikipedia - https://en.wikipedia.org/wiki/TikTok_Shop\\', \\'text\\': \\'In December 2022, Amazon announced the release of Amazon Inspire, a platform resembling TikTok Shop, in a bid to compete with TikTok itself. In September 2023, ByteDance announced the launch of TikTok Shop globally, which was notably influenced by the launch of Amazon Inspire.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'TikTok Shop - Wikipedia - https://en.wikipedia.org/wiki/TikTok_Shop\\', \\'text\\': \\'TikTok Shop is an e-commerce feature of the video hosting service TikTok. Officially launched in September 2023, the feature enables users interested in starting a business and generating income to upload their curated products on TikTok for others to discover and purchase.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'TikTok officially debuts shopping platform, TikTok Shop, to U.S. consumers - CBS News - https://www.cbsnews.com/news/tiktok-shop-e-commerce-us-debut/\\', \\'text\\': \\'TikTok Shop is on track to lose more than $500 million in the U.S. this year, according to an August report from The Information. Still, TikTok has a massive user base to which to sell. The app has skyrocketed in popularity in the U.S., amassing more than 150 million American users, the company said in a statement earlier this year. It has also become the second-most popular app among teens after YouTube, a Pew Research study from 2022 shows.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'TikTok officially debuts shopping platform, TikTok Shop, to U.S. consumers - CBS News - https://www.cbsnews.com/news/tiktok-shop-e-commerce-us-debut/\\', \\'text\\': \\'TikTok is officially rolling out its TikTok Shop marketplace and services to U.S. users this week.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'TikTok officially debuts shopping platform, TikTok Shop, to U.S. consumers - CBS News - https://www.cbsnews.com/news/tiktok-shop-e-commerce-us-debut/\\', \\'text\\': \\'About 40% of users currently have the Shop tab available in the app, the company said. TikTok creator Heather DiRocco talks lawsuit over Montana ban 06:54 · To be sure, the fledgling platform faces a number of challenges in the U.S., not least of which being that lawmakers here see the Chinese-owned social network as a national security risk and favor banning the app.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'TikTok officially debuts shopping platform, TikTok Shop, to U.S. consumers - CBS News - https://www.cbsnews.com/news/tiktok-shop-e-commerce-us-debut/\\', \\'text\\': \\'In Indonesia alone, TikTok has more than 100 million active users, who spend more than 100 minutes on the app a day, on average, according to Bloomberg.  · The shopping platform strives to reach $20 billion in merchandise sales this year, more than quadruple that from last year, Bloomberg reported.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'TikTok launches online shopping in the US | Reuters - https://www.reuters.com/technology/tiktok-launches-online-shopping-us-2023-09-12/\\', \\'text\\': \\'New features include a shop tab, where businesses can display their products with logistics and payments solutions powered by TikTok. The social media firm said it also integrated its shopping service with various third-party platforms like Shopify (SHOP.TO), opens new tab, Salesforce (CRM.N), opens new tab, and Zendesk, among others.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'TikTok launches online shopping in the US | Reuters - https://www.reuters.com/technology/tiktok-launches-online-shopping-us-2023-09-12/\\', \\'text\\': \"TikTok is bringing online shopping through a series of features on its main app and is hoping to replicate the success of Asian platforms Shein and PDD Holdings\\' (PDD.O), opens new tab Temu.\"}, {\\'doc_id\\': 4, \\'source\\': \\'TikTok launches online shopping in the US | Reuters - https://www.reuters.com/technology/tiktok-launches-online-shopping-us-2023-09-12/\\', \\'text\\': \\'U.S. flag and TikTok logo are seen in this illustration taken, June 2, 2023.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'TikTok Shop is where shoppers come to discover - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/tiktok-shop-is-where-shoppers-come-to-discover\\', \\'text\\': \\'Eligible customers can use Venmo at checkout to redeem an additional discount. TikTok Shop will launch a LIVE Price Match Guaranteed program for the first time, offering customers watching select Deals for You Days livestreams cash back on the difference (subject to terms and conditions) if they find a lower price off-platform on featured products.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'TikTok Shop is where shoppers come to discover - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/tiktok-shop-is-where-shoppers-come-to-discover\\', \\'text\\': \\'TikTok Shop has been on a journey since launching in the US in September 2023 to bring joy and inspiration to the shopping experience. Online shopping revolutionized fast and convenient shopping, but over time, this excitement of this experience lost its spark.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'TikTok Shop is where shoppers come to discover - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/tiktok-shop-is-where-shoppers-come-to-discover\\', \\'text\\': \"Based on what we observed in 2024, brands and creators hosted over 8 million hours of LIVE shopping sessions in the US. This is significant, especially when GlobalData\\'s survey shows that 76% of consumers who engaged with TikTok Shop bought something from a livestream in the past year. With TikTok Shop, large brands and small businesses have a platform to be the storytellers of their brand and products, and shoppers are finding brands and products they didn’t even know they were looking for.\"}, {\\'doc_id\\': 5, \\'source\\': \\'TikTok Shop is where shoppers come to discover - Newsroom | TikTok - https://newsroom.tiktok.com/en-us/tiktok-shop-is-where-shoppers-come-to-discover\\', \\'text\\': \\'In May, we issued our 2025 safety and IPR reports, sharing our progress in protecting the platform. To date, TikTok Shop has invested nearly $1 billion in tools, technologies, and people in order to protect customers, sellers, brands, and our marketplace from counterfeit activities, fraudulent behavior, and other instances of abuse. People don’t come to TikTok Shop just to buy—they come to explore and discover. It might be a creator styling an everyday outfit, a small business owner sharing the story behind their product, or a LIVE session that feels like shopping with a friend.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'TikTok Shop launches in the U.S. as the company bets big on e-commerce | AP News - https://apnews.com/article/tiktok-online-shopping-65470c109c80408f05875d8678fe5072\\', \\'text\\': \\'The e-commerce platform is being launched as TikTok continues to negotiate with the U.S. government over its future in the country. Critics have levied accusations that the social media giant could be a tool for China’s government to surveil Americans. The company said TikTok shop will offer a secure checkout process and that all of its U.S. user data is stored and managed by servers maintained by the software giant Oracle.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'TikTok Shop launches in the U.S. as the company bets big on e-commerce | AP News - https://apnews.com/article/tiktok-online-shopping-65470c109c80408f05875d8678fe5072\\', \\'text\\': \\'After months of testing, TikTok is fully launching its e-commerce product in the U.S., in an effort to translate the app’s cultural relevance among young consumers to sales. The company said Tuesday, Sept. 12, 2023 its shopping wing, called TikTok Shop, will include several features such as a “Shop Tab,” a marketplace its been testing on the app since August.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'TikTok Shop launches in the U.S. as the company bets big on e-commerce | AP News - https://apnews.com/article/tiktok-online-shopping-65470c109c80408f05875d8678fe5072\\', \\'text\\': \\'The company said Tuesday its shopping wing, called TikTok Shop, will include several features such as a “Shop Tab,” a marketplace its been testing on the app since August; affiliate videos in user’s feed that allows creators to earn commissions from products; as well as a logistics arm called Fulfilled by TikTok that stores and ships products for merchants.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'T\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'StaticCache' object has no attribute 'seen_tokens'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nGlobal online retail sales are expected to exceed $7.4 trillion in 2025.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/\\', \\'text\\': \\'In 2024, global retail e-commerce sales reached an estimated ************ U.S. dollars. Projections indicate a ** percent growth in this figure over the coming years, with expectations to come close to ************** dollars by 2028.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/\\', \\'text\\': \\'ACSI - U.S. customer satisfaction with online retail as of 2025\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/\\', \\'text\\': \\'Premium Statistic U.S. consumer shipping companies - customer experience 2017-2025\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/\\', \\'text\\': \\'Retail e-commerce sales worldwide from 2022 to 2028 (in billion U.S. dollars) [Graph], eMarketer, April 8, 2025.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics\\', \\'text\\': \\'Products or services are sold into non-native markets via online sales and marketing. ... Worldwide, it is anticipated that B2B ecommerce will reach $36 trillion by 2026. And B2C ecommerce will reach $5.5 trillion by 2027.  · The global ecommerce market is expected to total $4.8 trillion in 2025. That figure is estimated to grow over the next few years, showing that borderless ecommerce is becoming a profitable option for online retailers.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics\\', \\'text\\': \\'However, as an extension of social commerce, live shopping has started to become more popular as the strategy has soared in China. The live commerce market in China was $562 billion in 2023 and is expected to increase to $843 billion in 2025. It made up 19.2% of the retail ecommerce sales in 2023.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics\\', \\'text\\': \\'While this impact is global, European retailers expect higher revenue growth, with a larger proportion anticipating a 5% to 9% increase. As ecommerce matures, Deloitte found retailers are focusing on making online sales more profitable rather than just expanding market share.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics\\', \\'text\\': \\'The rise of mobile commerce (m-commerce) is significant, with some forecasting it to reach $558 billion in 2024, accounting for 7.6% of total retail sales.  · In 2023, nearly 80% of global consumers used their smartphone to access a retailer’s website while shopping in-store. Another 74% used a retailer’s app while shopping, according to Insider Intelligence.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/\\', \\'text\\': \\'In China, a staggering 92% of respondents use their phones for online shopping, while in India, the figure stands at 88%. mCommerce sales will account for $2.51 trillion in 2025, that would be a 21.25% increase from the previous year when the recorded sales were $2.07 trillion. The growth of mobile commerce is expected to be larger than the average annual growth rate of 15.3% forecast from 2018 to 2027.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/\\', \\'text\\': \\'In 2025, 21% of retail purchases are expected to take place online, and this share will rise to 22.6% by 2027. Ecommerce sales will surpass $6.8 trillion in 2025.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/\\', \\'text\\': \\'It is further expected that 22.6% of all retail purchases will be made online by 2027. The share of online retail purchases is rising at an average of 0.32% every year since 2021. This is a sign to invest more in the online presence of your business and stay relevant in the current retail scene. Here is a table showing the share of online retail transactions over the years: Source: Statista. Global eCommerce sales will account for $6.86 trillion in 2025, which is an 8.37% increase from 2024.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/\\', \\'text\\': \\'The sales will continue growing at a CAGR of 7.8% between 2025 to 2027 and reach $8 trillion by 2027. Growing at more than 2x rate compared to physical stores. This shows that eCommerce is becoming a more profitable choice for companies worldwide. Here is a table showing the growth in retail eCommerce sales globally over the years:\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/\\', \\'text\\': \\'Online shopping has grown steadily in popularity in recent years. In 2021, global online retail sales amounted to almost five trillion U.S. dollars, a figure expected to exceed seven trillion U.S. dollars by 2025. Digital development in Latin America boomed during the COVID-19 pandemic, generating unprecedented e-commerce growth in various economies across the region.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/\\', \\'text\\': \\'eMarketer, E-commerce as percentage of total retail sales worldwide from 2021 to 2027 Statista, https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/ (last visited January 05, 2025)\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/\\', \\'text\\': \\'E-commerce share of retail sales in Singapore 2015-2025\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/\\', \\'text\\': \\'eMarketer. \"E-commerce as percentage of total retail sales worldwide from 2021 to 2027.\" Chart. February 27, 2024. Statista. Accessed January 05, 2025.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Global Online Retail Statistics and Trends For 2025 - Invesp - https://www.invespcro.com/blog/online-retail-statistics-and-trends/\\', \\'text\\': \\'Global retail eCommerce sales are forecast to reach $7.4 trillion in 2025, according to eMarketer. This will account for nearly 24% of all global retail spending, showing how online shopping is becoming a dominant force in the retail landscape. The projected value of the global eCommerce market in 2025 is $7.4 trillion, driven by increased internet access, mobile commerce, and AI-powered shopping experiences across both emerging and mature markets. By 2025, the number of digital buyers worldwide is expected to surpass 2.77 billion, representing over 33% of the global population.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Global Online Retail Statistics and Trends For 2025 - Invesp - https://www.invespcro.com/blog/online-retail-statistics-and-trends/\\', \\'text\\': \\'The United States, just a little behind, contributes significantly to global e-commerce spending. Together, these two countries accounted for more than $4.1 trillion in e-commerce sales. ... These massive figures highlight China’s and the US’s dominance of the global online retail sector and their role in shaping global e-commerce trends.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Global Online Retail Statistics and Trends For 2025 - Invesp - https://www.invespcro.com/blog/online-retail-statistics-and-trends/\\', \\'text\\': \\'The next few years are expected to bring new technologies, improved customer experiences, and fresh growth opportunities—all pointing to one thing: ecommerce isn’t slowing down anywhere. In 2022, the global retail market generated sales of over 27 trillion U.S.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Global Online Retail Statistics and Trends For 2025 - Invesp - https://www.invespcro.com/blog/online-retail-statistics-and-trends/\\', \\'text\\': \\'With e-commerce sales hitting record highs and new shopping trends popping up everywhere, it takes time to keep up. But don’t worry—we’ve got you covered. In this article, we’re diving deep into the “Global Online Retail Statistics and Trends For 2025.” We’ll explore everything from the growth of ecommerce to the rise of mobile commerce and the impact of AI on shopping experiences.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'Global e-commerce overview: 2025 insights - https://ecommercegermany.com/blog/global-e-commerce\\', \\'text\\': \\'The category split in 2025 shows what people care about: ... But the revenue also shows what’s becoming essential in the digital shelf. Let’s start with the top earners. According to the ECDB report, the #1 revenue category globally is: 01 fashion, $1.251 trillion in online sales in 2024\\'}, {\\'doc_id\\': 6, \\'source\\': \\'Global e-commerce overview: 2025 insights - https://ecommercegermany.com/blog/global-e-commerce\\', \\'text\\': \\'Global e-commerce is no longer some kind of trend. It’s infrastructure. And it’s growing in new directions that matter for every retailer, manufacturer, or brand selling online. We looked into SellersCommerce and the ECDB Global eCommerce 2025 whitepaper to bring you this overview.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'Global e-commerce overview: 2025 insights - https://ecommercegermany.com/blog/global-e-commerce\\', \\'text\\': \\'You need to know where it’s happening, how fast it’s shifting, and what your buyers expect from the experience. It’s not evenly spread — and that’s the whole point. It’s more regional, strategic, and often surprising. Let’s start with the raw numbers. According to ECDB, the fastest-growing continent between 2024 and 2028 is Africa, with a projected +52.6% growth.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'Global e-commerce overview: 2025 insights - https://ecommercegermany.com/blog/global-e-commerce\\', \\'text\\': \\'According to SellersCommerce, global e-commerce will surpass $6.86 trillion in 2025. That’s up 8.37% from 2024, and part of a steady climb that will take the market to nearly $8 trillion by 2027. The ECDB report takes a narrower scope — just B2C physical goods (excluding services, B2B, C2C, returns, compensation for damaged or missing goods, any discounts granted, and digital products).\\'}, {\\'doc_id\\': 7, \\'source\\': \\'Global Ecommerce Sales Growth (2022–2028) [Updated Oct 2024] - https://www.oberlo.com/statistics/global-ecommerce-sales-growth\\', \\'text\\': \\'The growth rate of ecommerce consistently outpaces that of total retail sales, indicating a continued shift in consumer preference toward online shopping over traditional retail channels. The global ecommerce growth rate for 2024 is forecast at 8.4%, bringing global ecommerce sales worldwide to $6.09 trillion. According to experts’ forecasts, global ecommerce sales growth is set to continue, albeit at a slightly slower pace. Ecommerce’s growth rate worldwide is expected to decelerate to 7.8% in 2025, which will bring total ecommerce sales to $6.56 trillion.\\'}, {\\'doc_id\\': 7, \\'source\\': \\'Global Ecommerce Sales Growth (2022–2028) [Updated Oct 2024] - https://www.oberlo.com/statistics/global-ecommerce-sales-growth\\', \\'text\\': \\'In 2024, total retail sales worldwide are expected to rise to $31.1 trillion, marking an increase of 4.9% from 2023. This is 3.5 percentage points lower than the global rate.\\'}, {\\'doc_id\\': 7, \\'source\\': \\'Global Ecommerce Sales Growth (2022–2028) [Updated Oct 2024] - https://www.oberlo.com/statistics/global-ecommerce-sales-growth\\', \\'text\\': \\'In subsequent years, the gap between ecommerce and retail growth rates is projected to remain, with ecommerce consistently outpacing traditional retail growth, which is expected to slow to 3.6% by 2027.\\'}, {\\'doc_id\\': 7, \\'source\\': \\'Global Ecommerce Sales Growth (2022–\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nThe article \\'6 Best E-commerce Platforms of 2025: My Review\\' was authored by Bhoomika Pawar.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'6 Best E-commerce Platforms of 2025: My Review - https://learn.g2.com/best-ecommerce-platforms\\', \\'text\\': \\'To gain deeper insights, I collaborated with different e-commerce store owners, who provided valuable context on why they prefer certain platforms and how they use AI-powered tools. In cases where I couldn’t personally test a tool due to limited access, I consulted a professional with hands-on experience and validated their insights using verified G2 reviews. The screenshots featured in this article may be a mix of those captured during testing and ones obtained from the vendor’s G2 page.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'6 Best E-commerce Platforms of 2025: My Review - https://learn.g2.com/best-ecommerce-platforms\\', \\'text\\': \\'It was there that I developed a strong foundation in understanding what makes an e-commerce platform beneficial—fully connected functionality, scalability, and ease of use. I have always been curious about which platform would suit most businesses.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'6 Best E-commerce Platforms of 2025: My Review - https://learn.g2.com/best-ecommerce-platforms\\', \\'text\\': \\'In my experience, e-commerce platforms have made running an online store simple for everyone. They allow you to list products, process payments, track inventory, and manage orders—all from one place. But the best e-commerce platforms go well beyond the basics.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'6 Best E-commerce Platforms of 2025: My Review - https://learn.g2.com/best-ecommerce-platforms\\', \\'text\\': \\'I spent weeks testing these e-commerce platforms, exploring their unique features and whether they supported scalability - from small startups to scaling enterprises. I signed up to understand the different advantages they had when compared to their competitors.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Best E-Commerce Platforms of 2025 – Forbes Advisor - https://www.forbes.com/advisor/business/software/best-ecommerce-platform/\\', \\'text\\': \\'We analyzed and tested the best e-commerce platforms to find the best choices to power your online store and help you grow your business.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Best E-Commerce Platforms of 2025 – Forbes Advisor - https://www.forbes.com/advisor/business/software/best-ecommerce-platform/\\', \\'text\\': \\'Theme management and editing in OpenCart requires patience and fighting through a deeper learning curve than other e-commerce platforms. With direct hosting, you always know what your server resources are. It’s also a fantastic safety net for technical support outside of OpenCart. If anything goes wrong with hosting, you have your host’s included tech support, like Scala Hosting’s 24/7 live chat support with a 30-second guaranteed response time or its 15-minute response time ticketed support.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Best E-Commerce Platforms of 2025 – Forbes Advisor - https://www.forbes.com/advisor/business/software/best-ecommerce-platform/\\', \\'text\\': \\'Pricing and features are not quite as attractive as they once were, however. Ecwid used to be the starting point for many online shops due to a free forever plan, but pricing changed at the start of 2025 Q2. The previously free Starter plan is now $5 monthly but still carries the nearly draconian limits on products and features.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Best E-Commerce Platforms of 2025 – Forbes Advisor - https://www.forbes.com/advisor/business/software/best-ecommerce-platform/\\', \\'text\\': \\'As a small business owner, Liz understands the unique challenges entrepreneurs face. Well-versed in the digital landscape, she combines real-world experience in website design, building e-commerce shops, managing social media and marketing with years...\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Best E-Commerce Platforms for 2025 | The Ad Firm - https://www.theadfirm.net/2025-update-best-e-commerce-platforms-for-2025/\\', \\'text\\': \\'Modern consumers demand ethical practices and eco-conscious options, compelling platforms to prioritize green commerce in their features and operations. Local SEO: Dominate your local market and attract more customers with targeted local SEO strategies. PPC: Use precise PPC management to draw high-quality traffic and boost your leads effectively. Content Marketing: Create and distribute valuable, relevant content that captivates your audience and builds authority.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Best E-Commerce Platforms for 2025 | The Ad Firm - https://www.theadfirm.net/2025-update-best-e-commerce-platforms-for-2025/\\', \\'text\\': \\'E-commerce platforms have transformed significantly in recent years, with new trends, technologies, and user expectations driving innovation. As we head into 2025, businesses must choose platforms that align with their growth strategies, ensuring scalability, usability, and optimized performance.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Best E-Commerce Platforms for 2025 | The Ad Firm - https://www.theadfirm.net/2025-update-best-e-commerce-platforms-for-2025/\\', \\'text\\': \\'E-commerce platforms in 2025 are adapting to the ever-changing demands of businesses and consumers. These trends reshape how online stores operate and compete, from cutting-edge technologies to value-driven innovations.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Best E-Commerce Platforms for 2025 | The Ad Firm - https://www.theadfirm.net/2025-update-best-e-commerce-platforms-for-2025/\\', \\'text\\': \\'Artificial intelligence (AI) is transforming e-commerce by enhancing personalization, optimizing processes, and providing actionable insights. In 2025, AI-powered features will be a luxury and a necessity for platforms aiming to deliver top-tier user experiences.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'9 Best Ecommerce Platforms of 2025 (Know Your Options) - https://www.bigcommerce.com/articles/ecommerce/ecommerce-platforms/\\', \\'text\\': \\'Resell ecommerce with Commerce-as-a-Service. ... This in-depth report provides actionable strategies to help you sell more online. ... Whether you’re ready for it or not, ecommerce is here to stay. If you don’t believe us, just look at the statistics: According to Statista, global retail ecommerce sales will surpass $6 billion for the first time in 2024. But the record-breaking growth doesn’t stop there. By 2025, ecommerce sales will reach over $8 billion.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'9 Best Ecommerce Platforms of 2025 (Know Your Options) - https://www.bigcommerce.com/articles/ecommerce/ecommerce-platforms/\\', \\'text\\': \\'Coined by Gartner in June 2020, composable commerce is a modular digital commerce solution that replaces the traditional monolithic approach. This is a composable architecture-based solution that uses APIs to individualize the different components of an ecommerce site.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'9 Best Ecommerce Platforms of 2025 (Know Your Options) - https://www.bigcommerce.com/articles/ecommerce/ecommerce-platforms/\\', \\'text\\': \\'Other platforms, like Salesforce Commerce Cloud, provide support but at a less robust level — as it lacks several essential support teams from its services offering.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'9 Best Ecommerce Platforms of 2025 (Know Your Options) - https://www.bigcommerce.com/articles/ecommerce/ecommerce-platforms/\\', \\'text\\': \\'Composable commerce offers users the freedom and flexibility to efficiently manage site components to meet their ecommerce needs.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'10 Best Ecommerce Platforms in 2025 (Reviewed, Compared, and Rated) - https://www.emailvendorselection.com/best-ecommerce-platforms-review/\\', \\'text\\': \\'Sellfy has a 14-day free trial and a 30-day money-back guarantee with the paid plans. You get store design migration in Business and product migration in Premium. ... Sellfy is a specialised ecommerce platform for creators selling digital products and merchandise. It also works well for physical products and if you already have a website. The user interface is very easy to navigate and creating a store is really quick. If you ever need help the help articles cover the whole platform.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'10 Best Ecommerce Platforms in 2025 (Reviewed, Compared, and Rated) - https://www.emailvendorselection.com/best-ecommerce-platforms-review/\\', \\'text\\': \\'Full blogging platform to publish articles, create lookbooks, get traffic with your blog.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'10 Best Ecommerce Platforms in 2025 (Reviewed, Compared, and Rated) - https://www.emailvendorselection.com/best-ecommerce-platforms-review/\\', \\'text\\': \\'Directories List of Email service providers Email Marketing agencies Marketing Automation Software Email list building tools Lead Generation Tools Helpful articles Email marketing definitions Gross Profit Calculator © Copyright 2009 - 2025 About us | Contact | Privacy | Methodology\\'}, {\\'doc_id\\': 4, \\'source\\': \\'10 Best Ecommerce Platforms in 2025 (Reviewed, Compared, and Rated) - https://www.emailvendorselection.com/best-ecommerce-platforms-review/\\', \\'text\\': \"CJ helps B2B SaaS and tech companies establish online authority, build trust with people, and sell more. He\\'s the founder of The Copy Crusade, a content marketing agency for B2B companies. And has a special love for B2B MarTech, digital marketing, and ecommerce platforms.\"}, {\\'doc_id\\': 5, \\'source\\': \\'The 6 best eCommerce website building platforms in 2025 - https://zapier.com/blog/best-ecommerce-shopping-cart-software/\\', \\'text\\': \\'While most deals are customized and the specifics kept private, you can expect to pay at least $22,000 per year for a \"basic\" Adobe Commerce (formerly Magneto Enterprise Edition) store with less than $1 million in sales. Shopify Plus starts at $2,500 per month. As you can imagine, neither of these options is a great fit for a small bakery looking to sell a few cookies online, but for a large chain, they\\\\\\'re required. ... BigCommerce vs. Shopify: Which is best? This article was originally published in July 2019. The most recent update was in January 2025.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'The 6 best eCommerce website building platforms in 2025 - https://zapier.com/blog/best-ecommerce-shopping-cart-software/\\', \\'text\\': \"His photos have been published on hundreds of sites—mostly without his permission. ... ClickFunnels vs. Shopify: Which is best? [2025] ClickFunnels vs. Shopify: Which is best?... ... How eCommerce automation benefits your... ... Wix vs. Shopify: What\\'s the best eCommerce platform? [2025]\"}, {\\'doc_id\\': 5, \\'source\\': \\'The 6 best eCommerce website building platforms in 2025 - https://zapier.com/blog/best-ecommerce-shopping-cart-software/\\', \\'text\\': \\'Monthly fee. This is anything from free to a few hundred dollars and goes straight to the platform. For most of the eCommerce services on this list, expect to pay around $30 to $40 per month for a basic plan.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'The 6 best eCommerce website building platforms in 2025 - https://zapier.com/blog/best-ecommerce-shopping-cart-software/\\', \\'text\\': \\'Payment gateway fees. These are the fees you pay when you process a credit card charge. The normal fee is around 2.9% plus an additional $0.30, although this goes down with volume and higher upfront payments.\\'}, {\\'doc_id\\': 7, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'Social channels are crucial touchpoints for e-commerce: In fact, by 2030, social commerce revenue is expected to reach $6.2 trillion. When it comes to finding new products, interacting with brands, and authentic product recommendations that consumers trust, social shopping will be a juggernaut for online retailers in 2025.\\'}, {\\'doc_id\\': 7, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'For example, 33% of B2B buyers say they search for products on mobile devices and social platforms more than in the past. AI-driven personalization: From product search to creative email marketing, AI personalization is foundational to e-commerce in 2025.\\'}, {\\'doc_id\\': 7, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'Social shopping makes the customer journey easier and more engaging, especially for digital natives who spend a lot of time on those platforms. For businesses, it’s a shift in how they market products—focusing on creating shoppable content, live-streaming events, and leveraging influencers to reach potential customers will be key to e-commerce in 2025.\\'}, {\\'doc_id\\': 7, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'That may change for e-commerce in 2025, as smartphone usage, messaging apps, and AI become a normal part of the shopping journey within the e-commerce industry. Smart speakers like Amazon Alexa and Google Assistant enable users to search for products, make purchases, and track deliveries using voice commands. The actual experience, however, can feel clunky and unreliable. But with recent advances in natural language capabilities, more e-commerce platforms are optimizing for voice search, giving consumers a hands-free, convenient way to shop\\'}, {\\'doc_id\\': 8, \\'source\\': \\'11 Best Ecommerce Platforms for Your Business in 2025 - Shopify - https://www.shopify.com/blog/best-ecommerce-platforms\\', \\'text\\': \\'Big Cartel offers limited customization options without coding knowledge, includes a small app marketplace with only about 30 direct integrations, and has no built-in abandoned cart recovery or built-in payment gateway (relies on third-party options like Stripe and PayPal).\\'}, {\\'doc_id\\': 8, \\'source\\': \\'11 Best Ecommerce Platforms for Your Business in 2025 - Shopify - https://www.shopify.com/blog/best-ecommerce-platforms\\', \\'text\\': \\'Volusion makes it easy to integrate, with more than 30 payment gateways, and provides essential tools for\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nSustainability accounted for 8.8% of the total conversation.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'The State of AI in E-Commerce: 2025 Quid Trend Report - https://www.quid.com/knowledge-hub/resource-library/blog/the-state-of-ai-in-e-commerce-2025-quid-trend-report\\', \\'text\\': \\'We equip retail leaders with the clarity to navigate fast-moving markets by analyzing millions of digital conversations in real time. Our technology surfaces the trends gaining traction, the sentiment shaping engagement, and the signals worth acting on before they go mainstream. From product planning to marketing strategy, Quid gives you the insight to move early and with confidence.  · Let’s talk about how we can help you reshape your e-commerce strategy.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'The State of AI in E-Commerce: 2025 Quid Trend Report - https://www.quid.com/knowledge-hub/resource-library/blog/the-state-of-ai-in-e-commerce-2025-quid-trend-report\\', \\'text\\': \\'Each trend signals where brands are finding real value—and where the market is headed next.  · One of the most quietly powerful insights in the report was the role of sustainability, which accounted for 8.8% of total conversation. Although it didn’t receive the most mentions, it consistently earned high trust and positive sentiment.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'The State of AI in E-Commerce: 2025 Quid Trend Report - https://www.quid.com/knowledge-hub/resource-library/blog/the-state-of-ai-in-e-commerce-2025-quid-trend-report\\', \\'text\\': \\'This blog breaks down the report’s methodology, top trends, key insights, and the sentiment drivers that help brands determine what’s working and what’s next.  · Understanding AI’s impact in retail requires more than a list of buzzwords. Our analysis focused on a year’s worth of digital conversations—from May 2024 to May 2025—across a wide mix of platforms, including global news outlets, industry blogs, social media platforms, Reddit, customer forums, and product review sites.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'The State of AI in E-Commerce: 2025 Quid Trend Report - https://www.quid.com/knowledge-hub/resource-library/blog/the-state-of-ai-in-e-commerce-2025-quid-trend-report\\', \\'text\\': \\'In January, Cognizant’s AI assistant “Flo” debuted at NRF 2025, showcasing real-time customer support capabilities. That single post drove more than 7,000 engagements, offering a tangible example of how AI can enhance service delivery.  · Microsoft, NVIDIA, and PYMNTS also contributed to the rise in AI agent conversation with thought leadership content focused on service automation and personalization.  · To understand not just what’s trending, but why people care, we analyzed the drivers behind the sentiment in the AI e-commerce conversation.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'Voice commerce: Smartphones, messaging apps, and AI are driving conversational commerce to the forefront of the industry in 2025. Augmented reality (AR): AR can ease online shopping anxiety by allowing customers to “try on” clothes or makeup, or see how furniture or paint will look in their space. Sustainability in e-commerce: Eco-friendly packaging, carbon neutral shipping, and sustainable sourcing and production will become more prevalent for commerce brands.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'According to an IDC study, 46% of consumers believe that a retail brand’s sustainability record is an important deciding factor for whom they’ll do business with. In 2025, e-commerce companies are looking at everything from their product packaging to their manufacturing and warehousing facilities to assess their emissions baseline and identify opportunities to improve.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'As 85% of single-use plastic packaging ends up in landfills, brands are looking to reduce their environmental impact through sustainable packaging. In 2025, the efficiency and speed of e-commerce operations will heavily rely on supply chain innovations. By integrating technologies like AI, automation, and drones, logistics processes are becoming faster, more precise, and increasingly sustainable.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'Expect to see sustainability stories take the spotlight in around e-commerce in 2025, as more and more commerce brands adopt eco-friendly practices.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Ecommerce marketing trends in 2025: AI, sustainability and more - https://www.digitalcommerce360.com/2024/12/30/ecommerce-marketing-trends-going-into-2025/\\', \\'text\\': \\'“Companies that strategically embrace AI, sustainability, and personalization will emerge as leaders in this transformative era.” · Here are some key ecommerce marketing trends going into 2025. Social commerce growth Social platforms like TikTok and Instagram will drive over 10% of ecommerce by 2025, up from 7%, thanks to improved shopping features. Voice search dominance By 2025, half of online searches will be voice-activated, pushing businesses to adopt conversational AI.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Ecommerce marketing trends in 2025: AI, sustainability and more - https://www.digitalcommerce360.com/2024/12/30/ecommerce-marketing-trends-going-into-2025/\\', \\'text\\': \\'AI shopping agents Personalized product recommendations from AI agents will boost loyalty and conversions. Automation with AI agents AI will handle routine tasks, freeing businesses to focus on growth. Sustainability focus With 70% of consumers valuing sustainable brands, aligning with these priorities will build trust. AR/VR integration Immersive AR/VR experiences will enhance online shopping as the market hits $50 billion by 2025.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Ecommerce marketing trends in 2025: AI, sustainability and more - https://www.digitalcommerce360.com/2024/12/30/ecommerce-marketing-trends-going-into-2025/\\', \\'text\\': \\'The ecommerce landscape is poised for a significant transformation in the coming year, driven by advancements in artificial intelligence (AI), a heightened focus on sustainability, and the push for hyper-personalized customer experiences. According to Udayan Bose, CEO of NetElixir and a veteran in digital marketing, these trends represent a pivotal shift for businesses aiming to stay ahead in an increasingly competitive market.\\'}, {\\'doc_id\\': 3, \\'source\\': \"Jun 04, 2025: DHL\\'s E-Commerce Trends Report 2025: AI and social media reshaping online shopping - DHL Group - https://group.dhl.com/en/media-relations/press-releases/2025/dhl-e-commerce-trends-report-2025.html\", \\'text\\': \\'This year’s study includes eight chapters, featuring six shopper types and four generational segments, all highlighting how evolving consumer expectations are reshaping the future of online retail.\\'}, {\\'doc_id\\': 3, \\'source\\': \"Jun 04, 2025: DHL\\'s E-Commerce Trends Report 2025: AI and social media reshaping online shopping - DHL Group - https://group.dhl.com/en/media-relations/press-releases/2025/dhl-e-commerce-trends-report-2025.html\", \\'text\\': \\'While the report covers everything from cross-border purchasing to shoppers\\\\\\' views on sale days like Black Friday, four findings stand out in particular: the way AI and social commerce are transforming online shopping, the essential role that delivery plays in cart conversion, and sustainability shaping loyalty. \"It\\\\\\'s important to recognize that there isn\\\\\\'t just one type of online shopper or one type of market. The reasons for cart abandonment can vary widely. Our E-Commerce Trends Report analyzes the trends and developments shaping online shopping worldwide to help our customers grow their businesses.\\'}, {\\'doc_id\\': 3, \\'source\\': \"Jun 04, 2025: DHL\\'s E-Commerce Trends Report 2025: AI and social media reshaping online shopping - DHL Group - https://group.dhl.com/en/media-relations/press-releases/2025/dhl-e-commerce-trends-report-2025.html\", \\'text\\': \\'A shift in sustainability: 1 in 3 shoppers drop out due to sustainability concerns · Social commerce takes center stage: 70% of global consumers expect to shop primarily through social media by 2030 - bypassing traditional websites entirely · AI becomes essential: 7 in 10 shoppers want AI-driven shopping tools - from virtual try-ons to voice search - to guide their decisions · Bonn - DHL eCommerce has released its E-Commerce Trends Report 2025, drawing on insights from 24,000 online shoppers across 24 key global markets.\\'}, {\\'doc_id\\': 3, \\'source\\': \"Jun 04, 2025: DHL\\'s E-Commerce Trends Report 2025: AI and social media reshaping online shopping - DHL Group - https://group.dhl.com/en/media-relations/press-releases/2025/dhl-e-commerce-trends-report-2025.html\", \\'text\\': \\'By embracing technology, prioritizing sustainability, and understanding the evolving preferences of consumers, businesses can transform challenges into opportunities. Further insights and information as well as the full report are available under the following link: dhl.com/e-commerce-report or dhl.com/reports ... The E-Commerce Trends Report 2025 surveyed 24,000 consumers from Europe, the Americas, Asia-Pacific, Africa, and the Middle East.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'8 Trends Accelerating the Future of E-commerce in 2025 | Publicis Sapient - https://www.publicissapient.com/insights/future-ecommerce-trends\\', \\'text\\': \\'While consumers are concerned about the negative impact of artificial intelligence, from job loss (42 percent) to misinformation (53 percent), 27 percent of those who are familiar with and have used generative AI tools are excited about its ability to generate personalized product recommendations for them, according to a Publicis Sapient survey. It’s up to e-commerce leaders to perfect their technology to draw consumers in, rather than push them away. In 2025, the potential for increased conversion rates, basket sizes and consumer engagement online through AI will outweigh the risks of getting it wrong, as long as retailers have the right digital expertise and quality assurance practices in place.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'8 Trends Accelerating the Future of E-commerce in 2025 | Publicis Sapient - https://www.publicissapient.com/insights/future-ecommerce-trends\\', \\'text\\': \\'What challenges and opportunities will emerge in 2025? Our experts offer industry-specific predictions and guidance for what awaits businesses in the year ahead. ... With cost-of-living increases and sustainable purchasing habits on the rise, secondhand marketplaces, rental platforms and resale are going to accelerate more than ever before. According to a survey of consumers in the United Kingdom, over four in 10 (44 percent) buy more secondhand items than they did a year ago, while a further 57 percent say their re-commerce shopping behavior has remained consistent.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'8 Trends Accelerating the Future of E-commerce in 2025 | Publicis Sapient - https://www.publicissapient.com/insights/future-ecommerce-trends\\', \\'text\\': \\'Despite the fast rise of generative AI technology—particularly large language models (LLMs), through tools like ChatGPT—many organizations are left wondering which use cases provide the most value for their needs, whether or not customers will engage with it on search engines and, frankly, what they need to change to avoid getting left behind. In 2025, many e-commerce websites will continue rolling out generative or conversational search tools.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'8 Trends Accelerating the Future of E-commerce in 2025 | Publicis Sapient - https://www.publicissapient.com/insights/future-ecommerce-trends\\', \\'text\\': \\'To craft your e-commerce strategy for 2025 and beyond, contact Guy Elliott and Sudip Mazumder below. ... Get a behind-the-scenes look at how and why we created DBT GPT, Publicis Sapient’s new conversational AI chatbot solution.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'100+ AI Statistics Shaping Business in 2025 - Vena - https://www.venasolutions.com/blog/ai-statistics\\', \\'text\\': \\'Here, we’ll dive into more than 100 artificial intelligence statistics and trends for 2025 that illustrate the current state of AI adoption across multiple industries and its impact on the future of business and work.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'100+ AI Statistics Shaping Business in 2025 - Vena - https://www.venasolutions.com/blog/ai-statistics\\', \\'text\\': \\'AI adoption is rising, but 20% of finance teams cite AI and machine learning as major skill gaps, according to Vena’s 2025 State of Strategic Finance report.53\\'}, {\\'doc_id\\': 5, \\'source\\': \\'100+ AI Statistics Shaping Business in 2025 - Vena - https://www.venasolutions.com/blog/ai-statistics\\', \\'text\\': \\'It’s clear that artificial intelligence is rapidly transforming the business landscape, and 2025 promises even greater advancements—but also new challenges. Preparing your business for a future with AI will empower employees to make smarter decisions, connect better with customers and navigate ethical considerations. AI’s ability to analyze vast amounts of data to predict customer behavior, market trends and potential risks will continue to be refined.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'10\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': \"Ground Truth:\\n70% of online shoppers say that product content can make or break a sale.\\n\\nSnippet:\\n[{'doc_id': 0, 'source': 'Council Post: 4 Big Trends For DTC E-Commerce Growth In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/04/17/4-big-trends-for-dtc-e-commerce-growth-in-2025/', 'text': 'Another trend in e-commerce is the growing demand for more and more background detail and information on each product sold. No longer satisfied with just a nice-looking label and some positive star ratings, 70% of online shoppers now say that product content can make or break a sale.'}, {'doc_id': 0, 'source': 'Council Post: 4 Big Trends For DTC E-Commerce Growth In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/04/17/4-big-trends-for-dtc-e-commerce-growth-in-2025/', 'text': 'Based on these four e-commerce trends, savvy online brands should consider the following actions and investments to see strong DTC revenue growth in 2025: 1. Extend their brand experience to TikTok Shop and other social commerce platforms to capitalize on new sales opportunities with new and existing audiences. 2. Go deep with the amount of detail and supporting content provided for each product, including long-form video and regular live selling experiences. 3. Provide a more personalized experience for known and unknown shoppers with modern customer personalization technology that uses AI algorithms instead of cookies.'}, {'doc_id': 0, 'source': 'Council Post: 4 Big Trends For DTC E-Commerce Growth In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/04/17/4-big-trends-for-dtc-e-commerce-growth-in-2025/', 'text': '| Membership (fee-based)Apr 17, 2025, 07:15am EDT ... Diane Keng, CEO & cofounder of Breinify, a leading AI-power predictive personalization platform. Forbes 30 Under 30, Enterprise Technology. ... Direct-to-consumer (DTC) e-commerce brands are always looking for the next lever to pull that can help scale their businesses to new heights. But with the ever-changing nature of consumer trends and emerging tech—and the reality of limited budgets for marketing experimentation—it can be hard for brands to decipher between worthwhile long-term investments and passing fads.'}, {'doc_id': 0, 'source': 'Council Post: 4 Big Trends For DTC E-Commerce Growth In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/04/17/4-big-trends-for-dtc-e-commerce-growth-in-2025/', 'text': 'In this article, I’ll examine four big trends in DTC e-commerce growth that appear to be very much here to stay. The growth of social commerce will continue throughout 2025, with more than $100 billion in revenue projected from social media product purchases, an increase of 22% from 2024.'}, {'doc_id': 1, 'source': 'Top Ecommerce Trends to Watch in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-trends/', 'text': 'With consumers craving more immersive and authentic shopping experiences, livestream commerce will become a major revenue driver in 2025, transforming how brands connect with and convert shoppers online. Perhaps one of the greatest challenges of shopping online is the inability to see, touch, and fully experience a product in-person before buying — enter augmented reality (AR). According to eMarketer, the number of AR users in the US will exceed 100 million by the end of 2025, making up 32% of the population.'}, {'doc_id': 1, 'source': 'Top Ecommerce Trends to Watch in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-trends/', 'text': 'Especially in the fashion and apparel industry, younger shoppers are favoring brands that prioritize ethical and eco-friendly practices over those that don’t. According to a study by Drapers and BigCommerce, Drapers survey found that 57% of Gen Z and Millennials say sustainability is important when it comes to shopping for clothes, accessories or shoes — up from 47% in the 2022 survey.'}, {'doc_id': 1, 'source': 'Top Ecommerce Trends to Watch in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-trends/', 'text': 'Today, major retailers are leveraging AR for virtual try-ons and interactive 3D product views, allowing shoppers to visualize products in their real-world environments, thus increasing buyer confidence and reducing return rates. With 75% of US households owning a smart speaker in 2025, it’s no surprise that voice search is an up and coming trend in the ecommerce space. Voice assistants like Amazon Alexa and Google Assistant have transformed the way that consumers interact with ecommerce platforms — like BigCommerce and Shopify — offering a hands-free, convenient way to shop.'}, {'doc_id': 1, 'source': 'Top Ecommerce Trends to Watch in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-trends/', 'text': 'By simply using a voice command, shoppers can search for products, make purchases, and track orders with ease. In response, many ecommerce businesses are optimizing their sites for voice search, ensuring quick and accurate responses to voice queries. And as voice technology continues to innovate, its integration into the shopping experience will undoubtedly enhance customer convenience and drive significant growth in online sales.'}, {'doc_id': 3, 'source': '14 Online Shopping Trends Shaping 2025 - Shopify - https://www.shopify.com/enterprise/blog/online-shopping-trends-ecommerce', 'text': 'This isn’t the first or last time you’ll hear it: Your product pages sell, even more so as we move into 2025. A 2023 survey found that 70% of online shoppers say product-page content can make or break a sale.'}, {'doc_id': 3, 'source': '14 Online Shopping Trends Shaping 2025 - Shopify - https://www.shopify.com/enterprise/blog/online-shopping-trends-ecommerce', 'text': 'Social media platforms like Facebook and Instagram have become increasingly popular places for consumers to discover, research, and purchase new products.  · Social commerce makes shopping a more convenient and interactive experience, which helps explain why eMarketer projects over $100 billion in social commerce sales in 2025, a 22.4% growth from year prior.'}, {'doc_id': 3, 'source': '14 Online Shopping Trends Shaping 2025 - Shopify - https://www.shopify.com/enterprise/blog/online-shopping-trends-ecommerce', 'text': 'Get access to the data and insights shaping ecommerce and how the biggest brands are driving growth. Download the guide · Mindful shopping practices will increase. More shoppers will head in-store. Shoppers will look for more product details. Green initiatives will continue to be popular—with a caveat. More people will shop through social commerce.'}, {'doc_id': 3, 'source': '14 Online Shopping Trends Shaping 2025 - Shopify - https://www.shopify.com/enterprise/blog/online-shopping-trends-ecommerce', 'text': 'As mobile browsing overtakes desktop––almost 64% of global web traffic came from mobile devices in August 2024––increasing numbers of shoppers are tapping “buy” on their devices. In 2023, retail m-commerce sales hit $2.2 trillion, and now make up 60% of all ecommerce sales around the world. By 2027, analysts expect that number to reach $3.4 trillion.'}, {'doc_id': 4, 'source': 'eCommerce statistics 2025: key findings and shopping trends [latest research] - https://www.hostinger.com/ph/tutorials/ecommerce-statistics', 'text': 'With this uptrend, mobile commerce sales are projected to exceed $3.4 trillion by 2027. To keep up with evolving consumer behavior, online stores must prioritize mobile optimization in mobile-first markets. Start by creating a user-friendly customer journey, from browsing to purchasing products. Global mobile commerce is growing at a rate of 29%, capturing 7% more completed payments than traditional eCommerce. Around 70% of shoppers say mobile commerce is time-saving and convenient for buying on the go.'}, {'doc_id': 4, 'source': 'eCommerce statistics 2025: key findings and shopping trends [latest research] - https://www.hostinger.com/ph/tutorials/ecommerce-statistics', 'text': 'It’s no surprise that brands focusing on environmental, social, and governance (ESG) initiatives saw an average of 28% growth, while those without only grew by 20%. 24/7 availability, convenience, and discount deals make online shopping the go-to choice for 56.6% of consumers. That said, 44.4% still prefer in-store shopping, valuing the hands-on experience and ability to see, touch, and test products before buying. If you have the resources, consider adopting a multichannel business model to cater to both customer preferences. The thriving mobile commerce market makes it easy for people to shop online using only their phones.'}, {'doc_id': 4, 'source': 'eCommerce statistics 2025: key findings and shopping trends [latest research] - https://www.hostinger.com/ph/tutorials/ecommerce-statistics', 'text': 'Global eCommerce revenue is projected to exceed $6.4 trillion by 2029, with an annual growth rate (CAGR) of 9.49% from 2024 to 2029. This growth is consistent with the continued rise of online shopping worldwide. By 2029, the average revenue per user (ARPU) in the eCommerce market is expected to reach $1,620, highlighting the rising spending power of online shoppers.'}, {'doc_id': 4, 'source': 'eCommerce statistics 2025: key findings and shopping trends [latest research] - https://www.hostinger.com/ph/tutorials/ecommerce-statistics', 'text': 'Unexpected or high fees or taxes deterred 16% of shoppers from purchasing, while 14% decided to wait for a sale or discount. Meanwhile, indecisiveness or a change in mood accounted for 14% of abandoned carts. Other reasons for leaving carts include a lengthy or complicated checkout process (4%) and concerns about payment security (3%). High shipping costs and long delivery times are a bigger concern for men, with 59% finding them problematic compared to 41% of women.'}, {'doc_id': 5, 'source': 'DTC e-commerce: How consumer brands can get it right | McKinsey - https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/dtc-e-commerce-how-consumer-brands-can-get-it-right', 'text': 'In a similar vein, 75 percent of online shoppers say they prefer a personalized experience. For example, fashion brands such as Maje, Sandro, and The Kooples offer exclusive online presales to registered online customers. Assortment. Many brands choose to adapt their DTC assortment to the specific requirements of their sector and consumers.'}, {'doc_id': 5, 'source': 'DTC e-commerce: How consumer brands can get it right | McKinsey - https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/dtc-e-commerce-how-consumer-brands-can-get-it-right', 'text': 'During the COVID-19 pandemic, there has been a 70 percent increase in content uploads by users of Lego’s online platforms that help the company engage with consumers and find out what they like, especially in fast-growth markets, such as China.1“Lego builds its brand in China with experiences,” WARC, January 13, 2020, warc.com. Fueling innovation. DTC also provides the platform to test the latest innovation in products and services, giving brands direct access to consumer feedback for evaluation and testing.'}, {'doc_id': 5, 'source': 'DTC e-commerce: How consumer brands can get it right | McKinsey - https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/dtc-e-commerce-how-consumer-brands-can-get-it-right', 'text': 'Just 60 percent of consumer-goods companies, at best, feel even moderately prepared to capture e-commerce growth opportunities. Here are some concerns expressed by top executives globally: “I’m worried about fulfillment. What if we disappoint online shoppers?'}, {'doc_id': 5, 'source': 'DTC e-commerce: How consumer brands can get it right | McKinsey - https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/dtc-e-commerce-how-consumer-brands-can-get-it-right', 'text': 'At the early stages of DTC, brands often outsource logistics to guarantee quality, speed, and the flexibility to scale operations up or down as needed. Consumer brands that have their own retail network often use their stores as e-commerce fulfillment centers. Nike, for example, lets online shoppers pick up their purchases at brick-and-mortar Nike stores.'}, {'doc_id': 6, 'source': 'DTC Ecommerce Trends: What Brands Are Adopting in 2025 - https://webandcrafts.com/blog/dtc-ecommerce-trends', 'text': 'According to the June 2023 Global Consumer Insights Pulse Survey, about 63% of shoppers have purchased products from a brand’s website directly. In the highly competitive market, consumers wish for faster delivery of products, active customer support, personalized products, and a reliable source of information – this is where DTC e-commerce trends prove amazing.'}, {'doc_id': 6, 'source': 'DTC Ecommerce Trends: What Brands Are Adopting in 2025 - https://webandcrafts.com/blog/dtc-ecommerce-trends', 'text': 'Ecommerce retail sales are expected to reach 9.4 trillion U.S. dollars by 2026 on a global scale. Many physical retailers like BestBuy and Target have adopted measures for a major shift towards DTC models. As shoppers become more concerned and expectations grow, brands should find ways to meet the demands, offer value, and build exceptional customer experiences. This blog discusses the significant direct-to-consumer trends that shape the e-commerce sector and gives insights into how retailers should adopt these trends.'}, {'doc_id': 6, 'source': 'DTC Ecommerce Trends: What Brands Are Adopting in 2025 - https://webandcrafts.com/blog/dtc-ecommerce-trends', 'text': 'The global food and beverage market for e-commerce is expected to hit $903465.5 million by 20\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': \"Ground Truth:\\nThe article 'From AI To AR: The Bold Innovations Defining E-Commerce In 2025' by Dani Nadel was published on January 24, 2025.\\n\\nSnippet:\\n[{'doc_id': 0, 'source': 'Council Post: From AI To AR: The Bold Innovations Defining E-Commerce In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/01/24/from-ai-to-ar-the-bold-innovations-defining-e-commerce-in-2025/', 'text': 'Dani Nadel, President and COO, Feedvisor. ... Welcome to 2025, a year poised to redefine e-commerce and marketplaces.'}, {'doc_id': 0, 'source': 'Council Post: From AI To AR: The Bold Innovations Defining E-Commerce In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/01/24/from-ai-to-ar-the-bold-innovations-defining-e-commerce-in-2025/', 'text': 'What started as simple convenience is now the backbone of global commerce—a dynamic space where technology and consumer expectations collide in unpredictable ways. Advances in AI, sustainability demands and shifting shopping behaviors are redefining how we shop and do business. From logistics breakthroughs to predictive audiences, the trends that I believe will shape 2025 are bold, immersive and full of surprises.'}, {'doc_id': 0, 'source': 'Council Post: From AI To AR: The Bold Innovations Defining E-Commerce In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/01/24/from-ai-to-ar-the-bold-innovations-defining-e-commerce-in-2025/', 'text': '2025 isn’t just another year for e-commerce; it’s a leap into the future.'}, {'doc_id': 0, 'source': 'Council Post: From AI To AR: The Bold Innovations Defining E-Commerce In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/01/24/from-ai-to-ar-the-bold-innovations-defining-e-commerce-in-2025/', 'text': 'Amazon is making strides in this arena, and Walmart is keeping pace, innovating with in-home delivery that places goods directly into refrigerators or pantries using smart lock technology. It’s a race for speed—and seamless convenience. The future of e-commerce is immersive, transparent and incredibly smart.'}, {'doc_id': 1, 'source': 'Forbes: From AI to AR: The Bold Innovations Defining e-Commerce in 2025 - Feedvisor - https://feedvisor.com/resources/amazon-marketing-advertising-strategies/forbes-bold-innovations-defining-ecommerce-2025/', 'text': 'Meanwhile, logistics innovation—ranging from drone deliveries to in-home fulfillment—redefines speed and convenience. Dive into Dani Nadel’s latest Forbes article to explore how technology and consumer expectations are reshaping the future of commerce in bold and immersive ways. ... Discover the trends driving e-commerce in 2025 and how to position your brand for success.'}, {'doc_id': 1, 'source': 'Forbes: From AI to AR: The Bold Innovations Defining e-Commerce in 2025 - Feedvisor - https://feedvisor.com/resources/amazon-marketing-advertising-strategies/forbes-bold-innovations-defining-ecommerce-2025/', 'text': 'With 2025 set to redefine e-commerce and marketplaces, Feedvisor’s President and COO, Dani Nadel, highlights the groundbreaking trends shaping the year ahead. From AI-driven personalization to AR-powered shopping experiences, the landscape of global commerce is evolving at an unprecedented pace. Key innovations include advanced subscription models, hyper-personalized social commerce, and AI-driven programmatic advertising that seamlessly connects brands with predictive audiences.'}, {'doc_id': 2, 'source': '2025 Trends and Predictions: From AI to AR: The Bold Innovations Defining e-Commerce in 2025 - https://feedvisor.com/resources/e-commerce-strategies/bold-innovations-defining-ecommerce-2025/', 'text': 'This year marks a pivotal moment: advances in AI, sustainability demands, and shifting consumer behaviors are converging to redefine e-commerce. From logistics breakthroughs and predictive audiences to AR-enhanced shopping experiences, the trends shaping 2025 are bold, immersive, and full of surprises—offering brands, sellers, and consumers an opportunity to step into the future. Let’s dive into the trends and innovations redefining how we shop and do business.'}, {'doc_id': 2, 'source': '2025 Trends and Predictions: From AI to AR: The Bold Innovations Defining e-Commerce in 2025 - https://feedvisor.com/resources/e-commerce-strategies/bold-innovations-defining-ecommerce-2025/', 'text': 'At the same time, brands must remain mindful of their environmental footprint, ensuring that sustainability claims are credible and substantiated to avoid backlash or greenwashing accusations. Discover the trends driving e-commerce in 2025 and how to position your brand for success. ... In the race to deliver faster and smarter, logistics is becoming a critical frontier for innovation.'}, {'doc_id': 2, 'source': '2025 Trends and Predictions: From AI to AR: The Bold Innovations Defining e-Commerce in 2025 - https://feedvisor.com/resources/e-commerce-strategies/bold-innovations-defining-ecommerce-2025/', 'text': '2025 isn’t just another year for e-commerce; it is a leap into a future where innovation meets imagination. Marketplaces are no longer static platforms—they are dynamic ecosystems responding to every shift in consumer behavior, global trends, and technological advancements.'}, {'doc_id': 2, 'source': '2025 Trends and Predictions: From AI to AR: The Bold Innovations Defining e-Commerce in 2025 - https://feedvisor.com/resources/e-commerce-strategies/bold-innovations-defining-ecommerce-2025/', 'text': 'In 2025, social commerce will generate $2 trillion in global eCommerce sales, representing 27% of total transactions. This explosive growth and influence is fueled by social and messaging platforms transforming into shopping hubs that merge storytelling with seamless purchasing. Platforms like TikTok, YouTube and Instagram are evolving into digital concierges.'}, {'doc_id': 3, 'source': '8 Predictions for the Future of eCommerce in 2025: AI & Innovation | Sitecore - https://www.sitecore.com/resources/insights/ecommerce/the-2025-ai-evolution', 'text': 'Understand how circular marketplaces are gaining traction and why brands are being asked to reimagine their commerce strategy to align with behaviors, values, and more.'}, {'doc_id': 3, 'source': '8 Predictions for the Future of eCommerce in 2025: AI & Innovation | Sitecore - https://www.sitecore.com/resources/insights/ecommerce/the-2025-ai-evolution', 'text': 'In this article, we explore the top 8 predictions from our partners, including the integration of content and commerce, conversational commerce, and voice-enabled shopping, all focused on creating personalized, frictionless customer journeys. As we look toward 2025, it’s clear that commerce is on the verge of a major transformation, driven by cutting-edge innovations like headless platforms, AI-driven personalization, and immersive AR/VR experiences.'}, {'doc_id': 3, 'source': '8 Predictions for the Future of eCommerce in 2025: AI & Innovation | Sitecore - https://www.sitecore.com/resources/insights/ecommerce/the-2025-ai-evolution', 'text': 'These architectures aren’t just powering personalization and seamless shopping journeys—they’re providing the backbone for game-changing innovations like conversational commerce, voice-enabled shopping, and AI-driven product discovery. As we enter 2025, brands that embrace these trends will not only meet the growing demands of their customers but also position themselves as leaders in the next wave of commerce innovation.'}, {'doc_id': 3, 'source': '8 Predictions for the Future of eCommerce in 2025: AI & Innovation | Sitecore - https://www.sitecore.com/resources/insights/ecommerce/the-2025-ai-evolution', 'text': 'It will also enable brands to create a foundation for unlocking additional innovations like voice-enabled commerce, AR/VR, personalization and more. Roy Capon, Global Head of Customer Experience at Avanade · Avanade’s Roy Capon predicts that the biggest impact in 2025 will be the integration of AI across multiple facets of digital commerce.'}, {'doc_id': 4, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'By aligning AI innovation with data security best practices, e-commerce companies can provide personalized experiences without compromising customer privacy. It’s a balancing act that, when done well, can set a brand apart in a competitive market. Social commerce is set to dominate the e-commerce landscape in 2025, merging the convenience of online shopping with the interactive nature of social media. Platforms like Instagram, TikTok, and Pinterest are evolving into comprehensive buying experiences where users can discover, explore, and purchase products directly within their feeds.'}, {'doc_id': 4, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'As 85% of single-use plastic packaging ends up in landfills, brands are looking to reduce their environmental impact through sustainable packaging. In 2025, the efficiency and speed of e-commerce operations will heavily rely on supply chain innovations. By integrating technologies like AI, automation, and drones, logistics processes are becoming faster, more precise, and increasingly sustainable.'}, {'doc_id': 4, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'Augmented reality is transforming online shopping. Find out how brands are using AR technologies to deliver innovative e-commerce experiences.'}, {'doc_id': 4, 'source': 'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/', 'text': 'As e-commerce grows more complex, more brands will look to composable commerce in their quest for innovation and competitive differentiation. From hyper-personalized shopping experiences to customer support and advanced security measures, one thing is clear: In 2025, AI will be a driving force working behind the scenes – and alongside humans – to deliver seamless, efficient, and personalized e-commerce experiences.'}, {'doc_id': 5, 'source': 'Dani Nadel | President and COO - Feedvisor | Forbes Technology Council - https://councils.forbes.com/profile/Dani-Nadel-President-COO-Feedvisor/a3ddd531-4ba5-4cb4-bc5e-a0eda340fc48', 'text': 'Find articles by Dani Nadel, President and COO of Feedvisor in the Information Technology & Services industry and member of the Forbes Technology Council'}, {'doc_id': 5, 'source': 'Dani Nadel | President and COO - Feedvisor | Forbes Technology Council - https://councils.forbes.com/profile/Dani-Nadel-President-COO-Feedvisor/a3ddd531-4ba5-4cb4-bc5e-a0eda340fc48', 'text': 'Her innovative curriculum focuses on principles, tools, and techniques in digital marketing and explores how to create value in today’s hyper-competitive environment. Nadel came to Feedvisor following a nearly six-year tenure as Chief Digital Marketing Officer, Clubs and E-Commerce at Scholastic, ultimately transforming the company’s digital experience through strategic content, e-commerce, and marketing, as well as leading Scholastic’s transition to technology-enabled reading.'}, {'doc_id': 5, 'source': 'Dani Nadel | President and COO - Feedvisor | Forbes Technology Council - https://councils.forbes.com/profile/Dani-Nadel-President-COO-Feedvisor/a3ddd531-4ba5-4cb4-bc5e-a0eda340fc48', 'text': 'Prior to Scholastic, Nadel served as president of Publicis Modem, a full-service digital agency, as well as senior vice president of marketing at Digitas, a Publicis subsidiary. She holds both a BSBA from Washington University in St. Louis and an MBA from the Carroll School of Management at Boston College. ... This year, commerce isn’t just about transactions—it’s about stories, experiences and connections that are personal and unforgettable.'}, {'doc_id': 5, 'source': 'Dani Nadel | President and COO - Feedvisor | Forbes Technology Council - https://councils.forbes.com/profile/Dani-Nadel-President-COO-Feedvisor/a3ddd531-4ba5-4cb4-bc5e-a0eda340fc48', 'text': 'Those who keep apace of the latest trends understand how they may apply to their business holistically and experiment with a mindset to learn will yield the greatest consumer connections in the new year and beyond.'}, {'doc_id': 6, 'source': 'Forbes: Redefining Success In An Altered E-Commerce World - https://feedvisor.com/resources/company-updates/redefining-success-altered-e-commerce-world/', 'text': 'Learn how brands are redefining success in an altered e-commerce environment from our President and COO, Dani Nadel’s, Forbes article.'}, {'doc_id': 6, 'source': 'Forbes: Redefining Success In An Altered E-Commerce World - https://feedvisor.com/resources/company-updates/redefining-success-altered-e-commerce-world/', 'text': 'Learn how success should now be defined in our President and COO, Dani Nadel’s, latest Forbes article.'}, {'doc_id': 6, 'source': 'Forbes: Redefining Success In An Altered E-Commerce World - https://feedvisor\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nThe estimated market value of the MENA e-commerce market in 2024 is $41.6 billion.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'MENA E-commerce Market Report 2025, with Projected Compound Annual Growth Rates through 2029 - https://www.globenewswire.com/news-release/2025/04/10/3059558/28124/en/MENA-E-commerce-Market-Report-2025-with-Projected-Compound-Annual-Growth-Rates-through-2029.html\\', \\'text\\': \\'Dublin, April 10, 2025 (GLOBE NEWSWIRE) -- The \"E-commerce Regional Analysis Market: Middle East and North Africa\" report has been added to ResearchAndMarkets.com\\\\\\'s offering. This report explores the E-commerce markets in the Middle East and North Africa (MENA), using 2023 as a reference year and providing forecasts from 2024 through 2029, including compound annual growth rate (CAGR) projections.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'MENA E-commerce Market Report 2025, with Projected Compound Annual Growth Rates through 2029 - https://www.globenewswire.com/news-release/2025/04/10/3059558/28124/en/MENA-E-commerce-Market-Report-2025-with-Projected-Compound-Annual-Growth-Rates-through-2029.html\\', \\'text\\': \\'An in-depth analysis of the current and future potential for e-commerce markets in the Middle East and Northern Africa (MENA) region · Analyses of the MENA market trends, with revenue data for 2023, estimates for 2024, and projected CAGRs through 2029\\'}, {\\'doc_id\\': 0, \\'source\\': \\'MENA E-commerce Market Report 2025, with Projected Compound Annual Growth Rates through 2029 - https://www.globenewswire.com/news-release/2025/04/10/3059558/28124/en/MENA-E-commerce-Market-Report-2025-with-Projected-Compound-Annual-Growth-Rates-through-2029.html\\', \\'text\\': \\'The report examines factors influencing the industry, such as technological advances, economic conditions, and business considerations, and also offers market insights into the industry landscape. Additionally, the report analyzes key players in the E-commerce sector, categorizing them by type and product segment in the MENA region.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'MENA E-commerce Market Report 2025, with Projected Compound Annual Growth Rates through 2029 - https://www.globenewswire.com/news-release/2025/04/10/3059558/28124/en/MENA-E-commerce-Market-Report-2025-with-Projected-Compound-Annual-Growth-Rates-through-2029.html\\', \\'text\\': \\'Dublin, May 06, 2025 (GLOBE NEWSWIRE) -- The \"Liquid Packaging Carton - Global Strategic Business Report\" has been added to ResearchAndMarkets.com\\\\\\'s offering.The global market for Liquid Packaging...\\'}, {\\'doc_id\\': 1, \\'source\\': \\'MENA e-commerce grew by 30% in 2024, new report suggests - Wamda - https://www.wamda.com/2025/02/mena-e-commerce-grew-30-2024-new-report-suggests\\', \\'text\\': \\'The MENA e-commerce market saw a 30%+ increase in online orders, with Saudi Arabia and the UAE leading in Gross Merchandise Value (GMV), according to Flowwow & Admitad Report. The UAE’s online orders grew by 7%, and Saudi Arabia’s by 9%, outperforming the MENA average of 5%. The regional Average Order Value (AOV) increased from $30 in 2023 to $35.6 in 2024, with the UAE rising from $89 to $102 and Saudi Arabia from $49.6 to $52.5. This reflects stronger consumer spending. The MENA e-commerce market ($50 billion) is expected to expand further in 2025, driven by AI-driven personalisation, community-based shopping, and government policies.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'MENA e-commerce grew by 30% in 2024, new report suggests - Wamda - https://www.wamda.com/2025/02/mena-e-commerce-grew-30-2024-new-report-suggests\\', \\'text\\': \\'Flowwow projects 300% growth in GMV, reaching $6 million in 2025. ... Flowwow, a UAE-based gifting marketplace, and Admitad, a partner marketing platform, have released their joint 2024 report on the e-commerce and gifting markets in the Middle East. The market, valued at $1.8 billion, saw significant online orders growth in 2024, with 7% increases in the United Arab Emirates and 9% in Saudi Arabia, solidifying their positions as the region’s industry leaders.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'MENA e-commerce grew by 30% in 2024, new report suggests - Wamda - https://www.wamda.com/2025/02/mena-e-commerce-grew-30-2024-new-report-suggests\\', \\'text\\': \"“The development of the e-commerce and gifting markets, along with support for local entrepreneurship (SMEs), drives economic growth and creates new opportunities for both individuals and local businesses in the region. The MENA region, with the UAE in particular, leads the drive in our company\\'s development in the global market. Our record-breaking 2024 results have set the stage for even greater growth to come. In 2025-2026, we are expecting a 4x increase and YoY growth of +300% in the region,” Slava Bogdan, CEO of Flowwow, commented.\"}, {\\'doc_id\\': 1, \\'source\\': \\'MENA e-commerce grew by 30% in 2024, new report suggests - Wamda - https://www.wamda.com/2025/02/mena-e-commerce-grew-30-2024-new-report-suggests\\', \\'text\\': \\'The UAE Gifting Surge: Record-Breaking 200% Growth in 2024 · Due to the overall growth of the e-commerce market, online payments, and rising incomes, MENA countries are experiencing a boom in the experience economy and online gifting sector. According to recent research, the UAE Gifting Market is projected to grow at a CAGR of 14.7% during 2024-2030.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Middle East and Africa E-Commerce Market Size 2025-2034 - https://www.expertmarketresearch.com/reports/middle-east-and-africa-e-commerce-market\\', \\'text\\': \"The market is projected to grow at a CAGR of 12.70% between 2025 and 2034, reaching a value of around USD 307.38 Billion by 2034. ... In the MENA region, about 10 million of the population use Instagram, making up about 10% of the world’s Instagram users. Influx of social media direct impacts shopping decisions. E-commerce fulfilment centres in the GCC are growing resulted by the region\\'s technologically adept and well-connected consumer base. As per industry reports, as of January 2024, South Africa had 45.34 million active internet users, which facilitates the growth of e-commerce.\"}, {\\'doc_id\\': 3, \\'source\\': \\'Middle East and Africa E-Commerce Market Size 2025-2034 - https://www.expertmarketresearch.com/reports/middle-east-and-africa-e-commerce-market\\', \\'text\\': \\'The market reached a value approximately USD 92.99 Billion in 2024. The market is projected to grow at a CAGR of 12.70% between 2025 and 2034. The market is estimated to witness a healthy growth during 2025-2034 to reach around USD 307.38 Billion by 2034.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Middle East and Africa E-Commerce Market Size 2025-2034 - https://www.expertmarketresearch.com/reports/middle-east-and-africa-e-commerce-market\\', \\'text\\': \\'Add the report to your cart with one click and proceed to register. ... Choose a payment option for a secure checkout. You will be redirected accordingly.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Middle East and Africa E-Commerce Market Size 2025-2034 - https://www.expertmarketresearch.com/reports/middle-east-and-africa-e-commerce-market\\', \\'text\\': \\'Explore our key highlights of the report and gain a concise overview of key findings, trends, and actionable insights that will empower your strategic decisions. Please note that the figures mentioned in the description serve as estimates and may vary from the actual figures presented in the final report.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'MENA e-commerce market sees 30% growth in 2024, driven by Saudi Arabia and UAE | Logistics Manager - https://www.logisticsmanager.com/mena-e-commerce-market-sees-30-growth-in-2024-driven-by-saudi-arabia-and-uae/\\', \\'text\\': \\'The e-commerce market in the Middle East and North Africa (MENA) grew by more than 30% in 2024, with Saudi Arabia and the United Arab Emirates (UAE) driving the region’s gross merchandise value (GMV), according to a new report.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'MENA e-commerce market sees 30% growth in 2024, driven by Saudi Arabia and UAE | Logistics Manager - https://www.logisticsmanager.com/mena-e-commerce-market-sees-30-growth-in-2024-driven-by-saudi-arabia-and-uae/\\', \\'text\\': \\'“The development of the e-commerce and gifting markets, along with support for local entrepreneurship, is creating new opportunities for businesses across the region. The company expects its gross merchandise value in the UAE to exceed US$6m in 2025, a fourfold increase from 2024. The MENA e-commerce market, currently valued at US$50bn, is projected to continue expanding in 2025, with AI-driven personalisation, mobile commerce and social shopping expected to play an increasing role.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'MENA e-commerce market sees 30% growth in 2024, driven by Saudi Arabia and UAE | Logistics Manager - https://www.logisticsmanager.com/mena-e-commerce-market-sees-30-growth-in-2024-driven-by-saudi-arabia-and-uae/\\', \\'text\\': \\'“MENA e-commerce is moving toward AI-driven personalisation, community-oriented strategies, and tailored marketing approaches,” said Anna Gidirim, CEO of Admitad. The report also highlighted growth in the gifting sector, particularly in the UAE, where Flowwow recorded a 212.6% increase in revenue and a 198.2% rise in gift purchases in 2024 compared to the previous year.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'MENA e-commerce market sees 30% growth in 2024, driven by Saudi Arabia and UAE | Logistics Manager - https://www.logisticsmanager.com/mena-e-commerce-market-sees-30-growth-in-2024-driven-by-saudi-arabia-and-uae/\\', \\'text\\': \\'Conducted by Flowwow, a UAE-based gifting marketplace, and Admitad, a partner marketing platform, the report is based on an analysis of more than 6.8 million online orders across MENA and found that Saudi Arabia and the UAE recorded online order growth of 9% and 7%, respectively, outperforming the regional average of 5%. The average order value (AOV) also increased, rising from US$30 in 2023 to US$35.6 in 2024 across MENA.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'GCC E-Commerce Statistics - Growth in the GCC - IstiZada - https://istizada.com/blog/gcc-e-commerce-statistics/\\', \\'text\\': \\'The total e-commerce revenue in the GCC is forecasted to touch US$50 billion by 2025, growing at a CAGR of 10.95% from 2023-2027. This growth is supported by an increasing number of online shoppers, reaching almost 60%. However, there’s a perception challenge. For several Western brands, the region’s relatively small share in global B2C e-commerce sales doesn’t seem to justify the operational, logistical, and marketing investments required to enter these markets.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'GCC E-Commerce Statistics - Growth in the GCC - IstiZada - https://istizada.com/blog/gcc-e-commerce-statistics/\\', \\'text\\': \\'With internet penetration nearing 100% and a further 80% of users embracing online shopping, this region is a great target audience for new sellers. Couple this with an e-commerce opportunity that’s set to become a $50 billion market by 2025; there’s no reason why the GCC should remain overlooked.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'GCC E-Commerce Statistics - Growth in the GCC - IstiZada - https://istizada.com/blog/gcc-e-commerce-statistics/\\', \\'text\\': \\'The UAE is anticipated to acquire the largest market share during the forecast period. It owes principally to the country having numerous shopping complexes, the establishment of luxury brands, and plenty of things to shop for, stimulating the utilization of financial cards & payments to make transactions across locations conveniently. A study conducted by international fintech company checkout.com reveals some interesting trends in the payment landscape of the MENA region.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'GCC E-Commerce Statistics - Growth in the GCC - IstiZada - https://istizada.com/blog/gcc-e-commerce-statistics/\\', \\'text\\': \\'The market size of the e-commerce industry in the GCC in 2021, by country, was as follows: According to the Dubai CommerCity report on the MEASA E-commerce landscape, the annual e-commerce growth for the GCC from 2019 to 2022 reached an impressive 33%. What’s even more noteworthy is that this growth was nearly double the global rate of 17%. The GCC’s prominent members, Saudi Arabia and the UAE, grew at 39% and 38%, respectively.\\'}, {\\'doc_\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nRetailMeNot launched the \\'5 to Buy\\' event in September 2025.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories - https://www.prnewswire.com/news-releases/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-septembers-top-five-shopping-categories-302543800.html\\', \\'text\\': \\'AUSTIN, Texas, Sept. 2, 2025 /PRNewswire/ -- Today, RetailMeNot, a leading savings and cash back destination, announces the launch of its \"5 to Buy\" September savings event - available only in the RetailMeNot app.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories - https://www.prnewswire.com/news-releases/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-septembers-top-five-shopping-categories-302543800.html\\', \\'text\\': \\'RetailMeNot\\\\\\'s team of savings experts analyzed in-house retail data and industry trends to identify the top five smartest categories to shop in September. Those insights directly shaped the \"5 to Buy\" event offerings, with each category timed to when prices are at their best so shoppers can unlock even greater savings.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories - https://www.prnewswire.com/news-releases/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-septembers-top-five-shopping-categories-302543800.html\\', \\'text\\': \\'Today, RetailMeNot, a Ziff Davis company, announces the return of Summer Checklist, a savings event running from June 5-9.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories - https://www.prnewswire.com/news-releases/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-septembers-top-five-shopping-categories-302543800.html\\', \\'text\\': \\'Today, RetailMeNot, a Ziff Davis company, kicks off the return of Spring Savecation, a savings event happening from March 6-10.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'RetailMeNot Launches \"5 to Buy\" App Event with 30% Cash Back | ZD Stock News - https://www.stocktitan.net/news/ZD/retail-me-not-launches-app-exclusive-5-to-buy-savings-event-weekly-vftjolsf0sd3.html\\', \\'text\\': \\'RetailMeNot, a Ziff Davis (NASDAQ:ZD) company, has launched its \"5 to Buy\" savings event exclusively through its mobile app for September 2025. The program offers up to 30% cash back on purchases across five key shopping categories, with new deals released every Tuesday throughout the month.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'RetailMeNot Launches \"5 to Buy\" App Event with 30% Cash Back | ZD Stock News - https://www.stocktitan.net/news/ZD/retail-me-not-launches-app-exclusive-5-to-buy-savings-event-weekly-vftjolsf0sd3.html\\', \\'text\\': \\'AUSTIN, Texas, Sept. 2, 2025 /PRNewswire/ -- Today, RetailMeNot, a leading savings and cash back destination, announces the launch of its \"5 to Buy\" September savings event - available only in the RetailMeNot app.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'RetailMeNot Launches \"5 to Buy\" App Event with 30% Cash Back | ZD Stock News - https://www.stocktitan.net/news/ZD/retail-me-not-launches-app-exclusive-5-to-buy-savings-event-weekly-vftjolsf0sd3.html\\', \\'text\\': \"View original content to download multimedia:https://www.prnewswire.com/news-releases/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-septembers-top-five-shopping-categories-302543800.html · SOURCE RetailMeNot, Inc. It\\'s an app-exclusive promotion offering up to 30% cash back on purchases across five shopping categories, with new deals released every Tuesday in September 2025. The categories are: Home & Decor (Sept 2), Toys & Gaming (Sept 9), Health & Beauty (Sept 16), Tech & Smart Home (Sept 23), and Travel (Sept 30).\"}, {\\'doc_id\\': 1, \\'source\\': \\'RetailMeNot Launches \"5 to Buy\" App Event with 30% Cash Back | ZD Stock News - https://www.stocktitan.net/news/ZD/retail-me-not-launches-app-exclusive-5-to-buy-savings-event-weekly-vftjolsf0sd3.html\\', \\'text\\': \\'RetailMeNot\\\\\\'s team of savings experts analyzed in-house retail data and industry trends to identify the top five smartest categories to shop in September. Those insights directly shaped the \"5 to Buy\" event offerings, with each category timed to when prices are at their best so shoppers can unlock even greater savings.\\'}, {\\'doc_id\\': 2, \\'source\\': \"RetailMeNot’s Strategic \\'5 to Buy\\' Event as a Catalyst for E-Commerce Engagement and Cashback Growth - https://www.ainvest.com/news/retailmenot-strategic-5-buy-event-catalyst-commerce-engagement-cashback-growth-2509/\", \\'text\\': \\'In the post-pandemic savings economy, consumer behavior has shifted toward price sensitivity and convenience, creating fertile ground for platforms like RetailMeNot to innovate. The company’s latest \"5 to Buy\" event, launched in September 2025, exemplifies this trend by leveraging app-exclusive weekly cash back offers in five key categories—Home & Decor, Toys & Gaming, Health & Beauty, Tech & Smart Home, and Travel.\\'}, {\\'doc_id\\': 2, \\'source\\': \"RetailMeNot’s Strategic \\'5 to Buy\\' Event as a Catalyst for E-Commerce Engagement and Cashback Growth - https://www.ainvest.com/news/retailmenot-strategic-5-buy-event-catalyst-commerce-engagement-cashback-growth-2509/\", \\'text\\': \\'The event’s structure reflects a deep understanding of modern consumer preferences. By partnering with major retailers like Walmart, Best Buy, and Amazon, RetailMeNot taps into existing brand loyalty while introducing users to new products through stacked cash back incentives.\\'}, {\\'doc_id\\': 2, \\'source\\': \"RetailMeNot’s Strategic \\'5 to Buy\\' Event as a Catalyst for E-Commerce Engagement and Cashback Growth - https://www.ainvest.com/news/retailmenot-strategic-5-buy-event-catalyst-commerce-engagement-cashback-growth-2509/\", \\'text\\': \\'RetailMeNot’s Stackable Savings™ technology, which automatically combines discounts, promo codes, and cash back, further simplifies the purchasing process, addressing a key pain point in e-commerce [5]. Retail tech innovation is central to the \"5 to Buy\" event’s success.\\'}, {\\'doc_id\\': 2, \\'source\\': \"RetailMeNot’s Strategic \\'5 to Buy\\' Event as a Catalyst for E-Commerce Engagement and Cashback Growth - https://www.ainvest.com/news/retailmenot-strategic-5-buy-event-catalyst-commerce-engagement-cashback-growth-2509/\", \\'text\\': \\'For investors, the event represents a strategic play to capitalize on the $1.3 trillion U.S. digital coupon market, which continues to expand as consumers prioritize savings [4]. The post-pandemic landscape demands agility, and RetailMeNot’s \"5 to Buy\" event demonstrates the company’s ability to adapt.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories | MarketScreener Saudi Arabia - https://sa.marketscreener.com/news/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-september-s-top-fiv-ce7c50d3de8cf127\\', \\'text\\': \\'AUSTIN, Texas, Sept. 2, 2025 /PRNewswire/ -- Today, RetailMeNot, a leading savings and cash back destination, announces the launch of its \"5 to Buy\" September savings event - available only in the RetailMeNot app.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories | MarketScreener Saudi Arabia - https://sa.marketscreener.com/news/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-september-s-top-fiv-ce7c50d3de8cf127\\', \\'text\\': \\'View original content to download multimedia:https://www.prnewswire.com/news-releases/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-septembers-top-five-shopping-categories-302543800.html · SOURCE RetailMeNot, Inc. ... Ziff Davis, Inc. is a vertically focused digital media and Internet company. Its portfolio includes brands in technology, shopping, gaming and entertainment, connectivity, health, cybersecurity, and Martech. Its segments include Digital Media and Cybersecurity and Martech. The Digital Media segment specializes in the technology, shopping, gaming and entertainment, connectivity, and healthcare markets, offering content, tools, and services to consumers and businesses.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories | MarketScreener Saudi Arabia - https://sa.marketscreener.com/news/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-september-s-top-fiv-ce7c50d3de8cf127\\', \\'text\\': \\'The Cybersecurity and Martech segment provides cloud-based subscription services to consumers and businesses, including cybersecurity, privacy, and marketing technology. It markets its Cybersecurity and Martech offerings to a spectrum of prospective business customers. ... RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories\\'}, {\\'doc_id\\': 3, \\'source\\': \\'RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories | MarketScreener Saudi Arabia - https://sa.marketscreener.com/news/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-september-s-top-fiv-ce7c50d3de8cf127\\', \\'text\\': \\'RetailMeNot\\\\\\'s team of savings experts analyzed in-house retail data and industry trends to identify the top five smartest categories to shop in September. Those insights directly shaped the \"5 to Buy\" event offerings, with each category timed to when prices are at their best so shoppers can unlock even greater savings.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories | Morningstar - https://www.morningstar.com/news/pr-newswire/20250902da62963/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-septembers-top-five-shopping-categories\\', \\'text\\': \\'RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories ... AUSTIN, Texas, Sept. 2, 2025 · Every Tuesday in September, a new shopping category is spotlighted with one-day-only cash back offers · Score savings from top retailers like Walmart, Best Buy, Tarte Cosmetics, Amazon, Away and more · All deals are available exclusively in the RetailMeNot mobile app\\'}, {\\'doc_id\\': 4, \\'source\\': \\'RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories | Morningstar - https://www.morningstar.com/news/pr-newswire/20250902da62963/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-septembers-top-five-shopping-categories\\', \\'text\\': \\'AUSTIN, Texas, Sept. 2, 2025 /PRNewswire/ -- Today, RetailMeNot, a leading savings and cash back destination, announces the launch of its \"5 to Buy\" September savings event - available only in the RetailMeNot app.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'RetailMeNot Launches App-Exclusive \"5 to Buy\" Savings Event: Weekly Cash Back on September\\\\\\'s Top Five Shopping Categories | Morningstar - https://www.morningstar.com/news/pr-newswire/20250902da62963/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-on-septembers-top-five-shopping-categories\\', \\'text\\': \\'View original content to download multimedia:https://www.prnewswire.com/news-releases/retailmenot-launches-app-exclusive-5-to-buy-savings-event-weekly-cash-back-\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nGrace Hopper developed the first compiler in 1952.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'History of compiler construction - Wikipedia - https://en.wikipedia.org/wiki/History_of_compiler_construction\\', \\'text\\': \\'The first implemented compiler was written by Grace Hopper, who also coined the term \"compiler\", referring to her A-0 system which functioned as a loader or linker, not the modern notion of a compiler. The first Autocode and compiler in the modern sense were developed by Alick Glennie in 1952 at the University of Manchester for the Mark 1 computer.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'History of compiler construction - Wikipedia - https://en.wikipedia.org/wiki/History_of_compiler_construction\\', \\'text\\': \\'Even so, it took a while for compilers to become established, because they generated code that did not perform as well as hand-written assembler, they were daunting development projects in their own right, and the very limited memory capacity of early computers created many technical problems for practical compiler implementations. Between 1942 and 1945, Konrad Zuse developed Plankalkül (\"plan calculus\"), the first high-level language for a computer, for which he envisioned a Planfertigungsgerät (\"plan assembly device\"), which would automatically translate the mathematical formulation of a program into machine-readable punched film stock.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'History of compiler construction - Wikipedia - https://en.wikipedia.org/wiki/History_of_compiler_construction\\', \\'text\\': \"Building a self-hosting compiler is a bootstrapping problem, i.e. the first such compiler for a language must be either hand written machine code, compiled by a compiler written in another language, or compiled by running the compiler\\'s source on itself in an interpreter. Corrado Böhm developed a language, a machine, and a translation method for compiling that language on the machine in his PhD dissertation submitted in 1951.\"}, {\\'doc_id\\': 0, \\'source\\': \\'History of compiler construction - Wikipedia - https://en.wikipedia.org/wiki/History_of_compiler_construction\\', \\'text\\': \\'He not only described a complete compiler, but also defined for the first time that compiler in its own language. The language was interesting in itself, because every statement (including input statements, output statements and control statements) was a special case of an assignment statement. The Navy Electronics Laboratory International ALGOL Compiler or NELIAC was a dialect and compiler implementation of the ALGOL 58 programming language developed by the Naval Electronics Laboratory in 1958.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'History of compiler construction - Wikipedia - https://en.wikipedia.org/wiki/History_of_compiler_construction\\', \\'text\\': \\'In the early 1960s, Robert McClure at Texas Instruments invented a compiler-compiler called TMG, the name taken from \"transmogrification\". In the following years TMG was ported to several UNIVAC and IBM mainframe computers. The Multics project, a joint venture between MIT and Bell Labs, was one of the first to develop an operating system in a high-level language.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Compiler - Wikipedia - https://en.wikipedia.org/wiki/Compiler\\', \\'text\\': \"Some early milestones in the development of compiler technology: May 1952: Grace Hopper\\'s team at Remington Rand wrote the compiler for the A-0 programming language (and coined the term compiler to describe it), although the A-0 compiler functioned more as a loader or linker than the modern notion of a full compiler.\"}, {\\'doc_id\\': 1, \\'source\\': \\'Compiler - Wikipedia - https://en.wikipedia.org/wiki/Compiler\\', \\'text\\': \\'1952, before September: An Autocode compiler developed by Alick Glennie for the Manchester Mark I computer at the University of Manchester is considered by some to be the first compiled programming language.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Compiler - Wikipedia - https://en.wikipedia.org/wiki/Compiler\\', \\'text\\': \\'Theoretical computing concepts developed by scientists, mathematicians, and engineers formed the basis of digital modern computing development during World War II. Primitive binary languages evolved because digital devices only understand ones and zeros and the circuit patterns in the underlying machine architecture. In the late 1940s, assembly languages were created to offer a more workable abstraction of the computer architectures. Limited memory capacity of early computers led to substantial technical challenges when the first compilers were designed.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Compiler - Wikipedia - https://en.wikipedia.org/wiki/Compiler\\', \\'text\\': \\'It was developed by John Backus and used for the syntax of Algol 60. The ideas derive from the context-free grammar concepts by linguist Noam Chomsky. \"BNF and its extensions have become standard tools for describing the syntax of programming notations. In many cases, parts of compilers are generated automatically from a BNF description.\" Between 1942 and 1945, Konrad Zuse designed the first (algorithmic) programming language for computers called Plankalkül (\"Plan Calculus\").\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Compiler - Wikipedia - https://en.wikipedia.org/wiki/Compiler\\', \\'text\\': \"Multics was written in the PL/I language developed by IBM and IBM User Group. IBM\\'s goal was to satisfy business, scientific, and systems programming requirements. There were other languages that could have been considered but PL/I offered the most complete solution even though it had not been implemented. For the first few years of the Multics project, a subset of the language could be compiled to assembly language with the Early PL/I (EPL) compiler by Doug McIlory and Bob Morris from Bell Labs.\"}, {\\'doc_id\\': 2, \\'source\\': \\'machine instruction - How was the first compiler written? - Stack Overflow - https://stackoverflow.com/questions/1653649/how-was-the-first-compiler-written\\', \\'text\\': \\'The question is about the first compiler, not the first programs in general, despite programs sometimes being compilers; the history of the two is not the same. (An analogy: the answer to the question of when the first animals appeared on the Earth is not the answer to the question of when the first cats appeared on the Earth, despite cats being animals.) ... A human did. Read about the A-0 system: In 1952, Grace Hopper completed her first compiler for Sperry, known as the A-0.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'machine instruction - How was the first compiler written? - Stack Overflow - https://stackoverflow.com/questions/1653649/how-was-the-first-compiler-written\\', \\'text\\': \\'@mehaase this is why it is called \"compiler\". it makes a compilation of routines, each of which is (potentially) written in machine language directly. ... @MarkE.Haase The people Hopper referred to here were applications engineers and scientists using computers to for specific calculation tasks; they were not \"computer scientists\". There was a handful of cyberneticists around in 1952, but I doubt that she spoke to any of those.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'machine instruction - How was the first compiler written? - Stack Overflow - https://stackoverflow.com/questions/1653649/how-was-the-first-compiler-written\\', \\'text\\': \\'However, most of the time it\\\\\\'s simpler to use an assembler to \"compile\" assembly code, which automatically does these opcode lookups, as well as being helpful in computing addresses/offsets for named jump labels, et cetera.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'machine instruction - How was the first compiler written? - Stack Overflow - https://stackoverflow.com/questions/1653649/how-was-the-first-compiler-written\\', \\'text\\': \\'The first assemblers were written by hand. Those assemblers could then be used to assemble more complicated assemblers, which could then be use to assemble compilers written for higher-level languages, and so on.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Did Grace Hopper Create the First Compiler? – Communications of the ACM - https://cacm.acm.org/blogcacm/did-grace-hopper-create-the-first-compiler/\\', \\'text\\': \\'Heinz Rutishauser (ETH Zurich, Switzerland) is regarded as the developer of automatic programming. This is the fundament for the compiler (program for the translation of a higher programming language to machine language) (see Heinz Rutishauser: Automatische Rechenplanfertigung bei programmgesteuerten Rechenmaschinen, Birkhäuser Verlag, Basel 1952).\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Did Grace Hopper Create the First Compiler? – Communications of the ACM - https://cacm.acm.org/blogcacm/did-grace-hopper-create-the-first-compiler/\\', \\'text\\': \\'Friedrich Bauer (Germany), for example, also contributed to its development. Algol served as the foundation for a series of \"descendants\" (algorithmic languages) such as Pascal. With his programming language Plankalkül, Zuse was far ahead of his time. Since practically no notice was taken of this, however, its influence was naturally very limited. Grace Hopper (USA, 1952) and Corrado Böhm (Italy, 1954) were concerned with formula translators (compilers), as were Halcombe Laning and Niel Zierler (USA, 1954).\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Did Grace Hopper Create the First Compiler? – Communications of the ACM - https://cacm.acm.org/blogcacm/did-grace-hopper-create-the-first-compiler/\\', \\'text\\': \\'The experiences with the Z4 Zuse machine at the ETH Zurich prompted the Italian Corrado Böhm to develop a compiler (doctoral dissertation 1954). ... In their contribution \"Programming for high-speed digital calculating machines\" (1953), the British computer scientists J. M. Bennett and Alick E. Glennie mention the name Autocode. According to Christopher S. Strachey, this compiler was used from September 1952 with the Manchester Mark 1 computer.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Did Grace Hopper Create the First Compiler? – Communications of the ACM - https://cacm.acm.org/blogcacm/did-grace-hopper-create-the-first-compiler/\\', \\'text\\': \\'Nevertheless, Knuth considers Glennie to be the creator of the first true compiler which was actually implemented and used (see Donald E. Knuth; Luis Trabb Pardo: The early development of programming languages, in: Nicholas Constantine Metropolis; Jack Howlett; Gian-Carlo Rota (editors): A history of computing in the twentieth century, Academic Press, New York, London etc. 1980, pages 218 ff.). ... A first \"compiler\" called A-0 of Grace Murray Hopper was in operation with the Univac computer in the spring of 1952.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'r/AskHistorians on Reddit: Did Grace Hopper actually invent the compiler? - https://www.reddit.com/r/AskHistorians/comments/p6ztyw/did_grace_hopper_actually_invent_the_compiler/\\', \\'text\\': \\'This earlier development is the context of Hopper\\\\\\'s compiler. Her definition of a \"compiler\" was a: program-making routine, which produces a specific program for a particular problem. The \"A\" in the name A-0 came from \"Automatic Programming\", as per her definition of \"compiler\". Her A-0 of 1952 was followed by A-1 and A-2 in 1953. The first compiler for computers which stored their programs in memory was developed shortly afterwards.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'r/AskHistorians on Reddit: Did Grace Hopper actually invent the compiler? - https://www.reddit.com/r/AskHistorians/comments/p6ztyw/did_grace_hopper_actually_invent_the_compiler/\\', \\'text\\': \\'My compiler textbook (dragon book 2e from the 80s) credits Backus et al. For having invented the Fortran compiler. I have heard much about Grace…\\'}, {\\'doc_id\\': 4, \\'source\\': \\'r/AskHistorians on Reddit: Did Grace Hopper actually invent the compiler? - https://www.reddit.com/r/AskHistorians/comments/p6ztyw/did_grace_hopper_actually_invent_the_compiler/\\', \\'text\\': \\'Hopper\\\\\\'s compiler, called \"A-0\", was written for the UNIVAC, and was in use in 1952. The idea of a compiler, in the full modern sense, was a few years older. Konrad Zuse, who in 1941 completed a Turing-complete electromechanical programmable computer, the Z3, developed the idea of the compiler a few years after the war.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'r/AskHistorians on Reddit: Did Grace Hopper actually invent the compiler? - https://www.reddit.com/r/AskHistorians/comments/p6ztyw/did_grace_hopper_actually_invent_the_compiler/\\', \\'text\\': \\'He developed a high-level programming language for the Z4, \"Plankalkül\" (which can be translated as \"planning system\"). He was able to resume work with the Z4, and continued work on Plankalkül and a compiler for it, \"Planfertigungsgeräte\" (\"plan preparation device\"). Planfertigungsgeräte wasn\\\\\\'t completed, although the design was improved (and its name changed to \"Programmator\" in 1952).\\'}, {\\'doc_id\\': 7, \\'source\\': \\'History of Compiler Design. In this blog I’ll be trying to shadow… | by Pritesh Pawar | Medium - https://medium.com/@PowerPP/history-of-compiler-design-c48bfa78122e\\', \\'text\\': \\'History of Compiler Design In this blog I’ll be trying to shadow the history of compilers in detail along with the basic introduction to compilers and it’s optimization. Starting with what a …\\'}, {\\'doc_id\\': 7, \\'source\\': \\'History of Compiler Design. In this blog I’ll be trying to shadow… | by Pritesh Pawar | Medium - https://medium.com/@PowerPP/history-of-compiler-design-c48bfa78122e\\', \\'text\\': \\'In this blog I’ll be trying to shadow the history of compilers in detail along with the basic introduction to compilers and it’s…\\'}, {\\'doc_id\\': 7, \\'source\\': \\'History of Compiler Design. In this blog I’ll be trying to shadow… | by Pritesh Pawar | Medium - https://medium.com/@PowerPP/history-of-compiler-design-c48bfa78122e\\', \\'text\\': \\'Towards the end of the 1950s, machine-independent programming languages were first proposed. Subsequently, several experimental compilers were developed. The first compiler was written by Grace Hopper, in 1951, for the A-0 programming language.\\'}, {\\'doc_id\\': 7, \\'source\\': \\'History of Compiler Design. In this blog I’ll be trying to shadow… | by Pritesh Pawar | Medium - https://medium.com/@PowerPP/history-of-compiler-design-c48bfa78122e\\', \\'text\\': \\'In early days of compiler development, self hosting compilers were made. A compiler can be self hosted means it is written in programming language that it compiles, Building a self-hosting compiler is a bootstrapping problem, i.e. the first such compiler for a language must be either handwritten machine code or compiled by a compiler written in another language, or compiled by running the compiler in an interpreter.\\'}, {\\'doc_id\\': 8, \\'source\\': \\'The First Compiler - ORPALIS Technologies Series - https://www.orpalis.com/blog/the-first-compiler/\\', \\'text\\': \\'It was during those civilian years that she invented the first compiler. Eckert-Mauchly Computer and its successors developed a series of computers under the name “UNIVAC” (standing for UNIVersal Automatic Computer). From this family, the UNIVAC I remained particularly notorious for at least 2 reasons. One of the reasons is that an UNIVAC 1 (built for the U.S. Atomic Energy Commission) was used by CBS television to get a prediction on the result of the 1952 presidential elections in the USA.\\'}, {\\'doc_id\\': 8, \\'source\\': \\'\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nThe global e-commerce market size in 2025 was USD 21.62 trillion.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'E-commerce Market Size to Hit USD 75.12 Trn by 2034 - https://www.precedenceresearch.com/e-commerce-market\\', \\'text\\': \\'Asia Pacific region will lead the global e-commerce market during the forecast period 2025 to 2034. ... No cookie-cutter, only authentic analysis – take the 1st step to become a Precedence Research client\\'}, {\\'doc_id\\': 0, \\'source\\': \\'E-commerce Market Size to Hit USD 75.12 Trn by 2034 - https://www.precedenceresearch.com/e-commerce-market\\', \\'text\\': \\'For inquiries regarding discounts, bulk purchases, or customization requests, please contact us at sales@precedenceresearch.com · The global e-commerce market size exceeded USD 18.77 trillion in 2024 and it is expected to increase USD 75.12 trillion by 2034. The global e-commerce market will register growth rate of 14.88% between 2025 and 2034.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'E-commerce Market Size to Hit USD 75.12 Trn by 2034 - https://www.precedenceresearch.com/e-commerce-market\\', \\'text\\': \\'China is the sole competitor with the highest e-commerce sales globally. The rising demand for e-commerce in industries leads to the expansion of several businesses across regions.  · Additionally, according to the latest report published by GSMA “Mobile Economy Asia Pacific” in 2022, more than 400 million 5G connections, or slightly over 14% of all mobile connections, will exist by 2025.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'E-commerce Market Size to Hit USD 75.12 Trn by 2034 - https://www.precedenceresearch.com/e-commerce-market\\', \\'text\\': \"According to the GSMA, a third of the world\\'s population, or around 1.2 billion connections, will be covered by 5G networks by 2025. The rise of mobile devices and apps has extended the reach of e-commerce, enabling customers to shop on the go. Moreover, emerging technologies like artificial intelligence (AI), virtual reality (VR), and augmented reality (AR) are transforming how products are showcased and experienced online. The global e-commerce market is driven by the increasing integration of advanced technologies such as AI, VR and AR, the growing inclination of consumers towards online shopping, rising investment, growing collaboration and increasing government initiatives.\"}, {\\'doc_id\\': 1, \\'source\\': \\'B2C E-Commerce Market Size and Forecast 2025 to 2034 - https://www.precedenceresearch.com/b2c-e-commerce-market\\', \\'text\\': \\'According to Precedence Research, the global B2C e-commerce market size was reached at USD 6.55 trillion in 2024 and is anticipated to surpass USD 37.72 trillion by 2034. The global B2C e-commerce market is expected to drive growth at a CAGR of 19.13% over the forecast period 2025 to 2034.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'B2C E-Commerce Market Size and Forecast 2025 to 2034 - https://www.precedenceresearch.com/b2c-e-commerce-market\\', \\'text\\': \\'Asia Pacific dominated the global b2c e-commerce market in 2024 and will remains its dominance over the forecast period 2025 to 2034. ... No cookie-cutter, only authentic analysis – take the 1st step to become a Precedence Research client\\'}, {\\'doc_id\\': 1, \\'source\\': \\'B2C E-Commerce Market Size and Forecast 2025 to 2034 - https://www.precedenceresearch.com/b2c-e-commerce-market\\', \\'text\\': \\'The global b2c e-commerce market size is calculated at USD 7.81 trillion in 2025 and is forecasted to reach around USD 37.72 trillion by 2034, accelerating at a CAGR of 19.13% from 2025 to 2034. The Asia Pacific market size surpassed USD 3.86 trillion in 2024 and is expanding at a CAGR of 19.25% during the forecast period.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'B2C E-Commerce Market Size and Forecast 2025 to 2034 - https://www.precedenceresearch.com/b2c-e-commerce-market\\', \\'text\\': \\'Last Updated : 18 Jun 2025 | Report Code : 1590 | Category : ICT | Format : PDF / PPT / Excel ... The global b2c e-commerce market size accounted for USD 6.55 trillion in 2024 and is expected to exceed around USD 37.72 trillion by 2034, growing at a CAGR of 19.13% from 2025 to 2034.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics\\', \\'text\\': \\'Get an inside look at the global ecommerce landscape, with the top ecommerce statistics and trends to follow in 2025. ... Ecommerce is many things: cross-border commerce, borderless business, and international online retail. But more important than what it is, is what it isn’t.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics\\', \\'text\\': \\'The live commerce market in China was $562 billion in 2023 and is expected to increase to $843 billion in 2025. It made up 19.2% of the retail ecommerce sales in 2023.  · In the US, livestreaming was expected to reach $31 billion in 2023, almost triple the size in 2021.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics\\', \\'text\\': \\'Online retail continues to expand due to the increasing use of smartphones and tablets globally. The global mobile commerce market was worth $2.2 trillion in 2023, making up 60% of all global ecommerce sales. Global social commerce sales are set to reach $1.2 trillion by 2025.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics\\', \\'text\\': \"Types + Examples · Unified commerce for the world\\'s most ambitious brandsLearn More · popular postsDirect to consumer (DTC)The Complete Guide to Direct-to-Consumer (DTC) Marketing (2025)Tips and strategiesEcommerce Personalization: Benefits, Examples, and 7 Tactics for 2025Unified commerceHow To Sell on Multiple Channels Without the Logistical Headache (2025)Enterprise ecommerceComposable Commerce: What It Means and Is It Right for You?\"}, {\\'doc_id\\': 3, \\'source\\': \\'eCommerce - Worldwide | Statista Market Forecast - https://www.statista.com/outlook/emo/ecommerce/worldwide\\', \\'text\\': \\'User penetration will be 42.4% in 2025 and is expected to hit 49.1% by 2029. The average revenue per user (ARPU) is expected to amount to US$1,728.00. Key regions: United States, Asia, China, Japan, South Korea Market definition ... eCommerce, short for electronic commerce, refers to the sale of physical goods via a digital channel to a private end consumer (B2C).\\'}, {\\'doc_id\\': 3, \\'source\\': \\'eCommerce - Worldwide | Statista Market Forecast - https://www.statista.com/outlook/emo/ecommerce/worldwide\\', \\'text\\': \\'Revenue in the eCommerce Market is projected to reach US$4,791.00bn in 2025.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'eCommerce - Worldwide | Statista Market Forecast - https://www.statista.com/outlook/emo/ecommerce/worldwide\\', \\'text\\': \\'Revenue is expected to show an annual growth rate (CAGR 2025-2029) of 7.83%, resulting in a projected market volume of US$6,478.00bn by 2029.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'eCommerce - Worldwide | Statista Market Forecast - https://www.statista.com/outlook/emo/ecommerce/worldwide\\', \\'text\\': \\'With a projected market volume of US$1,773.00bn in 2025, most revenue is generated in China.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'E-Commerce Market Report 2025 - Research and Markets - https://www.researchandmarkets.com/reports/5735260/e-commerce-market-report\\', \\'text\\': \\'The e-commerce market size has grown rapidly in recent years. It will grow from $4.49 trillion in 2024 to $5.06 trillion in 2025 at a compound annual growth rate (CAGR) of 12.7%. The growth in the historic period can be attributed to internet penetration, evolving consumer behavior, secure payment solutions, mobile adoption and apps, globalization and cross-border trade.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'E-Commerce Market Report 2025 - Research and Markets - https://www.researchandmarkets.com/reports/5735260/e-commerce-market-report\\', \\'text\\': \\'E-Commerce Global Market Report 2025 provides strategists, marketers and senior management with the critical information they need to assess the market. This report focuses on e-commerce market which is experiencing strong growth.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'E-Commerce Market Report 2025 - Research and Markets - https://www.researchandmarkets.com/reports/5735260/e-commerce-market-report\\', \\'text\\': \\'The e-commerce market research report is one of a series of new reports that provides e-commerce market statistics, including e-commerce industry global market size, regional shares, competitors with an e-commerce market share, detailed e-commerce market segments, market trends and opportunities, and any further data you may need to thrive in the e-commerce industry.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'E-Commerce Market Report 2025 - Research and Markets - https://www.researchandmarkets.com/reports/5735260/e-commerce-market-report\\', \\'text\\': \\'The e-commerce market global report answers all these questions and many more. The report covers market characteristics, size and growth, segmentation, regional and country breakdowns, competitive landscape, market shares, trends and strategies for this market.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'E-commerce Market Size, Share And Growth Report, 2030 - https://www.grandviewresearch.com/industry-analysis/e-commerce-market\\', \\'text\\': \\'The global e-commerce market size was estimated at USD 25.93 trillion in 2023 and is projected to reach USD 83.26 trillion by 2030, growing at a CAGR of 18.9% from 2024 to 2030. Changes in the purchasing habits of consumers have significantly facilitated the expansion of e-commerce.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'E-commerce Market Size, Share And Growth Report, 2030 - https://www.grandviewresearch.com/industry-analysis/e-commerce-market\\', \\'text\\': \\'The program, supported by eBay Inc., will empower developing entrepreneurs with guidance, tools, and opportunities to shape the future of e-commerce. This report forecasts market value growth at global, regional, and country levels and provides an analysis of the latest industry trends in each of the sub-segments from 2018 to 2030. For this study, Grand View Research has segmented the global e-commerce market report based on product, model type, and region:\\'}, {\\'doc_id\\': 5, \\'source\\': \\'E-commerce Market Size, Share And Growth Report, 2030 - https://www.grandviewresearch.com/industry-analysis/e-commerce-market\\', \\'text\\': \\'The platform utilizes the use of data analytics and AI to enhance its offerings and customize recommendations according to client requirements. The following are the leading companies in the e-commerce market. These companies collectively hold the largest market share and dictate industry trends. Amazon.com, Inc. ... MercadoLibre S.R.L. ... In February 2024, Wix, a software company, partnered with Global-e Online to facilitate cross-border eCommerce directly to consumers.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'E-commerce Market Size, Share And Growth Report, 2030 - https://www.grandviewresearch.com/industry-analysis/e-commerce-market\\', \\'text\\': \\'The e-commerce market in France is growing significantly at a CAGR of 20.4% from 2024 to 2030. France can be considered a global fashion hub characterized by the presence of various fashion houses, luxury brands, and designer labels, such as Chanel, Dior, Louis Vuitton, and Balmain, among others, favored by consumers valuing high-quality and fashionable apparel.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/\\', \\'text\\': \\'Industry-specific and extensively researched technical data (partially from exclusive partnerships). A paid subscription is required for full access. ... In 2024, global retail e-commerce sales reached an estimated ************ U.S. dollars. Projections indicate a ** percent growth in this figure over the coming years, with expectations to come close to ************** dollars by 2028. Among the key players on the world stage, the American marketplace giant Amazon holds the title of the largest e-commerce player globally, with a gross merchandise value of nearly *********** U.S.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/\\', \\'text\\': \\'Global cross-border e-commerce market share 2016-2022 · Top challenges with cross-border e-commerce in the supply chain industry 2020 ... United Parcel Service, Inc. revenue 2008-2024 · United Parcel Service, Inc. package revenue by segment 2024 ... U.S. consumer shipping companies - customer experience 2017-2025\\'}, {\\'doc_id\\': 6, \\'source\\': \\'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/\\', \\'\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nThe projected global retail eCommerce sales for 2025 is $7.4 trillion.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/\\', \\'text\\': \\'In 2024, global retail e-commerce sales reached an estimated ************ U.S. dollars. Projections indicate a ** percent growth in this figure over the coming years, with expectations to come close to ************** dollars by 2028.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/\\', \\'text\\': \\'ACSI - U.S. customer satisfaction with online retail as of 2025\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/\\', \\'text\\': \\'Premium Statistic U.S. consumer shipping companies - customer experience 2017-2025\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Global retail e-commerce sales 2022-2028| Statista - https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/\\', \\'text\\': \\'Retail e-commerce sales worldwide from 2022 to 2028 (in billion U.S. dollars) [Graph], eMarketer, April 8, 2025.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/\\', \\'text\\': \\'Online shopping has grown steadily in popularity in recent years. In 2021, global online retail sales amounted to almost five trillion U.S. dollars, a figure expected to exceed seven trillion U.S. dollars by 2025. Digital development in Latin America boomed during the COVID-19 pandemic, generating unprecedented e-commerce growth in various economies across the region.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/\\', \\'text\\': \\'eMarketer, E-commerce as percentage of total retail sales worldwide from 2021 to 2027 Statista, https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/ (last visited January 05, 2025)\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/\\', \\'text\\': \\'E-commerce share of retail sales in Singapore 2015-2025\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Global e-commerce share of retail sales 2027 | Statista - https://www.statista.com/statistics/534123/e-commerce-share-of-retail-sales-worldwide/\\', \\'text\\': \\'eMarketer. \"E-commerce as percentage of total retail sales worldwide from 2021 to 2027.\" Chart. February 27, 2024. Statista. Accessed January 05, 2025.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Global: e-commerce retail sales CAGR 2024-2029 | Statista - https://www.statista.com/forecasts/220177/b2c-e-commerce-sales-cagr-forecast-for-selected-countries\\', \\'text\\': \\'According to recent industry calculations, Turkey will rank first among 20 countries worldwide in retail e-commerce development between 2024 and 2029, with a compound annual growth rate of 11.6 percent. The Turkish e-commerce market is currently valued at 3.4 trillion Turkish lira.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Global: e-commerce retail sales CAGR 2024-2029 | Statista - https://www.statista.com/forecasts/220177/b2c-e-commerce-sales-cagr-forecast-for-selected-countries\\', \\'text\\': \\'Statista. \"Retail e-commerce sales compound annual growth rate (CAGR) from 2024 to 2029, by country.\" Chart. June 10, 2024. Statista. Accessed January 05, 2025.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Global: e-commerce retail sales CAGR 2024-2029 | Statista - https://www.statista.com/forecasts/220177/b2c-e-commerce-sales-cagr-forecast-for-selected-countries\\', \\'text\\': \\'Statista. (2024). Retail e-commerce sales compound annual growth rate (CAGR) from 2024 to 2029, by country. Statista. Statista Inc.. Accessed: January 05, 2025.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Global: e-commerce retail sales CAGR 2024-2029 | Statista - https://www.statista.com/forecasts/220177/b2c-e-commerce-sales-cagr-forecast-for-selected-countries\\', \\'text\\': \\'Statista, Retail e-commerce sales compound annual growth rate (CAGR) from 2024 to 2029, by country Statista, https://www.statista.com/forecasts/220177/b2c-e-commerce-sales-cagr-forecast-for-selected-countries (last visited January 05, 2025)\\'}, {\\'doc_id\\': 3, \\'source\\': \\'51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/\\', \\'text\\': \\'Here is a table showing the share of online retail transactions over the years: Source: Statista. Global eCommerce sales will account for $6.86 trillion in 2025, which is an 8.37% increase from 2024.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/\\', \\'text\\': \\'In 2025, 21% of retail purchases are expected to take place online, and this share will rise to 22.6% by 2027. Ecommerce sales will surpass $6.8 trillion in 2025. There are over 28 million eCommerce stores globally. 52% of online shoppers look for products internationally. ... This section sheds light on the growth of the eCommerce sector over the years and what are its future projections.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/\\', \\'text\\': \\'The number of online shoppers will increase to 2.86 billion in 2026, reflecting the boom in eCommerce due to the increased internet penetration and convenience. China leads the online shopping trend with 904.6 million online shoppers, while the US has 288.45 million online buyers. Source: eMarketer, Statista 1, Statista 2. 21% of retail purchases will take place online in 2025, which is the highest to date.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/\\', \\'text\\': \\'This makes Amazon the biggest market share holder in the United States with Walmart in the second place with a 6.4% market share. Here is a table showing the market share of leading retail eCommerce companies in the United States in 2025: Source: Statista.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics\\', \\'text\\': \\'Get an inside look at the global ecommerce landscape, with the top ecommerce statistics and trends to follow in 2025. ... Ecommerce is many things: cross-border commerce, borderless business, and international online retail. But more important than what it is, is what it isn’t.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics\\', \\'text\\': \\'The live commerce market in China was $562 billion in 2023 and is expected to increase to $843 billion in 2025. It made up 19.2% of the retail ecommerce sales in 2023.  · In the US, livestreaming was expected to reach $31 billion in 2023, almost triple the size in 2021. Another new marketing channel coming on the horizon is connected TV (CTV) advertising—which refers to ads you’ll find on platforms like Hulu, Roku, and YouTube.  · The growth of CTV advertising spend in the US is projected to increase from $25 billion in 2023 to nearly $41 billion by 2027, while linear TV ad spend is expected to decline from $61 billion to $56 billion in the same period.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics\\', \\'text\\': \\'The ecommerce landscape in China and the Asia-Pacific (APAC) region has continued to evolve with significant growth in 2024 and projections for 2025.  · Despite a tepid start in the first half of 2023, China’s retail sector is rebounding, with retail sales growth showing signs of life as the year progresses.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Global Ecommerce Statistics: Trends to Guide Your Store in 2025 - Shopify - https://www.shopify.com/enterprise/blog/global-ecommerce-statistics\\', \\'text\\': \\'The rise of mobile commerce (m-commerce) is significant, with some forecasting it to reach $558 billion in 2024, accounting for 7.6% of total retail sales.  · In 2023, nearly 80% of global consumers used their smartphone to access a retailer’s website while shopping in-store. Another 74% used a retailer’s app while shopping, according to Insider Intelligence. M-commerce involves shopping online through mobile devices like smartphones or tablets. Mobile ecommerce will continue to break out over the next few years.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'eCommerce Growth Statistics 2025 (Sales Data & Market Trends) - https://www.shoptrial.co/ecommerce-growth-statistics/\\', \\'text\\': \\'Global e-commerce sales are expected to grow by 7.8% in 2025. As a result, the global e-commerce market is expected to reach $6.56 trillion this year. The market is projected to grow even further by the end of 2028, reaching around $8.09 trillion. Here is a table displaying the e-commerce sales growth worldwide by year: ... In 2024, global retail e-commerce sales reached an estimated $6 trillion, according to Statista.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'eCommerce Growth Statistics 2025 (Sales Data & Market Trends) - https://www.shoptrial.co/ecommerce-growth-statistics/\\', \\'text\\': \\'This article covers the latest eCommerce growth statistics, including the global market size and insights specific to the United States and other countries.  ·  Global e-commerce sales are projected to grow by 7.8% in 2025. The global online shopping market is expected to reach around $6.56 trillion this year. In 2024, e-commerce made up 17% of all retail sales worldwide.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'eCommerce Growth Statistics 2025 (Sales Data & Market Trends) - https://www.shoptrial.co/ecommerce-growth-statistics/\\', \\'text\\': \\'China tops the global e-commerce market, generating a staggering $1.47 trillion in revenue. In the U.S., e-commerce sales are projected to reach $1.3 trillion in 2025. Back in 2024, online shopping accounted for about 16% of all retail sales in the U.S.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'eCommerce Growth Statistics 2025 (Sales Data & Market Trends) - https://www.shoptrial.co/ecommerce-growth-statistics/\\', \\'text\\': \\'Here is a table displaying the share of e-commerce sales among the retail sales recorded in the United States by year: Source: United States Census Bureau. ... In 2025, worldwide e-commerce sales are projected to reach $6.56 trillion, reflecting a 7.8% increase from the previous year.  · Further, by 2027, e-commerce is expected to account for over 20% of global retail sales, highlighting its expanding influence in the retail sector.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'E-commerce worldwide - statistics & facts | Statista - https://www.statista.com/topics/871/online-shopping/\\', \\'text\\': \\'Most used payment processing technology - including payment gateways and BNPL (buy now, pay later) - on websites worldwide as of January 2025 · Premium Statistic Quarterly number of PayPal active accounts worldwide 2010-2024 · Quarterly number of PayPal active accounts worldwide 2010-2024 · Global user number of PayPal from 1st quarter 2010 to 3rd quarter 2024\\'}, {\\'doc_id\\': 6, \\'source\\': \\'E-commerce worldwide - statistics & facts | Statista - https://www.statista.com/topics/871/online-shopping/\\', \\'text\\': \\'Like many other industries, buying and selling goods has undergone a substantial transformation following the advent of the internet, and thanks to the ongoing digitalization of modern life, consumers all over the world now profit from the perks of online transactions. As global internet access and adoption rapidly increase, with over five billion internet users worldwide, the number of people making purchases online is ever-increasing. In 2024, retail e-commerce sales are estimated to exceed 4.1 trillion U.S.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'E-commerce worldwide - statistics & facts | Statista - https://www.statista\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': \"Ground Truth:\\n88% of U.S. households subscribe to at least one paid streaming video service.\\n\\nSnippet:\\n[{'doc_id': 0, 'source': 'Americans Spend $48 per Month on Video Streaming Services — and Half of Those Surveyed Say That’s Too Much - https://variety.com/2023/digital/news/consumer-spending-streaming-services-svod-deloitte-digital-trends-1235582760/', 'text': 'According to Deloitte’s 2023 Digital Media Trends survey, millennials are the most likely to have made changes to digital media subscriptions due to economic pressures. Indeed, millennials spend more than any other generation on paid streaming video services — an average of $54 per month.'}, {'doc_id': 0, 'source': 'Americans Spend $48 per Month on Video Streaming Services — and Half of Those Surveyed Say That’s Too Much - https://variety.com/2023/digital/news/consumer-spending-streaming-services-svod-deloitte-digital-trends-1235582760/', 'text': 'It’s the first time Deloitte’s Digital Media Trends survey asked respondents to put a dollar figure on their subscription-video spending. The number of SVOD services per U.S. household has held steady at around four for the last several years, while the rate of inflation has outpaced the sector’s price increases, according to Kevin Westcott, Deloitte’s U.S.'}, {'doc_id': 0, 'source': 'Americans Spend $48 per Month on Video Streaming Services — and Half of Those Surveyed Say That’s Too Much - https://variety.com/2023/digital/news/consumer-spending-streaming-services-svod-deloitte-digital-trends-1235582760/', 'text': 'As streaming video competition continues to intensify, subscription growth rates across the industry have slowed — and churn rates have increased, according to the Deloitte’s 17th annual Digital Media Trends report. On average, U.S. consumers pay $48 per month for subscription-video services, Deloitte’s survey found.'}, {'doc_id': 0, 'source': 'Americans Spend $48 per Month on Video Streaming Services — and Half of Those Surveyed Say That’s Too Much - https://variety.com/2023/digital/news/consumer-spending-streaming-services-svod-deloitte-digital-trends-1235582760/', 'text': 'The 17th edition of Deloitte’s Digital Media Trends survey was fielded online in November 2022 among 2,020 U.S.'}, {'doc_id': 1, 'source': '2023 Digital media trends survey | Deloitte Insights - https://www2.deloitte.com/us/en/insights/industry/technology/digital-media-trends-consumption-habits-survey/2023.html', 'text': 'Though early adopters of SVOD services, Millennials surveyed continue to show signs of subscription fatigue and cost-consciousness. At an average of US$54 per month, they spend the most on all their streaming video subscriptions of any generation, but our survey shows they’re also the most likely to churn through SVOD services.'}, {'doc_id': 1, 'source': '2023 Digital media trends survey | Deloitte Insights - https://www2.deloitte.com/us/en/insights/industry/technology/digital-media-trends-consumption-habits-survey/2023.html', 'text': 'As digital media behaviors evolve, streaming video providers may face more challenges. Watching TV shows or movies at home remains dominant for Gen X and older respondents, but across generations, there are frustrations around mounting costs. People are reevaluating what they’re getting for their time and money—and adjusting accordingly. ... Watching TV shows and movies remains the most enjoyed entertainment activity among Gen X and older (41+) people surveyed.'}, {'doc_id': 1, 'source': '2023 Digital media trends survey | Deloitte Insights - https://www2.deloitte.com/us/en/insights/industry/technology/digital-media-trends-consumption-habits-survey/2023.html', 'text': 'The 17th edition of the Digital Media Trends Survey was conducted by Deloitte’s Technology, Media & Telecommunications practice and fielded by an independent research firm. The online survey of 2,020 US consumers was conducted in November 2022. All data is weighted back to the most recent Census to give a representative view of what US consumers are doing.'}, {'doc_id': 1, 'source': '2023 Digital media trends survey | Deloitte Insights - https://www2.deloitte.com/us/en/insights/industry/technology/digital-media-trends-consumption-habits-survey/2023.html', 'text': 'It can also offer utility, foster community, and support emotional needs. Our survey shows younger generations gravitate toward more interactive and social experiences: places and spaces where they can escape into other worlds, find community, share what—and who—inspires them, cocreate adventures, and bring their friends along for the ride. Consumers weave together digital media experiences · As online entertainment experiences become more interwoven, one activity feeds into another.'}, {'doc_id': 2, 'source': 'U.S. households with paid streaming service surged 450% in less than a decade, study says - Los Angeles Times - https://www.latimes.com/business/hollywood/la-fi-ct-digital-media-report-deloitte-20180320-story.html', 'text': 'In yet another sign of streaming media’s growing dominance in the entertainment industry, the majority of U.S. households now subscribe to at least one digital video streaming service such as Netflix, Amazon Prime and Hulu, with a surge of original content driving consumer adoption, according to a new survey that will be released Tuesday by Deloitte. Deloitte’s 12th annual digital media trends survey shows that streaming video adoption passed the halfway mark in 2017 with 55% of U.S.'}, {'doc_id': 2, 'source': 'U.S. households with paid streaming service surged 450% in less than a decade, study says - Los Angeles Times - https://www.latimes.com/business/hollywood/la-fi-ct-digital-media-report-deloitte-20180320-story.html', 'text': 'In yet another sign of streaming media’s growing dominance in the entertainment industry, the majority of U.S. households now subscribe to at least one digital video streaming service such as Netflix, Amazon Prime and Hulu, with a surge of original content driving consumer adoption, according to a…'}, {'doc_id': 2, 'source': 'U.S. households with paid streaming service surged 450% in less than a decade, study says - Los Angeles Times - https://www.latimes.com/business/hollywood/la-fi-ct-digital-media-report-deloitte-20180320-story.html', 'text': 'Deloitte said in a new study that the percentage of U.S. households subscribing to a paid streaming video service has surged 450% since 2009.'}, {'doc_id': 2, 'source': 'U.S. households with paid streaming service surged 450% in less than a decade, study says - Los Angeles Times - https://www.latimes.com/business/hollywood/la-fi-ct-digital-media-report-deloitte-20180320-story.html', 'text': 'As more consumers cut the cord, pay TV penetration has fallen, dropping to 63% in 2017 after remaining steady at about 75% for years, according to the survey. The study showed that 16% to 22% of millennial consumers, as well as those in Generations X and Z, have never subscribed to a pay TV service and are probably unlikely to do so in the future. The majority of survey respondents said they felt they were paying too much for the value they received from a traditional pay TV subscription. Deloitte’s study found that Generation X — those who are between 35 and 51 years old — have picked up the viewing habits of younger generations, such as watching more content on mobile devices.'}, {'doc_id': 3, 'source': 'Deloitte Survey: 82% of U.S. Consumers Subscribe to at Least One Paid Streaming Video Service - Media Play News - https://www.mediaplaynews.com/deloitte-survey-82-of-u-s-consumers-subscribe-to-at-least-one-paid-streaming-video-service/', 'text': 'The average U.S. subscriber has four paid video streaming services, and 82% of U.S. consumers subscribe to at least one paid streaming video service, according to Deloitte’s annual “Digital Media Trends” survey, 15th edition. In addition, 55% of respondents now watch a free ad-supported video service.'}, {'doc_id': 3, 'source': 'Deloitte Survey: 82% of U.S. Consumers Subscribe to at Least One Paid Streaming Video Service - Media Play News - https://www.mediaplaynews.com/deloitte-survey-82-of-u-s-consumers-subscribe-to-at-least-one-paid-streaming-video-service/', 'text': 'As more consumers use advertising supported digital entertainment services, ad-related preferences and expectations around personalization and privacy vary across consumer segments and media, according to the survey. Some people welcome ads as a way to get more content while managing costs, building their own set of go-to services; others will do whatever they can to avoid advertising. ... Forty percent of U.S. consumers note that they would prefer to pay $12 a month for a streaming video service with no ads, versus 60% of consumers who would accept some ads for a reduction in monthly subscription costs.'}, {'doc_id': 3, 'source': 'Deloitte Survey: 82% of U.S. Consumers Subscribe to at Least One Paid Streaming Video Service - Media Play News - https://www.mediaplaynews.com/deloitte-survey-82-of-u-s-consumers-subscribe-to-at-least-one-paid-streaming-video-service/', 'text': 'But a new survey suggests many consumers are frustrated by their streaming experience and would prefer downloading content, according to a survey conducted by Penthera,… · Verizon Melding Go90 Streaming Video Service Into Oath Platform · Verizon’s struggling mobile streaming video service, Go90, is being folded into the telecom’s Oath platform, which includes AOL, HuffPost, Engadget, TechCrunch, Tumblr and Yahoo, Tim Armstrong, CEO of Oath, told a technology group. Speaking Feb. 13 at Recode’s Code Media…'}, {'doc_id': 3, 'source': 'Deloitte Survey: 82% of U.S. Consumers Subscribe to at Least One Paid Streaming Video Service - Media Play News - https://www.mediaplaynews.com/deloitte-survey-82-of-u-s-consumers-subscribe-to-at-least-one-paid-streaming-video-service/', 'text': 'However, from October 2020 to February 2021, Deloitte found that the churn rate for streaming video services is still hovering around 37%. ... Content (35%) and cost (46%) are the most important factors in deciding to subscribe to a new paid streaming video service. Fifty-two percent find it difficult to access content across so many services, and 49% are frustrated when a service doesn’t make good recommendations for them. Fifty-three percent of those surveyed are frustrated by needing multiple service subscriptions to access the content they want.'}, {'doc_id': 4, 'source': '2022 Digital media trends survey summary | Deloitte Insights - https://www2.deloitte.com/us/en/insights/industry/technology/digital-media-trends-consumption-habits-survey/summary.html', 'text': 'As Gen Z and Millennial entertainment choices gain favor across the globe, social and gaming experiences compete head-to-head with video for consumers’ attention.'}, {'doc_id': 4, 'source': '2022 Digital media trends survey summary | Deloitte Insights - https://www2.deloitte.com/us/en/insights/industry/technology/digital-media-trends-consumption-habits-survey/summary.html', 'text': 'Hannah Avery, “Fight to retain subscribers heats up as streaming growth stalls in the US ,” Kantar, November 3, 2021. View in Article · Tmera Hepburn, “The average U.S. household spends $47/month on streaming service subscriptions ,” Cord Cutters News, February 1, 2021.View in Article · Our consumer churn rate is the percentage of people who have cancelled, or both added and cancelled, a paid SVOD service in the last six months.'}, {'doc_id': 4, 'source': '2022 Digital media trends survey summary | Deloitte Insights - https://www2.deloitte.com/us/en/insights/industry/technology/digital-media-trends-consumption-habits-survey/summary.html', 'text': 'And even when there are lulls in engaging content, subscribers may not cancel their subscription if the cost is low enough. ... Streaming services can also use gated content to offer consumers pricing tiers. Some companies are experimenting with offering premium access to everything at a higher price and cheaper options for less content. Our global study found that many respondents thinking of cancelling a paid SVOD service would likely keep their subscriptions if they could get a discount.'}, {'doc_id': 4, 'source': '2022 Digital media trends survey summary | Deloitte Insights - https://www2.deloitte.com/us/en/insights/industry/technology/digital-media-trends-consumption-habits-survey/summary.html', 'text': 'This year’s Digital media trends survey revealed that media companies in the United States are now feeling more turbulence from the deeper currents shaping consumer behavior. After 15 years of growth, streaming video on-demand (SVOD) services have successfully unbundled video, lowered costs to consumers, and ignited fierce competition among providers. Top SVOD services are consolidating content and taking the competition for subscribers into global markets.'}, {'doc_id': 5, 'source': 'Digital media trends survey | Deloitte Insights - https://www.deloitte.com/us/en/insights/industry/technology/digital-media-trends-consumption-habits-survey/summary-2021.html', 'text': 'How can media and entertainment companies develop lasting relationships with discriminating consumers? Our latest survey reveals a world being reshaped by the COVID-19 pandemic and generational trends.'}, {'doc_id': 5, 'source': 'Digital media trends survey | Deloitte Insights - https://www.deloitte.com/us/en/insights/industry/technology/digital-media-trends-consumption-habits-survey/summary-2021.html', 'text': 'We define the five generations represented in this survey below: In this world of choice, US consumers have multiple free and paid entertainment options vying for their consideration. Most respondents said they use social media, have at least one paid streaming video service, and play video games frequently or occasionally.2 Many also subscribe to music streaming services and have a traditional pay TV subscription (figure 1).'}, {'doc_id': 5, 'source': 'Digital media trends survey | Deloitte Insights -\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nThe World Health Organization declared the COVID-19 pandemic over on May 5, 2023.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'CDC Museum COVID-19 Timeline | David J. Sencer CDC Museum | CDC - https://www.cdc.gov/museum/timeline/covid19.html\\', \\'text\\': \\'This timeline provides information about select moments in the COVID-19 pandemic in the United States and around the world beginning from its known origins to today. Late 2019 | Early 2020 | Mid 2020 | Late 2020 | Early 2021 | Mid-2021 | Late-2021 | Early 2022 | Mid 2022 · A cluster of patients in China’s Hubei Province, in the city of Wuhan, begin to experience the symptoms of an atypical pneumonia-like illness that does not respond well to standard treatments. The World Health Organization (WHO) Country Office in China is informed of several cases of a pneumonia of unknown etiology (cause) with symptoms including shortness of breath and fever occurring in Wuhan, China.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'CDC Museum COVID-19 Timeline | David J. Sencer CDC Museum | CDC - https://www.cdc.gov/museum/timeline/covid19.html\\', \\'text\\': \\'The Wisconsin Department of Health Services confirms that a child in Wisconsin has died from multisystem inflammatory syndrome in children (MIS-C), a rare but serious condition associated with COVID-19 infection in children. WHO releases data showing that the COVID-19 pandemic triggered a 25% increase in anxiety and depression worldwide, with young people and women at the highest risk.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'CDC Museum COVID-19 Timeline | David J. Sencer CDC Museum | CDC - https://www.cdc.gov/museum/timeline/covid19.html\\', \\'text\\': \\'As some countries discuss re-opening, WHO convenes the International Health Regulation Emergency Committee for a third time and declares that the global COVID-19 pandemic remains a Public Health Emergency of International Concern (PHEIC).\\'}, {\\'doc_id\\': 0, \\'source\\': \\'CDC Museum COVID-19 Timeline | David J. Sencer CDC Museum | CDC - https://www.cdc.gov/museum/timeline/covid19.html\\', \\'text\\': \\'First anniversary of WHO declaring COVID-19 a global pandemic. The Biden Administration announces plans for all adult Americans to be eligible and able to receive a COVID-19 vaccine by May 1, 2021. They plan to make COVID-19 vaccines accessible by delivering vaccines to 700 community health centers in under-resourced communities, doubling the number of pharmacies providing COVID-19 vaccines and the number of federally run mass vaccination centers, deploying more than 4,000 active-duty troops to support these efforts, and by launching the “Find a Vaccination Website” and a 1-800 Number.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'When Did the Pandemic Start and End? | Northwestern Medicine - https://www.nm.org/healthbeat/medical-advances/new-therapies-and-drug-trials/covid-19-pandemic-timeline\\', \\'text\\': \\'The COVID-19 pandemic started in March 2020. The public health emergency of international concern ended in May 2023.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'When Did the Pandemic Start and End? | Northwestern Medicine - https://www.nm.org/healthbeat/medical-advances/new-therapies-and-drug-trials/covid-19-pandemic-timeline\\', \\'text\\': \\'Worldwide tally reaches 755 million COVID-19 cases and 6.8 million deaths. The WHO declares an end to the public health emergency of international concern.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'When Did the Pandemic Start and End? | Northwestern Medicine - https://www.nm.org/healthbeat/medical-advances/new-therapies-and-drug-trials/covid-19-pandemic-timeline\\', \\'text\\': \\'In May 2023, the WHO declared an end to the public health emergency of international concern. Here’s what happened along the way. WHO declares pandemic. U.S. announces Operation Warp Speed to develop a COVID-19 vaccine as quickly as possible. U.S. reports 2 million cases. COVID-19 becomes 3rd leading cause of death in the U.S.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'When Did the Pandemic Start and End? | Northwestern Medicine - https://www.nm.org/healthbeat/medical-advances/new-therapies-and-drug-trials/covid-19-pandemic-timeline\\', \\'text\\': \\'WHO declares omicron variant of COVID-19 a “variant of concern.” · The FDA approves booster mRNA vaccines for everyone ages 18 and older.  · Omicron variant surges in the U.S., accounting for 99% of COVID-19 cases. FDA fully approves the Moderna COVID-19 vaccine for people ages 18 and older. WHO shows pandemic increased anxiety and depression by 25% worldwide — especially in young people and women.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'WHO chief declares end to COVID-19 as a global health emergency | UN News - https://news.un.org/en/story/2023/05/1136367\\', \\'text\\': \\'But he reflected that the impact of the pandemic had “exposed political fault lines, within and between nations. It has eroded trust between people, governments and institutions, fuelled by a torrent of mis- and disinformation.” · Readers can find information and guidance on the outbreak of the novel coronavirus (2019-nCoV) from the UN, World Health Organization and UN agencies here.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'WHO chief declares end to COVID-19 as a global health emergency | UN News - https://news.un.org/en/story/2023/05/1136367\\', \\'text\\': \\'Health systems in most countries have started showing the first major signs of recovery three years into the COVID-19 pandemic, which has left millions dead and hundreds of millions infected, according to a new UN report launched on Tuesday. ... The World Health Organization (WHO) on Wednesday launched a new initiative to help strengthen countries’ ability to plan for, and deal with, another deadly pandemic like COVID-19, as latest figures show a huge fall in COVID deaths this year.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'WHO chief declares end to COVID-19 as a global health emergency | UN News - https://news.un.org/en/story/2023/05/1136367\\', \\'text\\': \\'According to WHO’s Coronavirus Dashboard which has collated key statistics since early in the pandemic, the cumulative cases worldwide now stand at 765,222,932, with nearly seven million deaths: the precise figure currently stands at 6,921,614.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'WHO chief declares end to COVID-19 as a global health emergency | UN News - https://news.un.org/en/story/2023/05/1136367\\', \\'text\\': \\'For over 12 months, the pandemic “has been on a downward trend”, he said, with immunity increasing due to the highly effective vaccines developed in record time to fight the disease, and infections.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'COVID-19 pandemic - Wikipedia - https://en.wikipedia.org/wiki/COVID-19_pandemic\\', \\'text\\': \\'The COVID-19 pandemic (also known as the coronavirus pandemic and COVID pandemic), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), began with an outbreak of COVID-19 in Wuhan, China, in December 2019. Soon after, it spread to other areas of Asia, and then worldwide in early 2020. The World Health Organization (WHO) declared the outbreak a public health emergency of international concern (PHEIC) on 30 January 2020, and assessed the outbreak as having become a pandemic on 11 March.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'COVID-19 pandemic - Wikipedia - https://en.wikipedia.org/wiki/COVID-19_pandemic\\', \\'text\\': \\'As of that 28 December, 282,790,822 individuals worldwide had been confirmed as infected. As of 14 April 2022, over 500 million cases were confirmed globally. Most cases are unconfirmed, with the Institute for Health Metrics and Evaluation estimating the true number of cases as of early 2022 to be in the billions. One measure that public health officials and policymakers have used to monitor the pandemic and guide decision-making is the test positivity rate (\"percent positive\").\\'}, {\\'doc_id\\': 3, \\'source\\': \\'COVID-19 pandemic - Wikipedia - https://en.wikipedia.org/wiki/COVID-19_pandemic\\', \\'text\\': \\'On 5 May 2023, the WHO declared that the pandemic was no longer a public health emergency of international concern. This led several media outlets to incorrectly report that this meant the pandemic was \"over\".\\'}, {\\'doc_id\\': 3, \\'source\\': \\'COVID-19 pandemic - Wikipedia - https://en.wikipedia.org/wiki/COVID-19_pandemic\\', \\'text\\': \\'The WHO commented to Full Fact that it was unlikely to declare the pandemic over \"in the near future\" and mentioned cholera, which it considers to have been a pandemic since 1961 (i.e., continuously for the last 64 years). The WHO does not have an official category for pandemics or make declarations of when pandemics start or end. In June 2023, Hans Kluge, director of the WHO in Europe, commented that \"While the international public health emergency may have ended, the pandemic certainly has not\".\\'}, {\\'doc_id\\': 3, \\'source\\': \\'COVID-19 pandemic - Wikipedia - https://en.wikipedia.org/wiki/COVID-19_pandemic\\', \\'text\\': \\'Italy was the first European nation to experience a major outbreak in early 2020, becoming the first country worldwide to introduce a national lockdown. By 13 March 2020, the WHO declared Europe the epicentre of the pandemic and it remained so until the WHO announced it had been overtaken by South America on 22 May.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Global and U.S. Agencies Declare End of COVID-19 Emergency | Pfizer - https://www.pfizer.com/news/announcements/global-and-us-agencies-declare-end-covid-19-emergency\\', \\'text\\': \\'On May 5, more than three years since COVID-19 was designated as a pandemic, the World Health Organization (WHO) declared an end to the global Public Health Emergency (PHE) for COVID-19.1 Following an initial announcement earlier this year, the U.S.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Global and U.S. Agencies Declare End of COVID-19 Emergency | Pfizer - https://www.pfizer.com/news/announcements/global-and-us-agencies-declare-end-covid-19-emergency\\', \\'text\\': \\'The COVID-19 pandemic changed so much in our lives, but we must not lose sight of the lessons learned—most notably the way the global community came together to support and protect our neighbors locally and globally. ... World Health Organization. Statement on the fifteenth meeting of the IHR (2005) Emergency Committee on the COVID-19 pandemic.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Global and U.S. Agencies Declare End of COVID-19 Emergency | Pfizer - https://www.pfizer.com/news/announcements/global-and-us-agencies-declare-end-covid-19-emergency\\', \\'text\\': \\'Things are improving Over the course of the pandemic, COVID-19 vaccines and treatments have saved millions of lives and reduced hospitalizations.7,8 Since the peak of the Omicron surge at the end of January 2022, daily COVID-19 reported cases are down 92%, COVID-19 deaths have declined by over 80%, and new COVID-19 hospitalizations are down nearly 80%.9 To sustain the progress made during the pandemic and to help people protect themselves from and get treatment for COVID-19, governments and the healthcare industry must remain vigilant and maintain high levels of readiness for further COVID-19 outbreaks and the emergence of new virus variants.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Global and U.S. Agencies Declare End of COVID-19 Emergency | Pfizer - https://www.pfizer.com/news/announcements/global-and-us-agencies-declare-end-covid-19-emergency\\', \\'text\\': \\'https://www.who.int/news/item/05-05-2023-statement-on-the-fifteenth-meeting-of-the-international-health-regulations-(2005)-emergency-committee-regarding-the-coronavirus-disease-(covid-19)-pandemic. Published May 5, 2023. Accessed May 8, 2023. U.S. Health and Human Services. COVID-19 Public Health Emergency (PHE). https://www.hhs.gov/coronavirus/covid-19-public-health-emergency/index.html. Updated May 5, 2023. Accessed May 8, 2023. World Health Organization.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'WHO Declares COVID-19 a Pandemic - PMC - https://pmc.ncbi.nlm.nih.gov/articles/PMC7569573/\\', \\'text\\': \\'The World Health Organization (WHO) on March 11, 2020, has declared the novel coronavirus (COVID-19) outbreak a global pandemic (1). At a news briefing, WHO Director-General, Dr. Tedros Adhanom Ghebreyesus, noted that over the past 2 weeks, the number of cases outside China increased 13-fold and the number of countries with cases increased threefold.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'WHO Declares COVID-19 a Pandemic - PMC - https://pmc.ncbi.nlm.nih.gov/articles/PMC7569573/\\', \\'text\\': \\'8.World Health Organization. Coronavirus disease 2019 (COVID-19): Situation Report – 38. 27 February 2020 Accessed at www.who.int/docs/default-source/coronaviruse/situation-reports/20200227-sitrep-38-covid-19.pdf?sfvrsn=9f98940c_2. on 28 February 2020.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'WHO Declares COVID-19 a Pandemic - PMC - https://pmc.ncbi.nlm.nih.gov/articles/PMC7569573/\\', \\'text\\': \"Official websites use .gov A .gov website belongs to an official government organization in the United States. Secure .gov websites use HTTPS A lock ( ) or https:// means you\\'ve safely connected to the .gov website. Share sensitive information only on official, secure websites. ... As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with, the contents by NLM or the National Institutes\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nThe \\'Digital Commerce Market Report 2025: Benchmark Forecasts Highlight Market Trends Across 60 Countries\\' was published on June 17, 2025.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'Digital Commerce Market Report 2025: Benchmark Forecasts Highlight Market Trends Across 60 Countries - https://www.globenewswire.com/news-release/2025/06/17/3100881/28124/en/Digital-Commerce-Market-Report-2025-Benchmark-Forecasts-Highlight-Market-Trends-Across-60-Countries.html\\', \\'text\\': \\'The report includes both a data deliverable, sizing the market and providing key forecast data across 60 countries, and a strategy and trends report, delivering a complete assessment of the key trends, challenges and recommendations for stakeholders within the digital commerce market.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Digital Commerce Market Report 2025: Benchmark Forecasts Highlight Market Trends Across 60 Countries - https://www.globenewswire.com/news-release/2025/06/17/3100881/28124/en/Digital-Commerce-Market-Report-2025-Benchmark-Forecasts-Highlight-Market-Trends-Across-60-Countries.html\\', \\'text\\': \\'The report assesses the trends and challenges within the sector; analysing the state of the digital banking, eCommerce, digital ticketing, money transfer and proximity payments (including QR code payments and contactless payments) market segments in depth. The research also provides industry benchmark forecasts for the market, split by the following segments, as well as by 8 key regions and 60 countries:\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Digital Commerce Market Report 2025: Benchmark Forecasts Highlight Market Trends Across 60 Countries - https://www.globenewswire.com/news-release/2025/06/17/3100881/28124/en/Digital-Commerce-Market-Report-2025-Benchmark-Forecasts-Highlight-Market-Trends-Across-60-Countries.html\\', \\'text\\': \\'Country Data Tool: This tool lets users look at metrics for all regions and countries in the forecast period. Users can refine the metrics displayed via a search bar. Country Comparison Tool: Users can select and compare countries. The ability to export graphs is included in this tool. This report is ideal for eCommerce merchants, payment service providers, banks, fintechs, digital banking providers, and other stakeholders in the digital commerce space. It is also valuable for anyone looking to understand market dynamics, customer trends, and competitive strategies in this rapidly evolving sector.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Digital Commerce Market Report 2025: Benchmark Forecasts Highlight Market Trends Across 60 Countries - https://www.globenewswire.com/news-release/2025/06/17/3100881/28124/en/Digital-Commerce-Market-Report-2025-Benchmark-Forecasts-Highlight-Market-Trends-Across-60-Countries.html\\', \\'text\\': \\'The market-leading research suite for the Digital Commerce market includes access to the full set of forecast data, with 46 tables and over 30,000 datapoints. ... Statistics Analysis: Users benefit from the ability to search for specific metrics; displayed for all regions and countries across the data period.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Digital Commerce Market Report 2025-29: Size, Share, Trends - https://www.juniperresearch.com/research/fintech-payments/ecommerce/digital-commerce-market-research-report/\\', \\'text\\': \\'The research also provides industry benchmark forecasts for the market, split by the following segments, as well as by our 8 key regions and 60 countries: ... The suite includes both a data deliverable, sizing the market and providing key forecast data across 60 countries, and a strategy and trends report, delivering a complete assessment of the key trends, challenges and recommendations for stakeholders within the digital commerce market.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Digital Commerce Market Report 2025-29: Size, Share, Trends - https://www.juniperresearch.com/research/fintech-payments/ecommerce/digital-commerce-market-research-report/\\', \\'text\\': \\'Benchmark Industry Forecasts: A suite of comprehensive data and forecasts highlighting the total transaction volume, transaction value and number of digital users across digital banking, eCommerce, digital ticketing, money transfers and proximity payments, split by the total digital channels, and the online and mobile channels.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Digital Commerce Market Report 2025-29: Size, Share, Trends - https://www.juniperresearch.com/research/fintech-payments/ecommerce/digital-commerce-market-research-report/\\', \\'text\\': \\'The market-leading research suite for the Digital Commerce market includes access to the full set of forecast data, with 46 tables and over 30,000 datapoints. Metrics in the research suite include: ... Statistics Analysis: Users benefit from the ability to search for specific metrics; displayed for all regions and countries across the data period.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Digital Commerce Market Report 2025-29: Size, Share, Trends - https://www.juniperresearch.com/research/fintech-payments/ecommerce/digital-commerce-market-research-report/\\', \\'text\\': \\'The report includes detailed market forecasts for transaction volume, value, and user statistics across various digital commerce segments. It provides data on digital banking, eCommerce (both digital and physical goods), ticketing, money transfers, and proximity payments. The data is segmented by mobile vs. online usage and split across key regions and countries.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Digital Commerce Market Report 2025: Benchmark Forecasts Highlight Market Trends Across 60 Countries - https://finance.yahoo.com/news/digital-commerce-market-report-2025-151600984.html\\', \\'text\\': \\'Discover a comprehensive analysis of the booming Digital Commerce market in this latest research report, covering key segments like Digital Banking, eCommerce, and Proximity Payments. Get strategic insights, industry forecasts, and actionable recommendations for success across 60 countries.Dublin, June 17, 2025 (GLOBE NEWSWIRE) -- The \"Digital Commerce Market: 2025-2029\" report has been added to ResearchAndMarkets.com\\\\\\'s offering.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Digital Commerce Market Report 2025: Benchmark Forecasts Highlight Market Trends Across 60 Countries - https://finance.yahoo.com/news/digital-commerce-market-report-2025-151600984.html\\', \\'text\\': \\'Get strategic insights, industry forecasts, and actionable recommendations for success across 60 countries. Dublin, June 17, 2025 (GLOBE NEWSWIRE) -- The \"Digital Commerce Market: 2025-2029\" report has been added to ResearchAndMarkets.com\\\\\\'s offering. The Digital Commerce research report provides an in-depth analysis of this rapidly growing market; addressing the major drivers and challenges, and offering strategic recommendations so that vendors can best capitalise on this market growth. The report assesses the trends and challenges within the sector; analysing the state of the digital banking, eCommerce, digital ticketing, money transfer and proximity payments (including QR code payments and contactless payments) market segments in depth.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Digital Commerce Market Report 2025: Benchmark Forecasts Highlight Market Trends Across 60 Countries - https://finance.yahoo.com/news/digital-commerce-market-report-2025-151600984.html\\', \\'text\\': \\'The report includes both a data deliverable, sizing the market and providing key forecast data across 60 countries, and a strategy and trends report, delivering a complete assessment of the key trends, challenges and recommendations for stakeholders within the digital commerce market.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Digital Commerce Market Report 2025: Benchmark Forecasts Highlight Market Trends Across 60 Countries - https://finance.yahoo.com/news/digital-commerce-market-report-2025-151600984.html\\', \\'text\\': \\'Country Data Tool: This tool lets users look at metrics for all regions and countries in the forecast period. Users can refine the metrics displayed via a search bar. Country Comparison Tool: Users can select and compare countries. The ability to export graphs is included in this tool. This report is ideal for eCommerce merchants, payment service providers, banks, fintechs, digital banking providers, and other stakeholders in the digital commerce space. It is also valuable for anyone looking to understand market dynamics, customer trends, and competitive strategies in this rapidly evolving sector.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'2025 E-Commerce Trends Report - DHL eCommerce - Global - https://www.dhl.com/global-en/microsites/ec/ecommerce-insights/insights/reports/2025-ecommerce-trends-report.html\\', \\'text\\': \\'If that’s not enough, we also have a series of country reports, taking a deep dive into some of the most active and dynamic e-commerce markets across the globe. ... Disclaimer: This audio was created using Googles NotebookLM by uploading the 2025 press release of the DHL eCommerce E-Commerce Trends Report to the NotebookLM tool.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'2025 E-Commerce Trends Report - DHL eCommerce - Global - https://www.dhl.com/global-en/microsites/ec/ecommerce-insights/insights/reports/2025-ecommerce-trends-report.html\\', \\'text\\': \\'All stats and figures are taken from the DHL eCommerce Online Shopper Survey conducted between February and March 2025. Respondents were required to have made at least one purchase online within the three months prior to the survey. 70+ questions were asked to 24,000 respondents across 24 countries (1,000 per country) with an equal split across demographics – where possible. The countries chosen for this survey represent some of the most active e-commerce markets across the globe.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'2025 E-Commerce Trends Report - DHL eCommerce - Global - https://www.dhl.com/global-en/microsites/ec/ecommerce-insights/insights/reports/2025-ecommerce-trends-report.html\\', \\'text\\': \\'Delivery and returns preferences across global markets. The rise of out-of-home – and why your business can’t afford to ignore this. Shoppers’ real returns behavior – and how your business can reduce returns rates. Why not getting delivery and returns right could lead to 4 in 5 customers abandoning their cart. 2025 Delivery & Returns Trends Download the full Report\\'}, {\\'doc_id\\': 3, \\'source\\': \\'2025 E-Commerce Trends Report - DHL eCommerce - Global - https://www.dhl.com/global-en/microsites/ec/ecommerce-insights/insights/reports/2025-ecommerce-trends-report.html\\', \\'text\\': \\'Uncover the marketplaces capturing consumer attention in each country. ... Do shoppers still believe the Black Friday hype – or are they losing trust in retailers’ offers and prices? Sharpen your seasonal sales strategy with key insights, including: How many shoppers make a purchase during Black Friday and Cyber Monday. What motivates 71% of shoppers to spend during this period. How trust and buying behavior shift across generations.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Digital Commerce Market Growth & Demand 2025-2035 - https://www.futuremarketinsights.com/reports/digital-commerce-market\\', \\'text\\': \\'The section highlights the CAGRs of countries experiencing growth in the Digital Commerce market, along with the latest advancements contributing to overall market development. Based on current estimates USA, India and China are expected to see steady growth during the forecast period.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Digital Commerce Market Growth & Demand 2025-2035 - https://www.futuremarketinsights.com/reports/digital-commerce-market\\', \\'text\\': \"Such government support programs as the commission\\'s digital commerce guidelines mark the importance of compliance services. Indeed, estimates indicate that by 2025, more than 60% of e-commerce businesses in the United States will be requiring consulting services on regulatory compliance.\"}, {\\'doc_id\\': 4, \\'source\\': \\'Digital Commerce Market Growth & Demand 2025-2035 - https://www.futuremarketinsights.com/reports/digital-commerce-market\\', \\'text\\': \\'The below table presents the expected CAGR for the global Digital Commerce market over several semi-annual periods spanning from 2025 to 2035. This assessment outlines changes in the memory interconnect industry and identify revenue trends, offering key decision makers an understanding about market performance throughout the year.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Digital Commerce Market Growth & Demand 2025-2035 - https://www.futuremarketinsights.com/reports/digital-commerce-market\\', \\'text\\': \\'AI and ML algorithms are enabling advanced personalization by analyzing customer behavior, purchasing trends, and browsing patterns to deliver targeted recommendations. IoT enhances real-time visibility across logistics and connected devices, improving customer experience through precise tracking and automation.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'Digital Commerce Market Outlook Report 2025-2029: Digital Commerce Spend to Hit $34 Trillion by 2029 - ResearchAndMarkets.com - https://www.businesswire.com/news/home/20250623115233/en/Digital-Commerce-Market-Outlook-Report-2025-2029-Digital-Commerce-Spend-to-Hit-$34-Trillion-by-2029---ResearchAndMarkets.com\\', \\'text\\': \\'The research also provides industry benchmark forecasts for the market, split by the following segments, as well as by 8 key regions and 60 countries: ... The report includes both a data deliverable, sizing the market and providing key forecast data across 60 countries, and a strategy and trends report, delivering a complete assessment of the key trends, challenges and recommendations for stakeholders within the digital commerce market.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'Digital Commerce Market Outlook Report 2025-2029: Digital Commerce Spend to Hit $34 Trillion by 2029 - ResearchAndMarkets.com - https://www.businesswire.com/news/home/20250623115233/en/Digital-Commerce-Market-Outlook-Report-2025-2029-Digital-Commerce-Spend-to-Hit-$34-Trillion-by-2029---ResearchAndMarkets.com\\', \\'text\\': \\'DUBLIN--(BUSINESS WIRE)--The \"U.S. Veterinary Point of Care Diagnostics Market Size, Share & Trends Analysis Report by Product, Animal Type, Sample Type, Indication, Testing Category, End-Use, Country with Growth Forecasts, 2025-2030\" has been added to ResearchAndMarkets.com\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': \"Ground Truth:\\n70% of online shoppers say that product content can make or break a sale.\\n\\nSnippet:\\n[{'doc_id': 0, 'source': 'Council Post: 4 Big Trends For DTC E-Commerce Growth In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/04/17/4-big-trends-for-dtc-e-commerce-growth-in-2025/', 'text': 'Another trend in e-commerce is the growing demand for more and more background detail and information on each product sold. No longer satisfied with just a nice-looking label and some positive star ratings, 70% of online shoppers now say that product content can make or break a sale.'}, {'doc_id': 0, 'source': 'Council Post: 4 Big Trends For DTC E-Commerce Growth In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/04/17/4-big-trends-for-dtc-e-commerce-growth-in-2025/', 'text': 'Based on these four e-commerce trends, savvy online brands should consider the following actions and investments to see strong DTC revenue growth in 2025: 1. Extend their brand experience to TikTok Shop and other social commerce platforms to capitalize on new sales opportunities with new and existing audiences. 2. Go deep with the amount of detail and supporting content provided for each product, including long-form video and regular live selling experiences. 3. Provide a more personalized experience for known and unknown shoppers with modern customer personalization technology that uses AI algorithms instead of cookies.'}, {'doc_id': 0, 'source': 'Council Post: 4 Big Trends For DTC E-Commerce Growth In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/04/17/4-big-trends-for-dtc-e-commerce-growth-in-2025/', 'text': '| Membership (fee-based)Apr 17, 2025, 07:15am EDT ... Diane Keng, CEO & cofounder of Breinify, a leading AI-power predictive personalization platform. Forbes 30 Under 30, Enterprise Technology. ... Direct-to-consumer (DTC) e-commerce brands are always looking for the next lever to pull that can help scale their businesses to new heights. But with the ever-changing nature of consumer trends and emerging tech—and the reality of limited budgets for marketing experimentation—it can be hard for brands to decipher between worthwhile long-term investments and passing fads.'}, {'doc_id': 0, 'source': 'Council Post: 4 Big Trends For DTC E-Commerce Growth In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/04/17/4-big-trends-for-dtc-e-commerce-growth-in-2025/', 'text': 'In this article, I’ll examine four big trends in DTC e-commerce growth that appear to be very much here to stay. The growth of social commerce will continue throughout 2025, with more than $100 billion in revenue projected from social media product purchases, an increase of 22% from 2024.'}, {'doc_id': 1, 'source': 'Top Ecommerce Trends to Watch in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-trends/', 'text': 'With consumers craving more immersive and authentic shopping experiences, livestream commerce will become a major revenue driver in 2025, transforming how brands connect with and convert shoppers online. Perhaps one of the greatest challenges of shopping online is the inability to see, touch, and fully experience a product in-person before buying — enter augmented reality (AR). According to eMarketer, the number of AR users in the US will exceed 100 million by the end of 2025, making up 32% of the population.'}, {'doc_id': 1, 'source': 'Top Ecommerce Trends to Watch in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-trends/', 'text': 'Especially in the fashion and apparel industry, younger shoppers are favoring brands that prioritize ethical and eco-friendly practices over those that don’t. According to a study by Drapers and BigCommerce, Drapers survey found that 57% of Gen Z and Millennials say sustainability is important when it comes to shopping for clothes, accessories or shoes — up from 47% in the 2022 survey.'}, {'doc_id': 1, 'source': 'Top Ecommerce Trends to Watch in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-trends/', 'text': 'Today, major retailers are leveraging AR for virtual try-ons and interactive 3D product views, allowing shoppers to visualize products in their real-world environments, thus increasing buyer confidence and reducing return rates. With 75% of US households owning a smart speaker in 2025, it’s no surprise that voice search is an up and coming trend in the ecommerce space. Voice assistants like Amazon Alexa and Google Assistant have transformed the way that consumers interact with ecommerce platforms — like BigCommerce and Shopify — offering a hands-free, convenient way to shop.'}, {'doc_id': 1, 'source': 'Top Ecommerce Trends to Watch in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-trends/', 'text': 'By simply using a voice command, shoppers can search for products, make purchases, and track orders with ease. In response, many ecommerce businesses are optimizing their sites for voice search, ensuring quick and accurate responses to voice queries. And as voice technology continues to innovate, its integration into the shopping experience will undoubtedly enhance customer convenience and drive significant growth in online sales.'}, {'doc_id': 3, 'source': '14 Online Shopping Trends Shaping 2025 - Shopify - https://www.shopify.com/enterprise/blog/online-shopping-trends-ecommerce', 'text': 'This isn’t the first or last time you’ll hear it: Your product pages sell, even more so as we move into 2025. A 2023 survey found that 70% of online shoppers say product-page content can make or break a sale.'}, {'doc_id': 3, 'source': '14 Online Shopping Trends Shaping 2025 - Shopify - https://www.shopify.com/enterprise/blog/online-shopping-trends-ecommerce', 'text': 'Social media platforms like Facebook and Instagram have become increasingly popular places for consumers to discover, research, and purchase new products.  · Social commerce makes shopping a more convenient and interactive experience, which helps explain why eMarketer projects over $100 billion in social commerce sales in 2025, a 22.4% growth from year prior.'}, {'doc_id': 3, 'source': '14 Online Shopping Trends Shaping 2025 - Shopify - https://www.shopify.com/enterprise/blog/online-shopping-trends-ecommerce', 'text': 'Get access to the data and insights shaping ecommerce and how the biggest brands are driving growth. Download the guide · Mindful shopping practices will increase. More shoppers will head in-store. Shoppers will look for more product details. Green initiatives will continue to be popular—with a caveat. More people will shop through social commerce.'}, {'doc_id': 3, 'source': '14 Online Shopping Trends Shaping 2025 - Shopify - https://www.shopify.com/enterprise/blog/online-shopping-trends-ecommerce', 'text': 'As mobile browsing overtakes desktop––almost 64% of global web traffic came from mobile devices in August 2024––increasing numbers of shoppers are tapping “buy” on their devices. In 2023, retail m-commerce sales hit $2.2 trillion, and now make up 60% of all ecommerce sales around the world. By 2027, analysts expect that number to reach $3.4 trillion.'}, {'doc_id': 4, 'source': 'eCommerce statistics 2025: key findings and shopping trends [latest research] - https://www.hostinger.com/ph/tutorials/ecommerce-statistics', 'text': 'With this uptrend, mobile commerce sales are projected to exceed $3.4 trillion by 2027. To keep up with evolving consumer behavior, online stores must prioritize mobile optimization in mobile-first markets. Start by creating a user-friendly customer journey, from browsing to purchasing products. Global mobile commerce is growing at a rate of 29%, capturing 7% more completed payments than traditional eCommerce. Around 70% of shoppers say mobile commerce is time-saving and convenient for buying on the go.'}, {'doc_id': 4, 'source': 'eCommerce statistics 2025: key findings and shopping trends [latest research] - https://www.hostinger.com/ph/tutorials/ecommerce-statistics', 'text': 'It’s no surprise that brands focusing on environmental, social, and governance (ESG) initiatives saw an average of 28% growth, while those without only grew by 20%. 24/7 availability, convenience, and discount deals make online shopping the go-to choice for 56.6% of consumers. That said, 44.4% still prefer in-store shopping, valuing the hands-on experience and ability to see, touch, and test products before buying. If you have the resources, consider adopting a multichannel business model to cater to both customer preferences. The thriving mobile commerce market makes it easy for people to shop online using only their phones.'}, {'doc_id': 4, 'source': 'eCommerce statistics 2025: key findings and shopping trends [latest research] - https://www.hostinger.com/ph/tutorials/ecommerce-statistics', 'text': 'Global eCommerce revenue is projected to exceed $6.4 trillion by 2029, with an annual growth rate (CAGR) of 9.49% from 2024 to 2029. This growth is consistent with the continued rise of online shopping worldwide. By 2029, the average revenue per user (ARPU) in the eCommerce market is expected to reach $1,620, highlighting the rising spending power of online shoppers.'}, {'doc_id': 4, 'source': 'eCommerce statistics 2025: key findings and shopping trends [latest research] - https://www.hostinger.com/ph/tutorials/ecommerce-statistics', 'text': 'Unexpected or high fees or taxes deterred 16% of shoppers from purchasing, while 14% decided to wait for a sale or discount. Meanwhile, indecisiveness or a change in mood accounted for 14% of abandoned carts. Other reasons for leaving carts include a lengthy or complicated checkout process (4%) and concerns about payment security (3%). High shipping costs and long delivery times are a bigger concern for men, with 59% finding them problematic compared to 41% of women.'}, {'doc_id': 5, 'source': 'DTC e-commerce: How consumer brands can get it right | McKinsey - https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/dtc-e-commerce-how-consumer-brands-can-get-it-right', 'text': 'In a similar vein, 75 percent of online shoppers say they prefer a personalized experience. For example, fashion brands such as Maje, Sandro, and The Kooples offer exclusive online presales to registered online customers. Assortment. Many brands choose to adapt their DTC assortment to the specific requirements of their sector and consumers.'}, {'doc_id': 5, 'source': 'DTC e-commerce: How consumer brands can get it right | McKinsey - https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/dtc-e-commerce-how-consumer-brands-can-get-it-right', 'text': 'During the COVID-19 pandemic, there has been a 70 percent increase in content uploads by users of Lego’s online platforms that help the company engage with consumers and find out what they like, especially in fast-growth markets, such as China.1“Lego builds its brand in China with experiences,” WARC, January 13, 2020, warc.com. Fueling innovation. DTC also provides the platform to test the latest innovation in products and services, giving brands direct access to consumer feedback for evaluation and testing.'}, {'doc_id': 5, 'source': 'DTC e-commerce: How consumer brands can get it right | McKinsey - https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/dtc-e-commerce-how-consumer-brands-can-get-it-right', 'text': 'Just 60 percent of consumer-goods companies, at best, feel even moderately prepared to capture e-commerce growth opportunities. Here are some concerns expressed by top executives globally: “I’m worried about fulfillment. What if we disappoint online shoppers?'}, {'doc_id': 5, 'source': 'DTC e-commerce: How consumer brands can get it right | McKinsey - https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/dtc-e-commerce-how-consumer-brands-can-get-it-right', 'text': 'At the early stages of DTC, brands often outsource logistics to guarantee quality, speed, and the flexibility to scale operations up or down as needed. Consumer brands that have their own retail network often use their stores as e-commerce fulfillment centers. Nike, for example, lets online shoppers pick up their purchases at brick-and-mortar Nike stores.'}, {'doc_id': 6, 'source': 'DTC Ecommerce Trends: What Brands Are Adopting in 2025 - https://webandcrafts.com/blog/dtc-ecommerce-trends', 'text': 'According to the June 2023 Global Consumer Insights Pulse Survey, about 63% of shoppers have purchased products from a brand’s website directly. In the highly competitive market, consumers wish for faster delivery of products, active customer support, personalized products, and a reliable source of information – this is where DTC e-commerce trends prove amazing.'}, {'doc_id': 6, 'source': 'DTC Ecommerce Trends: What Brands Are Adopting in 2025 - https://webandcrafts.com/blog/dtc-ecommerce-trends', 'text': 'Ecommerce retail sales are expected to reach 9.4 trillion U.S. dollars by 2026 on a global scale. Many physical retailers like BestBuy and Target have adopted measures for a major shift towards DTC models. As shoppers become more concerned and expectations grow, brands should find ways to meet the demands, offer value, and build exceptional customer experiences. This blog discusses the significant direct-to-consumer trends that shape the e-commerce sector and gives insights into how retailers should adopt these trends.'}, {'doc_id': 6, 'source': 'DTC Ecommerce Trends: What Brands Are Adopting in 2025 - https://webandcrafts.com/blog/dtc-ecommerce-trends', 'text': 'The global food and beverage market for e-commerce is expected to hit $903465.5 million by 20\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nThe UK had nearly 60 million e-commerce users in 2023.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'E-commerce in the UK - Statistics & Facts | Statista - https://www.statista.com/topics/2333/e-commerce-in-the-united-kingdom/\\', \\'text\\': \\'E-commerce sales growth percentage in the United Kingdom (UK) from 2022 to 2028 · Premium Statistic Main cross-border online shopping markets in the UK 2023, by market share · Main cross-border online shopping markets in the UK 2023, by market share · Leading markets of origin of cross-border online purchases in the United Kingdom (UK) in 2023, by market share · Premium Statistic Online retail users in the United Kingdom 2017-2029\\'}, {\\'doc_id\\': 0, \\'source\\': \\'E-commerce in the UK - Statistics & Facts | Statista - https://www.statista.com/topics/2333/e-commerce-in-the-united-kingdom/\\', \\'text\\': \\'Number of e-commerce users in the United Kingdom (UK) from 2017 to 2029 (in millions) Premium Statistic Penetration rate of e-commerce in the UK 2020-2029 · Penetration rate of e-commerce in the UK 2020-2029 · Penetration rate of the e-commerce market in the United Kingdom from 2020 to 2029 ... Percentage change in annual internet retail sales value in the United Kingdom (UK) from 2010 to 2023\\'}, {\\'doc_id\\': 0, \\'source\\': \\'E-commerce in the UK - Statistics & Facts | Statista - https://www.statista.com/topics/2333/e-commerce-in-the-united-kingdom/\\', \\'text\\': \\'In 2024, the country is expected to have about 50 million e-commerce users — leaving non-digital buyers as a minority of the total population. Following the coronavirus pandemic, in 2020, internet retail sales in the UK grew by 47 percent, the fastest rate recorded in the previous ten years. In contrast to this steep growth resultant from the pandemic, the UK’s e-commerce retail sales growth hit a negative in 2022, likely a direct impact of inflation and other global current events. In 2023, however, the figure has begun to find its foothold once again, and the revenue of e-commerce in the UK is still expected to grow steadily in the coming years across all segments.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'E-commerce in the UK - Statistics & Facts | Statista - https://www.statista.com/topics/2333/e-commerce-in-the-united-kingdom/\\', \\'text\\': \\'Top online stores in the United Kingdom in 2023, by e-commerce net sales (in million U.S. dollars) Premium Statistic Most downloaded shopping apps in the UK 2023 ... Leading online marketplaces in the United Kingdom as of April 2023, based on number of monthly visits (in millions)\\'}, {\\'doc_id\\': 1, \\'source\\': \\'E-commerce worldwide - statistics & facts | Statista - https://www.statista.com/topics/871/online-shopping/\\', \\'text\\': \\'Leading the global ranking of online marketplaces in terms of traffic is Amazon. The Seattle-based e-commerce giant that offers e-retail, computing services, consumer electronics, and digital content registered 6.1 billion direct visits to its .com website in December 2023.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'E-commerce worldwide - statistics & facts | Statista - https://www.statista.com/topics/871/online-shopping/\\', \\'text\\': \\'Premium Statistic Most used payment methods in e-commerce worldwide in 2023, with a forecast for 2027 · Premium Statistic Market share of online payment processing software on web domains worldwide 2025 · Premium Statistic Quarterly number of PayPal active accounts worldwide 2010-2024 · Premium Statistic Quarterly number of PayPal payments 2014-2024 · Premium Statistic Market cap of 120 digital assets, such as crypto, on December 3, 2024\\'}, {\\'doc_id\\': 1, \\'source\\': \\'E-commerce worldwide - statistics & facts | Statista - https://www.statista.com/topics/871/online-shopping/\\', \\'text\\': \\'Top online stores worldwide in 2023, by e-commerce net sales (in billion U.S. dollar) Premium Statistic Top e-commerce marketplaces worldwide 2023, by gross merchandise value\\'}, {\\'doc_id\\': 1, \\'source\\': \\'E-commerce worldwide - statistics & facts | Statista - https://www.statista.com/topics/871/online-shopping/\\', \\'text\\': \\'Leading online marketplaces worldwide in 2023, by gross merchandise value (in billion U.S. dollars) Basic Statistic Leading tech companies worldwide 2024, by market cap · Leading tech companies worldwide 2024, by market cap · Leading tech companies worldwide as of November 15, 2024, by market capitalization (in billion U.S. dollars) Premium Statistic Value of leading e-commerce startup acquisitions 2024\\'}, {\\'doc_id\\': 2, \\'source\\': \\'eCommerce Statistics UK 2023: Navigating the Digital Marketplace | Ecommerce Fulfilment Services - https://deltafulfilment.co.uk/ecommerce-statistics-uk-2023-navigating-the-digital-marketplace/\\', \\'text\\': \\'According to a survey by Statista, 45% of UK participants like to pick up items they bought online in-store. This method, known as Buy Online, Pick-up in Store (BOPIS), became more popular during the pandemic, and its convenience will likely keep it popular.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'eCommerce Statistics UK 2023: Navigating the Digital Marketplace | Ecommerce Fulfilment Services - https://deltafulfilment.co.uk/ecommerce-statistics-uk-2023-navigating-the-digital-marketplace/\\', \\'text\\': \\'WooCommerce and Shopify were the most used ecommerce platforms in 2023. A growing preference for diverse online payment methods, with debit cards and digital wallets like PayPal and Apple Pay being popular among UK consumers. The UK’s retail market shows a significant tilt towards online shopping.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'eCommerce Statistics UK 2023: Navigating the Digital Marketplace | Ecommerce Fulfilment Services - https://deltafulfilment.co.uk/ecommerce-statistics-uk-2023-navigating-the-digital-marketplace/\\', \\'text\\': \\'The figures for April 2022 were influenced by external factors – the EU’s international trade sanctions and export-import bans from March 2022. These political and economic shifts contributed to a significant fall in retail sales. But the market’s resilience showed through, as there’s been a steady climb back up in online sales through 2023, reaching heights unseen since April 2021.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'eCommerce Statistics UK 2023: Navigating the Digital Marketplace | Ecommerce Fulfilment Services - https://deltafulfilment.co.uk/ecommerce-statistics-uk-2023-navigating-the-digital-marketplace/\\', \\'text\\': \\'External factors like health crises and international policies can have a substantial impact. Still, the market’s ability to recover and grow reflects the evolving consumer behaviour and the agility of the online retail platform. In November 2023, a trend emerged within the realm of online retail.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Top 34 ecommerce statistics, facts and figures you need to know in 2025. - https://www.charle.co.uk/articles/ecommerce-statistics/\\', \\'text\\': \\'According to the Digital Market Outlook, the number of e-commerce users in the United Kingdom is expected to grow to 62,1 million in 2025. Only a very small minority of the UK population are not using ecommerce to purchase goods. (Statista) - UK Ecommerce Statistics\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Top 34 ecommerce statistics, facts and figures you need to know in 2025. - https://www.charle.co.uk/articles/ecommerce-statistics/\\', \\'text\\': \\'E-commerce retail sales have been increasing steadily in conjunction with mobile commerce retail sales which are projected to increase to approximately 105 billion British pounds by 2024. (Statista) - UK Ecommerce Stats · Fashion is the largest market and accounts for 28.7% of the UK eCommerce revenue.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Top 34 ecommerce statistics, facts and figures you need to know in 2025. - https://www.charle.co.uk/articles/ecommerce-statistics/\\', \\'text\\': \"In the mid-90s, the internet began to see major technological advancements for commercial use - what would become known as \\'ecommerce\\'. Key players such as Amazon became the first businesses to form from selling online and following this we saw marketplaces such as eBay that allowed other businesses to sell products online too.\"}, {\\'doc_id\\': 3, \\'source\\': \\'Top 34 ecommerce statistics, facts and figures you need to know in 2025. - https://www.charle.co.uk/articles/ecommerce-statistics/\\', \\'text\\': \\'Charle Agency (Charle London Limited) | London Shopify Plus Agency | Copyright 2023 | Terms & Privacy\\'}, {\\'doc_id\\': 4, \\'source\\': \\'35 Top E-Commerce Statistics – Forbes Advisor UK - https://www.forbes.com/uk/advisor/business/ecommerce-statistics/\\', \\'text\\': \\'The ecommerce market has grown tremendously over the last several years. Explore these ecommerce statistics to identify key trends in the industry.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'35 Top E-Commerce Statistics – Forbes Advisor UK - https://www.forbes.com/uk/advisor/business/ecommerce-statistics/\\', \\'text\\': \\'In 2023, the UK had nearly 60 million e-commerce users (Digital Market Outlook, Statista)\\'}, {\\'doc_id\\': 4, \\'source\\': \\'35 Top E-Commerce Statistics – Forbes Advisor UK - https://www.forbes.com/uk/advisor/business/ecommerce-statistics/\\', \\'text\\': \\'By 2025, the UK is predicted to have 62.1 million e-commerce users (Digital Market Outlook, Statista) In 2020, during Covid, e-commerce sales in the UK accounted for around a third (32.5%) of all retail sales (Statista) By 2022, the proportion of UK retail sales made online was 26.5% – but this was still more than double the level compared to 2012 (Statista) By 2025, the proportion of all UK retail sales made online is predicted to reach 38.1% – amounting to a value of £152 billion or $194.1 billion (Statista)\\'}, {\\'doc_id\\': 4, \\'source\\': \\'35 Top E-Commerce Statistics – Forbes Advisor UK - https://www.forbes.com/uk/advisor/business/ecommerce-statistics/\\', \\'text\\': \\'Selling products online means you’re not limited to local consumers. This gives you nearly unlimited potential for new demographics – and the statistics show companies are taking advantage. The global e-commerce market is expected to be worth $6.3 trillion this year – up from $5.8 trillion in 2023.[1]\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Essential Ecommerce Statistics To Know - https://swifterm.com/essential-ecommerce-statistics-to-know/\\', \\'text\\': \\'In 2023, the UK had nearly 60 million ecommerce users (Digital Market Outlook, Statista)\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Essential Ecommerce Statistics To Know - https://swifterm.com/essential-ecommerce-statistics-to-know/\\', \\'text\\': \\'By 2025, the UK is predicted to have 62.1 million ecommerce users (Digital Market Outlook, Statista) In 2020, during Covid, ecommerce sales in the UK accounted for around a third (32.5%) of all retail sales (Statista) By 2022, the proportion of UK retail sales made online was 26.5% – but this was still more than double the level compared to 2012 (Statista) By 2025, the proportion of all UK retail sales made online is predicted to reach 38.1% – amounting to a value of £152 billion or $194.1 billion (Statista)\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Essential Ecommerce Statistics To Know - https://swifterm.com/essential-ecommerce-statistics-to-know/\\', \\'text\\': \\'Selling products online means you’re not limited to local consumers. This gives you nearly unlimited potential for new demographics – and the statistics show companies are taking advantage. The global ecommerce market is expected to be worth $6.3 trillion this year – up from $5.8 trillion in 2023.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Essential Ecommerce Statistics To Know - https://swifterm.com/essential-ecommerce-statistics-to-know/\\', \\'text\\': \\'In just three years, mobile commerce sales will nearly double to $856 billion. To stay competitive in your industry, your business must start building mobile ecommerce into your overall digital marketing strategy.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/\\', \\'text\\': \\'Source: Statista. 84% of shoppers also said that they would be willing to install and shop through a mobile app if it gave them access to better sales or pricing. Mobile commerce is also attributed to 60% of global eCommerce sales in 2023 and experts predict it to rise this year as well.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/\\', \\'text\\': \\'Ecommerce sales in the United States have been steadily increasing for over a decade, hitting a record high of $1.19 trillion in 2023. That is a 301% increase from $297 billion in 2014. The pandemic in 2020 significantly boosted online sales in the country. Sales worth $159.8 billion were recorded in the first quarter of 2020, and jumped to $213.3 billion in the second quarter — a 33.5% increase. This surge accelerated the shift to online shopping by about five years. Source: United States Census Bureau.  · The B2B e-commerce market is valued at $32.11 trillion as of 2025 and is expected to grow at a CAGR of 14.5%, reaching $36.16 trillion by 2026.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'51 ECommerce Statistics In 2025 (Global And U.S. Data) | SellersCommerce - https://www.sellerscommerce.com/blog/ecommerce-statistics/\\', \\'text\\': \\'It is predicted that the total losses to online payment fraud globally between 2023 and 2027 will exceed $343 billion. Source: Mastercard, Juniper Research. Latin\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nSocial commerce is expected to generate 27% of e-commerce sales in 2025.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'Council Post: From AI To AR: The Bold Innovations Defining E-Commerce In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/01/24/from-ai-to-ar-the-bold-innovations-defining-e-commerce-in-2025/\\', \\'text\\': \\'Dani Nadel, President and COO, Feedvisor. ... Welcome to 2025, a year poised to redefine e-commerce and marketplaces. What started as simple convenience is now the backbone of global commerce—a dynamic space where technology and consumer expectations collide in unpredictable ways.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Council Post: From AI To AR: The Bold Innovations Defining E-Commerce In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/01/24/from-ai-to-ar-the-bold-innovations-defining-e-commerce-in-2025/\\', \\'text\\': \\'Social commerce will generate $2 trillion in global sales, representing 27% of e-commerce.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Council Post: From AI To AR: The Bold Innovations Defining E-Commerce In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/01/24/from-ai-to-ar-the-bold-innovations-defining-e-commerce-in-2025/\\', \\'text\\': \\'Advanced delivery models will be central as marketplaces invest heavily in drone delivery, same-day fulfillment, and decentralized micro-warehousing to meet consumer expectations. Add self-driving trucks and delivery robots into the mix and we’ll see end-to-end optimization for long-haul and last-mile logistics. Amazon is making strides in this arena, and Walmart is keeping pace, innovating with in-home delivery that places goods directly into refrigerators or pantries using smart lock technology.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Council Post: From AI To AR: The Bold Innovations Defining E-Commerce In 2025 - https://www.forbes.com/councils/forbestechcouncil/2025/01/24/from-ai-to-ar-the-bold-innovations-defining-e-commerce-in-2025/\\', \\'text\\': \\'2025 isn’t just another year for e-commerce; it’s a leap into the future.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'2025 Trends and Predictions: From AI to AR: The Bold Innovations Defining e-Commerce in 2025 - https://feedvisor.com/resources/e-commerce-strategies/bold-innovations-defining-ecommerce-2025/\\', \\'text\\': \\'Discover the bold e-commerce trends of 2025, from AI-powered innovations and AR shopping to sustainability and shifting consumer behaviors—reshaping how we shop and sell. ... Welcome to 2025, a year that promises to redefine e-commerce and marketplaces. What was once a simple convenience has become the backbone of global commerce—a dynamic ecosystem where technology and consumer expectations collide in exciting and unpredictable ways.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'2025 Trends and Predictions: From AI to AR: The Bold Innovations Defining e-Commerce in 2025 - https://feedvisor.com/resources/e-commerce-strategies/bold-innovations-defining-ecommerce-2025/\\', \\'text\\': \\'In 2025, social commerce will generate $2 trillion in global eCommerce sales, representing 27% of total transactions.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'2025 Trends and Predictions: From AI to AR: The Bold Innovations Defining e-Commerce in 2025 - https://feedvisor.com/resources/e-commerce-strategies/bold-innovations-defining-ecommerce-2025/\\', \\'text\\': \\'Discover the trends driving e-commerce in 2025 and how to position your brand for success. ... In the race to deliver faster and smarter, logistics is becoming a critical frontier for innovation. Advanced delivery models will be center stage as marketplaces invest heavily in drone delivery, same-day fulfillment, and decentralized micro-warehousing to meet sky-high consumer expectations.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'2025 Trends and Predictions: From AI to AR: The Bold Innovations Defining e-Commerce in 2025 - https://feedvisor.com/resources/e-commerce-strategies/bold-innovations-defining-ecommerce-2025/\\', \\'text\\': \\'This year marks a pivotal moment: advances in AI, sustainability demands, and shifting consumer behaviors are converging to redefine e-commerce. From logistics breakthroughs and predictive audiences to AR-enhanced shopping experiences, the trends shaping 2025 are bold, immersive, and full of surprises—offering brands, sellers, and consumers an opportunity to step into the future. Let’s dive into the trends and innovations redefining how we shop and do business.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'Influencer marketing and user-generated content (UGC) is brand content that’s created by users, rather than the brand. Social channels are crucial touchpoints for e-commerce: In fact, by 2030, social commerce revenue is expected to reach $6.2 trillion. When it comes to finding new products, interacting with brands, and authentic product recommendations that consumers trust, social shopping will be a juggernaut for online retailers in 2025.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'Expect to see sustainability stories take the spotlight in around e-commerce in 2025, as more and more commerce brands adopt eco-friendly practices. As 85% of single-use plastic packaging ends up in landfills, brands are looking to reduce their environmental impact through sustainable packaging. In 2025, the efficiency and speed of e-commerce operations will heavily rely on supply chain innovations.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'By aligning AI innovation with data security best practices, e-commerce companies can provide personalized experiences without compromising customer privacy. It’s a balancing act that, when done well, can set a brand apart in a competitive market. Social commerce is set to dominate the e-commerce landscape in 2025, merging the convenience of online shopping with the interactive nature of social media. Platforms like Instagram, TikTok, and Pinterest are evolving into comprehensive buying experiences where users can discover, explore, and purchase products directly within their feeds.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'As AR continues to become more accessible, sophisticated and user-friendly, it will be a powerful tool for creating interactive shopping experiences that build trust and drive sales. Augmented reality is transforming online shopping. Find out how brands are using AR technologies to deliver innovative e-commerce experiences. Growing concern for the future of our environment has consumers and governments alike putting pressure on companies to curb emissions and invest in sustainable practices. For e-commerce businesses, that means delivering a high-quality customer experience that’s also eco-friendly. According to an IDC study, 46% of consumers believe that a retail brand’s sustainability record is an important deciding factor for whom they’ll do business with.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Forbes: From AI to AR: The Bold Innovations Defining e-Commerce in 2025 - Feedvisor - https://feedvisor.com/resources/company-updates/forbes-bold-innovations-defining-ecommerce-2025/\\', \\'text\\': \\'Meanwhile, logistics innovation—ranging from drone deliveries to in-home fulfillment—redefines speed and convenience. Dive into Dani Nadel’s latest Forbes article to explore how technology and consumer expectations are reshaping the future of commerce in bold and immersive ways. ... Discover the trends driving e-commerce in 2025 and how to position your brand for success.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Forbes: From AI to AR: The Bold Innovations Defining e-Commerce in 2025 - Feedvisor - https://feedvisor.com/resources/company-updates/forbes-bold-innovations-defining-ecommerce-2025/\\', \\'text\\': \\'With 2025 set to redefine e-commerce and marketplaces, Feedvisor’s President and COO, Dani Nadel, highlights the groundbreaking trends shaping the year ahead. From AI-driven personalization to AR-powered shopping experiences, the landscape of global commerce is evolving at an unprecedented pace. Key innovations include advanced subscription models, hyper-personalized social commerce, and AI-driven programmatic advertising that seamlessly connects brands with predictive audiences.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'12 E-Commerce Trends to Follow in 2025 - https://artlabs.ai/blog/12-e-commerce-trends-to-follow-in-2025\\', \\'text\\': \"Under the Amazon Renewed program, old products that are professionally refurbished are offered for sale again with a 2-year warranty. According to some, 2025 will be the year of hyperpersonalization in e-commerce. Pop-up ads appearing everywhere or forced-to-watch video ads are not anyone\\'s favorite. The hyperpersonalization trend, which is expected to rebuild the retail environment in a personalized manner, will give a new identity to our everyday shopping routines.\"}, {\\'doc_id\\': 4, \\'source\\': \\'12 E-Commerce Trends to Follow in 2025 - https://artlabs.ai/blog/12-e-commerce-trends-to-follow-in-2025\\', \\'text\\': \\'However, in line with the shopping habits of the dominant generations today, sales and marketing experts emphasize that it is not possible to have a ‘sustainable success’ in sales without sustainable touches. Ethical Production and Consumption: As we approach 2025, customers expect brands to take more responsibility in both environmental and social sustainability.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'12 E-Commerce Trends to Follow in 2025 - https://artlabs.ai/blog/12-e-commerce-trends-to-follow-in-2025\\', \\'text\\': \\'Brands that successfully adopt omnichannel marketing will be better equipped to meet evolving consumer expectations and adapt to changing shopping behaviors. While AR technology offers innovations that fundamentally change the e-commerce field, where will VR be positioned in 2025?\\'}, {\\'doc_id\\': 4, \\'source\\': \\'12 E-Commerce Trends to Follow in 2025 - https://artlabs.ai/blog/12-e-commerce-trends-to-follow-in-2025\\', \\'text\\': \\'It is becoming a standard cybersecurity approach adopted by organizations across various industries to mitigate risks, particularly in environments where sensitive data is constantly accessed and exchanged. We introduced the concept of social commerce under the AR heading. By 2025, social commerce is expected to be an important part of e-commerce.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'AI for Ecommerce: How It’s Transforming the Future - https://www.bloomreach.com/en/blog/why-ai-is-the-future-of-e-commerce\\', \\'text\\': \\'Ecommerce is one of the leading adopters of artificial intelligence (AI), with use cases from personalized product recommendations and enhanced customer service to streamlined workflows, smart logistics, and sales/demand forecasting. Organizations that adopt AI business strategies generate an average of 10-12% extra revenue. With more and more consumers gravitating toward online shopping (21% of retail purchases in 2025 will be made online), it’s more important than ever for ecommerce brands to adopt AI if they hope to keep up with consumer expectations. In this article, we look at how AI allows retailers to evolve their customer journeys and create personalized experiences that keep shoppers coming back for more.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'AI for Ecommerce: How It’s Transforming the Future - https://www.bloomreach.com/en/blog/why-ai-is-the-future-of-e-commerce\\', \\'text\\': \\'Delivery — 99% of consumers say fast delivery is important when making online purchases, which is why 42% of retailers are working on how to offer same-day delivery · AI-powered chatbots currently handle 70% of online customer conversations. However, following the launch of generative AI, the value of the ecommerce sector has ballooned to $5.92 trillion as retailers rush to level up their current chatbots with new functionality. Generative AI in ecommerce can now power conversational commerce online, which frees up commerce-driving teams to work on less menial tasks.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'AI for Ecommerce: How It’s Transforming the Future - https://www.bloomreach.com/en/blog/why-ai-is-the-future-of-e-commerce\\', \\'text\\': \\'Read up on the latests in AI, commerce and personalization. ... Become inspired with our collection of use cases. ... Join our virtual events covering popular topics. ... Find an in-person event to meet the Bloomreach team. ... Read a number of guides covering best practices. ... See how we stack up according to analysts.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'AI for Ecommerce: How It’s Transforming the Future - https://www.bloomreach.com/en/blog/why-ai-is-the-future-of-e-commerce\\', \\'text\\': \\'According to research by McKinsey, the business impact of using AI for personalization alone results in: ... In addition to personalized product recommendations, AI also enables retailers to understand the intent behind a shopper’s search query. When the average ecommerce bounce rate is between 20-45%, smarter searches are shown to reduce this number by offering up more relevant results.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'8 Predictions for the Future of eCommerce in 2025: AI & Innovation | Sitecore - https://www.sitecore.com/resources\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\n83% of global brands aim to leverage AI to improve the overall user experience.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'How Ecommerce AI is Transforming Business in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-ai/\\', \\'text\\': \\'That can mean anything from scheduling emails in a CRM or marketing tool, using Zapier to automate tasks or leveraging advanced technology to help with hiring. In the context of future ecommerce trends, however, some of the most commonly talked about today are robotics and machine learning.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'How Ecommerce AI is Transforming Business in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-ai/\\', \\'text\\': \\'Access to more business and customer data and processing power is enabling ecommerce operators to understand their customers and identify new trends better than ever. In an insight from Accenture, they write, “AI systems can explore highly complex and varied options for customer engagement very quickly, and continuously optimize their performance as more data becomes available. This means marketers can set parameters and allow the AI to optimize and learn to achieve precision.” · According to a report from Emerging Tech Brew, “Machine learning’s predictive powers shine in logistics, helping to forecast transit times, demand levels, and shipment delays.”\\'}, {\\'doc_id\\': 0, \\'source\\': \\'How Ecommerce AI is Transforming Business in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-ai/\\', \\'text\\': \\'Resell ecommerce with Commerce-as-a-Service.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'How Ecommerce AI is Transforming Business in 2025 - https://www.bigcommerce.com/articles/ecommerce/ecommerce-ai/\\', \\'text\\': \\'We are dedicated to helping our customers expand their businesses and improve their bottom line. Through thought leadership on ecommerce trends, best practices, and innovations, we provide in-depth insights into both B2C and B2B strategies, enabling businesses to succeed and thrive in today’s dynamic digital marketplace.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'AI for Ecommerce: How It’s Transforming the Future - https://www.bloomreach.com/en/blog/why-ai-is-the-future-of-e-commerce\\', \\'text\\': \\'With more and more consumers gravitating toward online shopping (21% of retail purchases in 2025 will be made online), it’s more important than ever for ecommerce brands to adopt AI if they hope to keep up with consumer expectations. In this article, we look at how AI allows retailers to evolve their customer journeys and create personalized experiences that keep shoppers coming back for more. We’ll also consider how AI helps with internal operations to improve overall competitiveness, as well as look ahead at what the future of ecommerce looks like for those who successfully adopt AI.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'AI for Ecommerce: How It’s Transforming the Future - https://www.bloomreach.com/en/blog/why-ai-is-the-future-of-e-commerce\\', \\'text\\': \\'It’s essential to uphold transparency and ethical use of AI, ensuring that the brand maintains its authoritative and trustworthy image while embracing the benefits of AI in enhancing the overall ecommerce experience. ... Carl works with Bloomreach professionals to produce valuable, customer-centric content. A trusted expert with over 15 years of experience, Carl loves exploring unique ways to turn problems into solutions within digital commerce.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'AI for Ecommerce: How It’s Transforming the Future - https://www.bloomreach.com/en/blog/why-ai-is-the-future-of-e-commerce\\', \\'text\\': \\'These agents work autonomously to improve relevancy and accuracy in product discovery, initiate conversations across your site, hyper-personalize marketing campaigns, and streamline workflows. This technology enhances user experience, optimizes marketing efforts, and ultimately drives sales by leveraging data-driven insights to deliver a more personalized and efficient shopping journey.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'AI for Ecommerce: How It’s Transforming the Future - https://www.bloomreach.com/en/blog/why-ai-is-the-future-of-e-commerce\\', \\'text\\': \\'Furthermore, providing transparency in AI-powered product recommendations and ensuring they align with a brand’s ethos while fostering trust with customers is a critical challenge. Despite these obstacles, leveraging AI in ecommerce can lead to enhanced customer experiences, improved operational efficiency, and data-driven decision-making.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'For businesses aiming to scale globally or cater to niche markets, the composable commerce trend provides the agility needed to create unique digital experiences for diverse audiences. As e-commerce grows more complex, more brands will look to composable commerce in their quest for innovation and competitive differentiation. From hyper-personalized shopping experiences to customer support and advanced security measures, one thing is clear: In 2025, AI will be a driving force working behind the scenes – and alongside humans – to deliver seamless, efficient, and personalized e-commerce experiences.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'This approach ensures that as businesses leverage AI for personalization, they’re maintaining customer trust. By aligning AI innovation with data security best practices, e-commerce companies can provide personalized experiences without compromising customer privacy. It’s a balancing act that, when done well, can set a brand apart in a competitive market. Social commerce is set to dominate the e-commerce landscape in 2025, merging the convenience of online shopping with the interactive nature of social media.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'For e-commerce businesses, that means delivering a high-quality customer experience that’s also eco-friendly. According to an IDC study, 46% of consumers believe that a retail brand’s sustainability record is an important deciding factor for whom they’ll do business with. In 2025, e-commerce companies are looking at everything from their product packaging to their manufacturing and warehousing facilities to assess their emissions baseline and identify opportunities to improve.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'E-commerce trends 2025: Top 10 insights and stats driving online shopping as AI goes mainstream - https://www.the-future-of-commerce.com/2024/12/04/e-commerce-trends-2025/\\', \\'text\\': \\'For online retailers, e-commerce trends in 2025 reflect a hybrid shopping reality. Customers expect to move fluidly between digital and physical purchases with a brand – and the brand better know them well enough to serve up personalized suggestions, great customer service, and an outstanding CX, or else they’ll bail. Last year, global retail e-commerce sales landed around $5.8 trillion. Experts are anticipating ongoing growth, with 2027 projections surpassing $8 trillion by 2027.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Factors influencing the adoption of artificial intelligence in e-commerce by small and medium-sized enterprises - ScienceDirect - https://www.sciencedirect.com/science/article/pii/S2667096824000740\\', \\'text\\': \\'Therefore, companies are increasingly leveraging technology to enhance their processes and gain a competitive edge. In this context, the adoption of artificial intelligence (AI) in e-commerce has become a crucial area for business development. However, there is currently a lack of understanding regarding the key factors that determine the adoption of AI in e-commerce by small and medium-sized enterprises. Thus, to fill this gap, this study aims to investigate the factors influencing the adoption of AI tools in e-commerce for SMEs.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Factors influencing the adoption of artificial intelligence in e-commerce by small and medium-sized enterprises - ScienceDirect - https://www.sciencedirect.com/science/article/pii/S2667096824000740\\', \\'text\\': \\'Empirical data for the current study were collected using a digital survey, which was disseminated to a purposive sample of SMEs in Saudi Arabia. Analysis of the collected data was performed using structural equation modeling (SEM), and the results support the role of both dynamic capabilities and entrepreneurial orientation in facilitating the adoption of AI in e-commerce.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'The Impact of Artificial Intelligence Marketing on E-Commerce Sales - https://www.mdpi.com/2079-8954/12/10/429\\', \\'text\\': \\'This review explores the influence of AI marketing on e-commerce sales, examining how AI-driven strategies affect key metrics such as customer acquisition and conversion rates. Given the growing importance of AI in online retail, this paper employs a critical review methodology, analyzing 50 documents from the Scopus database.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'The Impact of Artificial Intelligence Marketing on E-Commerce Sales - https://www.mdpi.com/2079-8954/12/10/429\\', \\'text\\': \\'As AI continues to develop, its integration into marketing strategies will become more sophisticated, providing businesses with new opportunities to improve customer engagement and generate sales [31]. For instance, AI-driven analytics can provide insights into customer behavior, preferences, and trends, which can be used to create targeted marketing campaigns. This capability not only improves customer engagement but also increases conversion rates, making AI an invaluable asset for marketers seeking to optimize their strategies in a competitive environment [32]. Predictive analytics leverages historical data to forecast future consumer behavior, allowing marketers to anticipate customer needs and adjust their strategies accordingly.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'The Impact of Artificial Intelligence Marketing on E-Commerce Sales - https://www.mdpi.com/2079-8954/12/10/429\\', \\'text\\': \\'Labib, E. Artificial intelligence in marketing: Exploring current and future trends. Cogent Bus. Manag. 2024, 11, 2348728. [Google Scholar] [CrossRef] Hermann, E. Leveraging artificial intelligence in marketing for social good—An ethical perspective. J. Bus. Ethics 2022, 179, 43–61.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'The Impact of Artificial Intelligence Marketing on E-Commerce Sales - https://www.mdpi.com/2079-8954/12/10/429\\', \\'text\\': \\'AI has significantly enhanced key performance indicators such as sales growth, customer acquisition cost (CAC), customer lifetime value (CLV), and return on marketing investment (ROMI). By leveraging machine learning, deep learning, and natural language processing, AI has enabled businesses to deliver highly personalized and targeted marketing campaigns, resulting in increased engagement, improved conversion rates, and overall sales growth.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'50+ AI Marketing Statistics in 2025: AI Marketing Trends & Insights - https://www.seo.com/ai/marketing-statistics/\\', \\'text\\': \\'According to AI marketing statistics, marketers are also using AI for content creation, personalization, and ad targeting. AI in marketing market is valued at 47.32 billion US dollars in 2025 and is expected to grow at a CAGR of 36.6% to reach 107.5 billion by 2028.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'50+ AI Marketing Statistics in 2025: AI Marketing Trends & Insights - https://www.seo.com/ai/marketing-statistics/\\', \\'text\\': \"AI is changing marketing, and you can\\'t afford to fall behind. Check out our AI marketing stats to learn how to leverage artificial intelligence for content, personalization, and efficiency.\"}, {\\'doc_id\\': 5, \\'source\\': \\'50+ AI Marketing Statistics in 2025: AI Marketing Trends & Insights - https://www.seo.com/ai/marketing-statistics/\\', \\'text\\': \\'AI for marketers allows them to streamline the content creation process, improve personalization across different marketing channels, and boost efficiency and productivity. Below, we get into the top 50 AI marketing statistics that’ll help you stay ahead of the competition in 2025 and beyond.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'50+ AI Marketing Statistics in 2025: AI Marketing Trends & Insights - https://www.seo.com/ai/marketing-statistics/\\', \\'text\\': \\'Lornah Ngugi is a seasoned digital marketing writer with 6+ years of experience translating complex marketing strategies into engaging, results-driven content. She holds a BS in Business Information Technology and is certified in HubSpot Academy, Google Analytics, LinkedIn Marketing, and Google Digital Academy.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'AI in eCommerce: Benefits, Statistics, Use Cases and Examples - https://masterofcode.com/blog/state-of-artificial-intelligence-ai-in-ecommerce-statistics-and-deployment\\', \\'text\\': \\'We’ve compiled this data under two main areas of performance to get a quantitative understanding of how AI is being incorporated into digital commerce companies and provide the numbers businesses can use to make better-informed decisions in 2025.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'AI in eCommerce: Benefits, Statistics, Use Cases and Examples - https://masterofcode.com/blog/state-of-artificial-intelligence-ai-in-ecommerce-statistics-and-deployment\\', \\'text\\': \\'The global Conversational AI market size is expected to grow to $13.9 billion by 2025. (Business Wire) Facebook Messenger hosts over 300,000 active chatbots. Chatbots are also one of the most popular methods of implementing AI in eCommerce. (Hootsuite) The increasing rate of adoption is driven by many factors such as the new customer demand, cost-effective and personalized customer service, and the need for more accurate insights into Conversational AI trends.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'AI in eCommerce: Benefits, Statistics, Use Cases and Examples - https://masterofcode.com/blog/state-of-artificial-intelligence-ai-in-ecommerce-statistics-and-deployment\\', \\'text\\': \\'Sales Forecasting: In addition to managing inventory, AI can predict overall sales trends by checking various factors. It assists firms in financial planning, devising marketing strategies, and allocating resources effectively. By using predictive analytics, companies gain insights into market demand fluctuations, seasonal trends, and consumer behavior patterns.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'AI\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nJPMorgan downgraded Riskified to Underweight on August 31, 2025.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'JPMorgan Downgrades Riskified (RSKD) to Underweight From Neutral - https://finance.yahoo.com/news/jpmorgan-downgrades-riskified-rskd-underweight-041700319.html\\', \\'text\\': \\'Riskified Ltd. (NYSE:RSKD) is one of the best long-term penny stocks to buy right now. On August 20, JPMorgan analyst Reginald Smith downgraded Riskified Ltd. (NYSE:RSKD) to Underweight from Neutral without assigning a price target. The analyst told investors in a research note that Riskified Ltd.’s (NYSE:RSKD) volume growth and revenue have trailed the broader […]\\'}, {\\'doc_id\\': 0, \\'source\\': \\'JPMorgan Downgrades Riskified (RSKD) to Underweight From Neutral - https://finance.yahoo.com/news/jpmorgan-downgrades-riskified-rskd-underweight-041700319.html\\', \\'text\\': \\'Riskified Ltd. (NYSE:RSKD) is involved in fraud prevention solutions, empowering businesses by making e-commerce safe, frictionless, and accessible.\\'}, {\\'doc_id\\': 1, \\'source\\': \"JPMorgan\\'s Downgrade of Riskified: A Cautionary Signal for E-Commerce Risk Tech Investors? - https://www.ainvest.com/news/jpmorgan-downgrade-riskified-cautionary-signal-commerce-risk-tech-investors-2508-0/\", \\'text\\': \"JPMorgan\\'s Downgrade of Riskified: A Cautionary Signal for E-Commerce Risk Tech Investors?\"}, {\\'doc_id\\': 1, \\'source\\': \"JPMorgan\\'s Downgrade of Riskified: A Cautionary Signal for E-Commerce Risk Tech Investors? - https://www.ainvest.com/news/jpmorgan-downgrade-riskified-cautionary-signal-commerce-risk-tech-investors-2508-0/\", \\'text\\': \\'- JPMorgan downgrades Riskified to Underweight, citing growth underperformance and margin pressures.\\'}, {\\'doc_id\\': 1, \\'source\\': \"JPMorgan\\'s Downgrade of Riskified: A Cautionary Signal for E-Commerce Risk Tech Investors? - https://www.ainvest.com/news/jpmorgan-downgrade-riskified-cautionary-signal-commerce-risk-tech-investors-2508-0/\", \\'text\\': \\'AI-powered fraud, which now accounts for 91% of merchants’ top concerns, is outpacing traditional fraud prevention tools [1]. Cybercriminals are leveraging generative AI to create synthetic identities and intelligent bots, forcing companies to invest in real-time behavior analytics and layered identity verification [5]. Meanwhile, omnichannel expansion has widened attack surfaces, exposing vulnerabilities in unsecured APIs and inconsistent security protocols [2]. These trends are pushing e-commerce businesses to prioritize risk management, yet Riskified’s stagnant growth suggests it may be falling behind competitors in addressing these threats. JPMorgan’s downgrade serves as a cautionary signal for investors, highlighting the fragility of risk tech firms that fail to align with sector-wide innovation cycles.\\'}, {\\'doc_id\\': 1, \\'source\\': \"JPMorgan\\'s Downgrade of Riskified: A Cautionary Signal for E-Commerce Risk Tech Investors? - https://www.ainvest.com/news/jpmorgan-downgrade-riskified-cautionary-signal-commerce-risk-tech-investors-2508-0/\", \\'text\\': \\'Riskified’s revenue and volume growth—pegged at low-to-mid single digits in 2025—has trailed the broader e-commerce sector’s high single-digit expansion [1]. This gap is alarming given that e-commerce is projected to grow at a 7.54% CAGR through 2033, driven by AI-powered personalization and omnichannel adoption [4]. JPMorgan’s skepticism centers on Riskified’s capacity to accelerate volume growth from 5% in 2025 to 25% by 2026, a trajectory that appears increasingly unrealistic amid rising operational complexity [1]. The firm’s inability to match the pace of the sector suggests a misalignment with the technological and consumer trends reshaping e-commerce, such as real-time fraud detection and AI-driven logistics [5].\\'}, {\\'doc_id\\': 2, \\'source\\': \\'JPMorgan downgrades Riskified stock rating on growth concerns By Investing.com - https://www.investing.com/news/analyst-ratings/jpmorgan-downgrades-riskified-stock-rating-on-growth-concerns-93CH-4201352\\', \\'text\\': \\'JPMorgan attributed Riskified’s underperformance to a large client loss in the fourth quarter of 2024 and weakness in luxury spending and the tickets and travel segments. The downgrade also reflected skepticism about Riskified’s ability to achieve its adjusted EBITDA margin targets of 15-20% by 2026, with JPMorgan forecasting only a 10% margin for that period.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'JPMorgan downgrades Riskified stock rating on growth concerns By Investing.com - https://www.investing.com/news/analyst-ratings/jpmorgan-downgrades-riskified-stock-rating-on-growth-concerns-93CH-4201352\\', \\'text\\': \\'JPMorgan downgrades Riskified stock rating on growth concerns\\'}, {\\'doc_id\\': 2, \\'source\\': \\'JPMorgan downgrades Riskified stock rating on growth concerns By Investing.com - https://www.investing.com/news/analyst-ratings/jpmorgan-downgrades-riskified-stock-rating-on-growth-concerns-93CH-4201352\\', \\'text\\': \\'While acknowledging Riskified’s disciplined expense management, JPMorgan estimated that the company would need to accelerate volume growth from 5% in 2025 to approximately 25% in 2026 to hit its targets, expressing a preference for more scaled and profitable financial technology companies with diversified e-commerce exposure. In other recent news, Riskified Ltd.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'JPMorgan downgrades Riskified stock rating on growth concerns By Investing.com - https://www.investing.com/news/analyst-ratings/jpmorgan-downgrades-riskified-stock-rating-on-growth-concerns-93CH-4201352\\', \\'text\\': \\'Despite these positive earnings and revenue outcomes, there were concerns about gross profit margins, which fell short of expectations at approximately 50%, compared to the 51% expected and 53% from the previous year. Truist Securities maintained a Buy rating on Riskified, citing strong consumer spending and a robust sales pipeline.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'JPMorgan Upgrades Upstart to Overweight, Targets 88 Dollars by 2026 - https://www.ainvest.com/news/jpmorgan-upgrades-upstart-overweight-targets-88-dollars-2026-2508/\\', \\'text\\': \\'In contrast, JPMorgan has downgraded its rating for Kaspi.kz (KSPI.US) from \"overweight\" to \"neutral,\" and for CompoSecure (CMPO.US) and Riskified (RSKD.US) from \"neutral\" to \"underweight.\" The downgrade for CompoSecure is attributed to its fluctuating growth over multiple quarters and limited visibility into its full-year performance, which is heavily concentrated in the second half of the year.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'JPMorgan Upgrades Upstart to Overweight, Targets 88 Dollars by 2026 - https://www.ainvest.com/news/jpmorgan-upgrades-upstart-overweight-targets-88-dollars-2026-2508/\\', \\'text\\': \\'JPMorgan Upgrades Upstart to Overweight, Targets 88 Dollars by 2026\\'}, {\\'doc_id\\': 3, \\'source\\': \\'JPMorgan Upgrades Upstart to Overweight, Targets 88 Dollars by 2026 - https://www.ainvest.com/news/jpmorgan-upgrades-upstart-overweight-targets-88-dollars-2026-2508/\\', \\'text\\': \"For Riskified, the investment bank noted that its revenue and transaction volume growth rates have lagged behind the overall e-commerce industry and peers such as Shopify and Affirm. There is growing skepticism about Riskified\\'s ability to achieve its adjusted EBITDA margin target of 15-20% by 2026, which could exert continuous pressure on its stock price.\"}, {\\'doc_id\\': 3, \\'source\\': \\'JPMorgan Upgrades Upstart to Overweight, Targets 88 Dollars by 2026 - https://www.ainvest.com/news/jpmorgan-upgrades-upstart-overweight-targets-88-dollars-2026-2508/\\', \\'text\\': \\'- JPMorgan upgrades Upstart to \"overweight\" with $88 price target, citing stable credit trends and expected rate cuts boosting fintechs through 2025.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'JPMorgan Downgrades Riskified to Underweight, Raises Concerns Over E-commerce Growth. - https://www.ainvest.com/news/jpmorgan-downgrades-riskified-underweight-raises-concerns-commerce-growth-2508/\\', \\'text\\': \"JPMorgan downgraded Riskified (RSKD) to Underweight from Neutral due to trailing volume growth and revenue compared to the broader e-commerce group, attributed to weakness in the travel and luxury sectors. The firm is skeptical about Riskified\\'s ability to scale into its 2026 adjusted EBITDA margin targets.\"}, {\\'doc_id\\': 4, \\'source\\': \\'JPMorgan Downgrades Riskified to Underweight, Raises Concerns Over E-commerce Growth. - https://www.ainvest.com/news/jpmorgan-downgrades-riskified-underweight-raises-concerns-commerce-growth-2508/\\', \\'text\\': \"Riskified provides fraud prevention solutions for e-commerce businesses. Daily stocks & crypto headlines, free to your inbox ... Add a public comment... ... JPMorgan Posts 0.98% Drop With 37th-Ranked $2.09 Billion Trading Volume Amid Strategic Tech Collaborations and Retail Expansion ... Krispy Kreme Stock Plummets: JPMorgan\\'s Shocking Downgrade!\"}, {\\'doc_id\\': 5, \\'source\\': \\'JPMorgan downgrades commodities to underweight | Reuters - https://www.reuters.com/article/jpmorgan-commodities-idAFL4E7MN08920111123/\\', \\'text\\': \\'SINGAPORE, Nov 23 (Reuters) - JPMorgan Chase has downgraded commodities to underweight, saying policy failures in the United States and Europe have darkened the outlook for the next six months.\\'}, {\\'doc_id\\': 6, \\'source\\': \"J.P. Morgan downgrades PH stocks to \\'underweight\\' - https://mb.com.ph/2022/05/10/j-p-morgan-downgrades-ph-to-underweight/\", \\'text\\': \\'J.P. Morgan Global Research has downgraded the Philippines to “underweight” and ranked it last in the order of preference in ASEAN in its equity investment strategy immediately after the conclusion of national and local elections.\\'}, {\\'doc_id\\': 8, \\'source\\': \\'JPMorgan downgrades Krispy Kreme stock to Underweight on turnaround risks By Investing.com - https://in.investing.com/news/analyst-ratings/jpmorgan-downgrades-krispy-kreme-stock-to-underweight-on-turnaround-risks-93CH-4981458\\', \\'text\\': \\'JPMorgan downgrades Krispy Kreme stock to Underweight on turnaround risks\\'}, {\\'doc_id\\': 8, \\'source\\': \\'JPMorgan downgrades Krispy Kreme stock to Underweight on turnaround risks By Investing.com - https://in.investing.com/news/analyst-ratings/jpmorgan-downgrades-krispy-kreme-stock-to-underweight-on-turnaround-risks-93CH-4981458\\', \\'text\\': \\'Despite this, revenue slightly exceeded projections, reaching $379.8 million compared to the anticipated $378.66 million. In addition to the earnings report, Krispy Kreme is undergoing a strategic shift following the termination of its partnership with McDonald’s. Morgan Stanley has reiterated its Underweight rating on Krispy Kreme, maintaining a price target of $2.50.\\'}, {\\'doc_id\\': 8, \\'source\\': \\'JPMorgan downgrades Krispy Kreme stock to Underweight on turnaround risks By Investing.com - https://in.investing.com/news/analyst-ratings/jpmorgan-downgrades-krispy-kreme-stock-to-underweight-on-turnaround-risks-93CH-4981458\\', \\'text\\': \\'JPMorgan also noted that only five insiders hold approximately 48% of the company, with previous take-private investor JAB controlling about 43%, while underlying U.S.\\'}, {\\'doc_id\\': 9, \\'source\\': \\'JPMorgan downgrades Shanghai Junshi Biosciences stock to Underweight By Investing.com - https://www.investing.com/news/analyst-ratings/jpmorgan-downgrades-shanghai-junshi-biosciences-stock-to-underweight-93CH-4218600\\', \\'text\\': \\'JPMorgan downgrades Shanghai Junshi Biosciences stock to Underweight\\'}, {\\'doc_id\\': 9, \\'source\\': \\'JPMorgan downgrades Shanghai Junshi Biosciences stock to Underweight By Investing.com - https://www.investing.com/news/analyst-ratings/jpmorgan-downgrades-shanghai-junshi-biosciences-stock-to-underweight-93CH-4218600\\', \\'text\\': \\'While JPMorgan expressed encouragement about the company’s plans to advance additional assets into clinical development, it believes the current valuation already reflects significant optimism and requires more clinical data evidence to justify.\\'}]\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nThe year-over-year revenue growth percentage for Alibaba\\'s Cloud Intelligence Group in Q2 2025 was 26%.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \"Alibaba\\'s AI-Driven Cloud and E-Commerce Expansion: A High-Growth Bet for 2026? - https://www.ainvest.com/news/alibaba-ai-driven-cloud-commerce-expansion-high-growth-bet-2026-2509/\", \\'text\\': \\'Alibaba’s Cloud Intelligence Group has emerged as a cornerstone of its growth strategy. In Q2 2025, the division reported a 26% year-over-year revenue increase to RMB33.4 billion ($4.66 billion), driven by AI-related products that grew at triple-digit rates for the eighth consecutive quarter [1]. This performance underscores Alibaba’s pivot toward AI-native infrastructure, including its newly developed AI chip and partnerships with global chipmakers like NVIDIA and AMD [4]. The cloud unit’s adjusted EBITA rose 26% year-on-year, reflecting strong demand for AI-driven tools such as Qwen3 and Lingma, which are now embedded in enterprise workflows and consumer platforms like Taobao and Alipay [3].\\'}, {\\'doc_id\\': 0, \\'source\\': \"Alibaba\\'s AI-Driven Cloud and E-Commerce Expansion: A High-Growth Bet for 2026? - https://www.ainvest.com/news/alibaba-ai-driven-cloud-commerce-expansion-high-growth-bet-2026-2509/\", \\'text\\': \\'By 2025, over 100,000 enterprises had adopted Qwen3, and Alibaba.com aims for 100% AI adoption among its 200,000 merchants by year-end [5]. This push extends beyond e-commerce, with AI innovations like smart glasses and automotive cockpits showcased at the 2025 World Artificial Intelligence Conference [4]. Such diversification could unlock new revenue streams, though execution risks remain. Despite its AI-driven momentum, Alibaba faces hurdles. Free cash flow turned negative in Q2 2025 due to capital expenditures in cloud infrastructure and instant commerce [4], raising questions about short-term profitability.\\'}, {\\'doc_id\\': 0, \\'source\\': \"Alibaba\\'s AI-Driven Cloud and E-Commerce Expansion: A High-Growth Bet for 2026? - https://www.ainvest.com/news/alibaba-ai-driven-cloud-commerce-expansion-high-growth-bet-2026-2509/\", \\'text\\': \\'- Alibaba Group is repositioning as an AI-native enterprise, integrating cloud computing, e-commerce, and AI to drive its 2026 strategic goals. - Its Cloud Intelligence Group saw 26% YoY revenue growth in Q2 2025, fueled by triple-digit AI product growth and partnerships with NVIDIA/AMD.\\'}, {\\'doc_id\\': 0, \\'source\\': \"Alibaba\\'s AI-Driven Cloud and E-Commerce Expansion: A High-Growth Bet for 2026? - https://www.ainvest.com/news/alibaba-ai-driven-cloud-commerce-expansion-high-growth-bet-2026-2509/\", \\'text\\': \\'With a 33% share of China’s AI cloud market in 2025, it outpaces rivals like Huawei and Tencent [1]. This leadership is bolstered by strategic investments in open-source ecosystems and developer engagement, earning Alibaba Cloud a “Leader” designation in Omdia’s 2025 GenAI Cloud report [5]. However, its global market share remains modest at 4%, trailing AWS, Microsoft Azure, and Google Cloud [4]. To bridge this gap, Alibaba is expanding data centers in Southeast Asia and establishing AI Global Competency Centers, signaling a long-term play to capture emerging markets [3]. The e-commerc\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Alibaba Cloud revenue hits $3.64bn for the quarter - DCD - https://www.datacenterdynamics.com/en/news/alibaba-cloud-revenue-hits-364bn-for-the-quarter/\\', \\'text\\': \\'Alibaba has released its Q2 2024 financial results, with Alibaba Cloud seeing growth off the back of AI.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Alibaba Cloud revenue hits $3.64bn for the quarter - DCD - https://www.datacenterdynamics.com/en/news/alibaba-cloud-revenue-hits-364bn-for-the-quarter/\\', \\'text\\': \\'Alibaba CEO Eddie Wu said that Alibaba Cloud will see double-digit growth in the second half of 2024, with much of that driven by AI products. ... \"There\\\\\\'s very, very robust demand among our customers for AI and AI-relevant products,\" said Wu. \"Demand is still far from being satisfied.\" \"If you look at the industry as a whole, demand for CPU-based traditional cloud computing is relatively limited, where most of the growth is now focused on GPU-based AI product development.\"\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Alibaba Cloud revenue hits $3.64bn for the quarter - DCD - https://www.datacenterdynamics.com/en/news/alibaba-cloud-revenue-hits-364bn-for-the-quarter/\\', \\'text\\': \\'For the quarter, AI-related product revenue sustained \"triple-digit growth,\" with Wu saying in his opening remarks in the earnings call: \"We\\\\\\'re seeing more major customers choosing Alibaba Cloud as their compute infrastructure for AI development. At the same time, Alibaba\\\\\\'s proprietary large language models are gaining wider adoption.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Alibaba Cloud revenue hits $3.64bn for the quarter - DCD - https://www.datacenterdynamics.com/en/news/alibaba-cloud-revenue-hits-364bn-for-the-quarter/\\', \\'text\\': \\'Alibaba tactically cut the cost of its cloud services this year, with some reductions reaching as much as 55 percent for Chinese customers.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Alibaba reports 2% increase in revenue for Q2 2025 following strong growth in AI and cloud services - https://www.dimsumdaily.hk/alibaba-reports-2-increase-in-revenue-for-q2-2025-following-strong-growth-in-ai-and-cloud-services/\\', \\'text\\': \\'Home News Finance Alibaba reports 2% increase in revenue for Q2 2025 following strong growth... ... 29th August 2025 – (Hangzhou) Eddie Wu, Chief Executive Officer, stated, “This quarter, our strategic emphasis on consumption and AI + Cloud has driven robust growth.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Alibaba reports 2% increase in revenue for Q2 2025 following strong growth in AI and cloud services - https://www.dimsumdaily.hk/alibaba-reports-2-increase-in-revenue-for-q2-2025-following-strong-growth-in-ai-and-cloud-services/\\', \\'text\\': \\'Toby Xu, Chief Financial Officer, added, “Our core businesses achieved strong revenue growth, with customer management revenue increasing by 10% and revenue from the Cloud Intelligence Group rising by 26%. AI-related product revenue has seen triple-digit growth for eight consecutive quarters. This strength allows us to invest significantly in quick commerce and AI initiatives while improving operational efficiency, as AIDC has significantly narrowed its losses this quarter.” · In the quarter ending 30th June, 2025, revenue reached RMB247.65 billion (US$34.57 billion), marking a 2% year-on-year increase.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Alibaba reports 2% increase in revenue for Q2 2025 following strong growth in AI and cloud services - https://www.dimsumdaily.hk/alibaba-reports-2-increase-in-revenue-for-q2-2025-following-strong-growth-in-ai-and-cloud-services/\\', \\'text\\': \\'We have seen substantial synergies from our consumer platforms, leading to record highs in monthly active users and daily order volume. The Cloud Intelligence Group experienced accelerated revenue growth, with AI-related product revenue now making up a considerable portion of our external revenue.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Alibaba reports 2% increase in revenue for Q2 2025 following strong growth in AI and cloud services - https://www.dimsumdaily.hk/alibaba-reports-2-increase-in-revenue-for-q2-2025-following-strong-growth-in-ai-and-cloud-services/\\', \\'text\\': \\'Free cash flow was an outflow of RMB18.82 billion (US$2.63 billion), compared to an inflow of RMB17.37 billion in the previous year, primarily due to increased expenditures on cloud infrastructure and investments in “Taobao Instant Commerce.” As of June 30, 2025, cash and other liquid investments totalled RMB585.66 billion (US$81.76 billion).\\'}, {\\'doc_id\\': 3, \\'source\\': \\'How AI is Driving Alibaba’s Revenue Growth in 2025 - InfotechLead - https://infotechlead.com/artificial-intelligence/how-ai-is-driving-alibabas-revenue-growth-in-2025-90898\\', \\'text\\': \\'Alibaba Group continues to capitalize on the AI revolution, with artificial intelligence playing a central role in its revenue growth for the quarter ended June 30, 2025. The company reported total revenue of RMB 247.65 billion (US$34.57 billion), marking a 2 percent year-over-year increase, driven largely by strong performance in its AI and cloud businesses.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'How AI is Driving Alibaba’s Revenue Growth in 2025 - InfotechLead - https://infotechlead.com/artificial-intelligence/how-ai-is-driving-alibabas-revenue-growth-in-2025-90898\\', \\'text\\': \\'Alibaba’s Cloud Intelligence Group generated RMB 33.40 billion ($4.66 billion) in revenue, a 26 percent increase year-over-year, exceeding analyst expectations of 18.4 percent growth.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'How AI is Driving Alibaba’s Revenue Growth in 2025 - InfotechLead - https://infotechlead.com/artificial-intelligence/how-ai-is-driving-alibabas-revenue-growth-in-2025-90898\\', \\'text\\': \\'AI has become a central pillar of Alibaba’s growth strategy, powering both its cloud and e-commerce businesses. From tripling AI-related revenue for eight consecutive quarters to enhancing consumer engagement and international expansion, Alibaba’s focus on AI is not only driving immediate revenue growth but also positioning the company for long-term leadership in the global digital economy. ... Reliance Industries (RIL) has announced two major initiatives aimed... ... Snowflake posted $1.1 billion in revenue for Q2 FY26,...\\'}, {\\'doc_id\\': 3, \\'source\\': \\'How AI is Driving Alibaba’s Revenue Growth in 2025 - InfotechLead - https://infotechlead.com/artificial-intelligence/how-ai-is-driving-alibabas-revenue-growth-in-2025-90898\\', \\'text\\': \\'News website for Camera, AI, CIO, Cloud, Devices, Digital, Gaming, Network, Software, and Security. ... Reliance Industries (RIL) has announced two major initiatives aimed... ... India and the United States are strategic partners in... ... Snowflake posted $1.1 billion in revenue for Q2 FY26,... © 2025 Kizhakedath Media Services.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Cloud Market Share Q2 2025: Microsoft Dips, AWS Still Kingpin - https://www.crn.com/news/cloud/2025/cloud-market-share-q2-2025-microsoft-dips-aws-still-kingpin\\', \\'text\\': \\'In June, Oracle reported fourth fiscal quarter 2025 total cloud revenue of $6.7 billion, up 27 percent year over year. No. 4: Alibaba ... The Chinese cloud giant won 4 percent share of the global cloud market in the second quarter of 2025. Alibaba has consistently ranked in fourth place for the past several years with market share hovering around 4 percent quarter after quarter. In May, Alibaba’s Cloud Intelligence Group reported $4.15 billion in revenue for the first quarter of 2025, representing an increase of 18 percent year over year.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Cloud Market Share Q2 2025: Microsoft Dips, AWS Still Kingpin - https://www.crn.com/news/cloud/2025/cloud-market-share-q2-2025-microsoft-dips-aws-still-kingpin\\', \\'text\\': \\'Microsoft’s Intelligent Cloud group generated $29.9 billion in revenue during the second quarter of 2025, representing a 26 percent year-over-year growth rate.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Cloud Market Share Q2 2025: Microsoft Dips, AWS Still Kingpin - https://www.crn.com/news/cloud/2025/cloud-market-share-q2-2025-microsoft-dips-aws-still-kingpin\\', \\'text\\': \\'“This is a good time to be a cloud provider,” said John Dinsdale, a chief analyst at Synergy Research Group, in an email to CRN. “Despite being on the verge of becoming a $100-billion-per-quarter market, cloud revenues are still growing by around 25 percent per year, and we are forecasting that average annual growth over the next five years will remain above 20 percent,” Dinsdale said. [Related: AWS Vs. Microsoft Vs. Google Cloud Earnings Q2 2025 Face-Off] AWS, Alibaba, Google Cloud, Oracle and Microsoft were the top five leaders in the cloud market during the second quarter of 2025.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'Cloud Market Share Q2 2025: Microsoft Dips, AWS Still Kingpin - https://www.crn.com/news/cloud/2025/cloud-market-share-q2-2025-microsoft-dips-aws-still-kingpin\\', \\'text\\': \\'Cloud providers have seen quarterly revenue jump by $36 billion since the beginning of 2023, with GenAI being the major driver of this growth. CRN breaks down the cloud market-share figures for AWS, Alibaba, Google Cloud, Oracle and Microsoft—as well as other top 20 market leaders—for the second quarter of 2025.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Alibaba stock jumps as AI-driven cloud acceleration offsets Q2 results miss By Investing.com - https://www.in\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nThe study for the personalized cancer vaccine is expected to complete by 2027.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'When will patients see personalized cancer vaccines? — Harvard Gazette - https://news.harvard.edu/gazette/story/2024/04/when-will-patients-see-personalized-cancer-vaccines/\\', \\'text\\': \\'What’s exciting is that there also now is a series of industry-sponsored studies — my research group is not involved in them — that are ongoing nationwide, even worldwide, that, hopefully within the next two or three years, will give us a population-level view of the impact of such personal cancer vaccines.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'When will patients see personalized cancer vaccines? — Harvard Gazette - https://news.harvard.edu/gazette/story/2024/04/when-will-patients-see-personalized-cancer-vaccines/\\', \\'text\\': \\'“I hope that sometime in the not-too-distant future our patients can go to a clinic and say, ‘Order me up a vaccine personalized for my cancer,’ and we’ll be able to administer it on site.” · In your first study that came out in Nature in 2017, you treated six melanoma patients.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'When will patients see personalized cancer vaccines? — Harvard Gazette - https://news.harvard.edu/gazette/story/2024/04/when-will-patients-see-personalized-cancer-vaccines/\\', \\'text\\': \\'Catherine J. Wu has been a pioneer in a promising approach to fight cancer: a vaccine that targets the specific immunogenic peptides generated by the distinct tumor mutations of any individual cancer. Honored in February with the $1 million Sjöberg Prize, given for cancer research, Wu, a professor of medicine at Harvard Medical School and Lavine Family Chair for Preventative Cancer Therapies at the Dana-Farber Cancer Institute, spoke with the Gazette about the technology, its promise, and expectations that patients might see it in the near future.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'When will patients see personalized cancer vaccines? — Harvard Gazette - https://news.harvard.edu/gazette/story/2024/04/when-will-patients-see-personalized-cancer-vaccines/\\', \\'text\\': \\'I do know that three to four years after receiving the vaccine, all patients were still alive. We reported this result in 2021. Remarkably, two study patients who had very advanced cancer — stage IV disease — saw their cancer recur soon after vaccination.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Personalized Vaccine for Liver Cancer Shows Promise in Clinical Trial | Johns Hopkins Medicine - https://www.hopkinsmedicine.org/news/newsroom/news-releases/2024/04/personalized-vaccine-for-liver-cancer-shows-promise-in-clinical-trial\\', \\'text\\': \\'The most common adverse effect associated with the vaccine was mild injection site reactions. There were no serious adverse events. Nearly one-third of the patients treated with the combination therapy saw their tumors shrink—about twice as many patients as seen in studies of anti-PD-1 therapy alone in HCC. About 8% had a complete response with no evidence of tumor left after the combination treatment. “The study provides evidence that a personalized cancer vaccine can enhance clinical responses to anti-PD-1 therapy,” says lead author Mark Yarchoan, M.D., an associate professor of oncology at the Johns Hopkins University School of Medicine.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Personalized Vaccine for Liver Cancer Shows Promise in Clinical Trial | Johns Hopkins Medicine - https://www.hopkinsmedicine.org/news/newsroom/news-releases/2024/04/personalized-vaccine-for-liver-cancer-shows-promise-in-clinical-trial\\', \\'text\\': \\'Adding a personalized anti-tumor vaccine to standard immunotherapy is safe and about twice as likely to shrink cancer as standard immunotherapy alone for patients with hepatocellular carcinoma, the most common type of liver cancer, according to a clinical trial led by researchers at the Johns Hopkins Kimmel Cancer Center and its Convergence Institute. The study will be published April 7 in Nature Medicine, with findings also presented at 1:30 p.m.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Personalized Vaccine for Liver Cancer Shows Promise in Clinical Trial | Johns Hopkins Medicine - https://www.hopkinsmedicine.org/news/newsroom/news-releases/2024/04/personalized-vaccine-for-liver-cancer-shows-promise-in-clinical-trial\\', \\'text\\': \\'Decades of experience and research with cancer vaccines from study co-author Elizabeth Jaffee, M.D., deputy director of the Kimmel Cancer Center and the Dana and Albert “Cubby” Broccoli Professor of Oncology, and other visionary Johns Hopkins scientists have made the successful trial possible. Jaffee and her colleagues saw the potential of cancer vaccines early on and worked to overcome challenges to their development. “We are at an exciting time in new therapy development. Personalized vaccines are the next generation of vaccines that are showing promise in treating difficult cancers when given with immune checkpoint therapy.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Personalized Vaccine for Liver Cancer Shows Promise in Clinical Trial | Johns Hopkins Medicine - https://www.hopkinsmedicine.org/news/newsroom/news-releases/2024/04/personalized-vaccine-for-liver-cancer-shows-promise-in-clinical-trial\\', \\'text\\': \\'When the research team evaluated tumor biopsy samples taken from the study participants after they received the vaccine, they found evidence that T-cells were created in response to the vaccine that travelled to the tumor and attacked tumor cells. They also found that patients who received vaccines targeting the greatest number of mutant proteins had the best responses. This finding may help scientists create even more effective personalized cancer vaccines.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Promising signs in early trial for personalised cancer vaccines | The Royal Marsden - https://www.royalmarsden.nhs.uk/promising-signs-early-trial-personalised-cancer-vaccines\\', \\'text\\': \\'Tube strikes from 8-11 September are also expected to cause disruption. Please see the industrial action updates page for more information on affected routes. Researchers today (Monday 22 June) presented results from a phase 1 study, that saw some cancer patients receive vaccines based on unique information taken from their own tumour. Researchers found the personalised treatment was well tolerated, with patients largely experiencing low to moderate side effects.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Promising signs in early trial for personalised cancer vaccines | The Royal Marsden - https://www.royalmarsden.nhs.uk/promising-signs-early-trial-personalised-cancer-vaccines\\', \\'text\\': \\'Dr Lopez, who presented the results at this year’s virtual AACR conference (American Association for Cancer Research), added: “We were able to generate tumour-specific immune responses in the majority of evaluable patients, using a personalised cancer vaccine approach in combination with immune checkpoint blockade. It is like our overall low clinical response rate is due to the advanced disease many of patients had, and the large number of treatments they had already received.” · Researchers are looking to expand this area of investigation, to understand potential for patients with earlier stage cancers, and with a larger patient population. The study was funded by Genentech and BioNTech.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Promising signs in early trial for personalised cancer vaccines | The Royal Marsden - https://www.royalmarsden.nhs.uk/promising-signs-early-trial-personalised-cancer-vaccines\\', \\'text\\': \\'Because mutations are not shared between cancers, a personalised treatment approach that targets individual tumour neoantigens may be a viable immunotherapeutic strategy for numerous patients with cancer.” · Clinicians led by The Royal Marsden, The Institute of Cancer Research, London, and Barts Health NHS Trust investigated the vaccine, RO7198457, when given in combination with the immunotherapy drug atezolizumab (Tecentriq), in 144 patients who had advanced cancers.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Promising signs in early trial for personalised cancer vaccines | The Royal Marsden - https://www.royalmarsden.nhs.uk/promising-signs-early-trial-personalised-cancer-vaccines\\', \\'text\\': \\'Researchers found when they analysed blood samples of 63 patients, the immune system in 73 per cent had been activated in response to the vaccine. The clinical response rate was therefore low overall but did provide researchers with information for future research. \"We were able to generate tumour-specific immune responses in the majority of evaluable patients, using a personalised cancer vaccine approach in combination with immune checkpoint blockade.\"\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Here are 12 new advances in the battle to beat cancer | World Economic Forum - https://www.weforum.org/stories/2025/02/cancer-treatment-and-diagnosis-breakthroughs/\\', \\'text\\': \\'Thirty hospitals have joined the Cancer Vaccine Launch Pad, which matches patients with upcoming trials using the same mRNA technology found in current COVID-19 jabs. Over 200 patients from the UK, Germany, Belgium, Spain and Sweden will receive up to 15 doses of the personalized vaccine, with the study expected to complete by 2027.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Here are 12 new advances in the battle to beat cancer | World Economic Forum - https://www.weforum.org/stories/2025/02/cancer-treatment-and-diagnosis-breakthroughs/\\', \\'text\\': \\'Scientists working to improve the treatment and diagnosis of cancer are beginning to use AI, DNA sequencing and precision oncology among other techniques.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Here are 12 new advances in the battle to beat cancer | World Economic Forum - https://www.weforum.org/stories/2025/02/cancer-treatment-and-diagnosis-breakthroughs/\\', \\'text\\': \\'Breast, lung and colon cancer are among the most common, while the number of new cancer cases annually is expected to grow by more than 75% between 2022 and 2050. There is some good news, however. Medical advances are accelerating the battle against cancer. Here are 12 recent developments. Thousands of NHS cancer patients in England could soon access trials of a new vaccine treatment.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Here are 12 new advances in the battle to beat cancer | World Economic Forum - https://www.weforum.org/stories/2025/02/cancer-treatment-and-diagnosis-breakthroughs/\\', \\'text\\': \\'This involves studying the genetic makeup and molecular characteristics of cancer tumours in individual patients. The precision oncology approach identifies changes in cells that might be causing the cancer to grow and spread. Personalized treatments can then be developed.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'The current clinical landscape of personalized cancer vaccines - ScienceDirect - https://www.sciencedirect.com/science/article/pii/S0305737222000470\\', \\'text\\': \\'In this review, we describe the different types of personalized cancer vaccines and summarize the completed and ongoing cancer vaccination clinical trials in the last 10 years (database from www.clinicaltrials.gov). We also discuss the pros and cons of using different tumor animal models, i.e. syngeneic models, patient-derived xenografts models and genetically engineered mouse models, as tools for investigating cancer vaccination strategies. Finally, we describe preclinical studies that seek to test new emerging vaccination strategies as well as improving existing methods.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'The current clinical landscape of personalized cancer vaccines - ScienceDirect - https://www.sciencedirect.com/science/article/pii/S0305737222000470\\', \\'text\\': \\'Personalized cancer vaccines can trigger a broad-based antitumor response and long-term immunological memory.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'The current clinical landscape of personalized cancer vaccines - ScienceDirect - https://www.sciencedirect.com/science/article/pii/S0305737222000470\\', \\'text\\': \\'Preclinical tumor animal models are useful tools for investigating and improving cancer vaccination strategies. Due to the intrinsic genetic instability of tumor cells, aberrant and novel tumor antigens can be expressed and serve as potential targets for cancer immunotherapy.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Personalized Cancer Vaccine Proves Promising in a Phase 1 Trial at Mount Sinai | Mount Sinai - New York - https://www.mountsinai.org/about/newsroom/2025/personalized-cancer-vaccine-proves-promising-in-a-phase-1-trial-at-mount-sinai\\', \\'text\\': \\'Researchers at the Icahn School of Medicine at Mount Sinai, led by Nina Bhardwaj, MD, PhD, Ward-Coleman Chair in Cancer Research and Director of the Vaccine and Cell Therapy Laboratory, have tested a promising new type of personalized multi-peptide neoantigen cancer vaccine, called PGV001, in a small group of patients. This early study (phase 1 trial) is an important step in finding better ways to help people fight cancer.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Personalized Cancer Vaccine Proves Promising in a Phase 1 Trial at Mount Sinai | Mount Sinai - New York - https://www.mountsinai.org/about/newsroom/2025/personalized-cancer-vaccine-proves-promising-in-a-phase-1-trial-at-mount-sinai\\', \\'text\\': \\'The vaccine then teaches the immune system to target these changes, making treatment more personal and precise. Unlike tumor-associated antigens, neoantigens are not subject to central tolerance, meaning they can trigger a robust immune attack against cancer cells.  · “We wanted to develop cancer vaccines that can stop cancer from coming back in patients who are at high risk of recurrence. This study shows that making personalized cancer vaccines is possible and safe,” said Dr.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Personalized Cancer Vaccine Proves Promising in a Phase 1 Trial at Mount Sinai | Mount Sinai - New York - https://www.mountsinai.org/about/newsroom/2025/personalized-cancer-vaccine-proves-promising-in-a-phase-1-trial-at-mount-sinai\\', \\'text\\': \\'The study included patients who had already received standard cancer treatments but still had a high risk of the disease returning. Using a computational platform developed by Mount Sinai experts, scientists analyzed tumor and germline sequencing data to select the most promising neoantigens for each patient. The vaccine was then formulated with carefully chosen peptide sequences encoding neoantigens to optimize immune activation.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Personalized Cancer Vaccine Proves Promising in a Phase 1 Trial\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': \"Ground Truth:\\nThe article 'Infectious Disease Preparedness: Lessons and Strategies for 2025' was published on May 23, 2025.\\n\\nSnippet:\\n[{'doc_id': 0, 'source': '38. Till the next pandemic: National preparedness · Infectious Disease Emergencies: Preparedness and Response - https://emergencies.pubpub.org/pub/the-next-pandemic/release/3', 'text': 'Infectious Disease Emergencies: Preparedness and Response · Published on Jan 12, 2025DOI10.56159/emergencies-38 · Harsh lessons were learned by comparing the national level responses — and outcomes — during the acute pandemic emergency that was COVID-19.'}, {'doc_id': 0, 'source': '38. Till the next pandemic: National preparedness · Infectious Disease Emergencies: Preparedness and Response - https://emergencies.pubpub.org/pub/the-next-pandemic/release/3', 'text': 'Infectious diseases do not stop at political borders or geographic boundaries, so it is vital to run multi-country exercises, including, among others, sharing expertise and planning for cross-deployments. Our future preparedness plans must build upon trust and leadership, community engagement, improvements to public health communications and policy creation, data collection and disease modelling, rapid response capacity, integration of healthcare as a unified public health response, supply chain management, preparedness measurement tools, and the ability to develop therapies and vaccines [33]. One must also make allowances for critical distinctions between countries with differing economies.'}, {'doc_id': 0, 'source': '38. Till the next pandemic: National preparedness · Infectious Disease Emergencies: Preparedness and Response - https://emergencies.pubpub.org/pub/the-next-pandemic/release/3', 'text': 'Priorities are clear and lessons have been learned. All countries must individually and collectively improve their preparedness in order to have a better response to future events.'}, {'doc_id': 0, 'source': '38. Till the next pandemic: National preparedness · Infectious Disease Emergencies: Preparedness and Response - https://emergencies.pubpub.org/pub/the-next-pandemic/release/3', 'text': 'The litany has gone from “lessons learned” to lessons relearned to lessons ignored to lessons observed. Any brilliant new exposition of how to improve preparedness must address why the hundreds of other reports over the decades failed to catalyse the necessary national changes.'}, {'doc_id': 1, 'source': 'Preparedness and Response Considerations for High-Consequence Infectious Disease - Volume 31, Number 8—August 2025 - Emerging Infectious Diseases journal - CDC - https://wwwnc.cdc.gov/eid/article/31/8/25-0313_article', 'text': 'Understanding the resurgence of mpox: key drivers and lessons from recent outbreaks in Africa. Trop Med Health. 2025;53:47. DOIPubMedGoogle Scholar · Flinn JB, Hynes NA, Sauer LM, Maragakis LL, Garibaldi BT. The role of dedicated biocontainment patient care units in preparing for COVID-19 and other infectious disease outbreaks.'}, {'doc_id': 1, 'source': 'Preparedness and Response Considerations for High-Consequence Infectious Disease - Volume 31, Number 8—August 2025 - Emerging Infectious Diseases journal - CDC - https://wwwnc.cdc.gov/eid/article/31/8/25-0313_article', 'text': 'Marburg virus disease: A summary for clinicians. Int J Infect Dis. 2020;99:233–42. DOIPubMedGoogle Scholar · Branda F, Ceccarelli G, Giovanetti M, Albanese M, Binetti E, Ciccozzi M, et al. Nipah virus: a zoonotic threat re-emerging in the wake of global public health challenges. Microorganisms. 2025;13:124.'}, {'doc_id': 1, 'source': 'Preparedness and Response Considerations for High-Consequence Infectious Disease - Volume 31, Number 8—August 2025 - Emerging Infectious Diseases journal - CDC - https://wwwnc.cdc.gov/eid/article/31/8/25-0313_article', 'text': 'Infect Control Hosp Epidemiol. 2021;42:208–11. DOIPubMedGoogle Scholar · Smith PW, Anderson AO, Christopher GW, Cieslak TJ, Devreede GJ, Fosdick GA, et al. Designing a biocontainment unit to care for patients with serious communicable diseases: a consensus statement. Biosecur Bioterror. 2006;4:351–65. DOIPubMedGoogle Scholar · National Emerging Special Pathogens Training & Education Center. National Special Pathogen System (NSPS). 2025 [cited 2025 Apr 28]. https://netec.org/nsps/nsps-about-the-nsps'}, {'doc_id': 1, 'source': 'Preparedness and Response Considerations for High-Consequence Infectious Disease - Volume 31, Number 8—August 2025 - Emerging Infectious Diseases journal - CDC - https://wwwnc.cdc.gov/eid/article/31/8/25-0313_article', 'text': 'His research interests include understanding the epidemiology, prevention, and control of high-consequence infectious disease outbreaks. ... We thank Vikramjit Mukherjee for his critical review of this manuscript. The National Emerging Special Pathogens Training and Education Center is funded by the US Administration for Strategic Preparedness and Response (grant no.'}, {'doc_id': 2, 'source': 'Epidemic preparedness and response capacity against infectious disease outbreaks in 186 countries, 2018–2022 | BMC Infectious Diseases | Full Text - https://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-024-10168-8', 'text': 'Objectives Disruptive public health risks and events, including infectious disease outbreaks, are inevitable, but their effects can be mitigated by investing in prevention and preparedness. We assessed the epidemic preparedness and response capacities of health systems in 186 countries from 2018 to 2022.'}, {'doc_id': 2, 'source': 'Epidemic preparedness and response capacity against infectious disease outbreaks in 186 countries, 2018–2022 | BMC Infectious Diseases | Full Text - https://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-024-10168-8', 'text': 'Also, fostering strong leadership and coordination with international bodies, including civil society and private sector organizations, and improving connections across subnational, national, regional, and global levels are critical for improving epidemic preparedness in the region [34]. Additionally, increasing investments in digital health technologies and data-sharing platforms for faster outbreak detection and reporting, and integrating lessons from past outbreaks such as Ebola and COVID-19 into national preparedness plans, are crucial for building more resilient health systems [3, 23]. Ou'}, {'doc_id': 2, 'source': 'Epidemic preparedness and response capacity against infectious disease outbreaks in 186 countries, 2018–2022 | BMC Infectious Diseases | Full Text - https://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-024-10168-8', 'text': 'The occurrence and impact of infectious disease outbreaks and other disruptive public health risks and events can be significantly reduced by investing in prevention, preparedness, and response measures [1]. Responsible for over 6.9 million deaths globally as of October 2023, the COVID-19 pandemic has highlighted the need for countries to strengthen their health system preparedness for public health emergencies [2, 3]. Evidence points to the increasing risk of emerging infectious diseases due to factors like international travel, trade, animal husbandry, rising human population density, and in'}, {'doc_id': 2, 'source': 'Epidemic preparedness and response capacity against infectious disease outbreaks in 186 countries, 2018–2022 | BMC Infectious Diseases | Full Text - https://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-024-10168-8', 'text': 'Fourth, our analysis focused on regional trends rather than country-level trends, which would have provided more detailed insights into individual countries’ epidemic preparedness issues. However, our more workable approach allowed us to capture broader patterns and dynamics, such as the persistent, unimproving gap in the timely detection of infectious disease outbreaks and the across-the-board weakness in IHR capacities in SSA countries.'}, {'doc_id': 3, 'source': 'Infectious Disease Preparedness: Lessons and Strategies for 2025 - https://medicalrealities.com/infectious-disease-preparedness-lessons-and-strategies-for-2025/', 'text': 'So as we dive into the lessons and strategies shaping infectious disease preparedness in 2025, keep in mind how interconnected and dynamic this field is. There’s no one-size-fits-all solution.'}, {'doc_id': 3, 'source': 'Infectious Disease Preparedness: Lessons and Strategies for 2025 - https://medicalrealities.com/infectious-disease-preparedness-lessons-and-strategies-for-2025/', 'text': 'Infectious disease preparedness in 2025 stands at a complex crossroads—a dynamic intersection of scientific innovation, global cooperation, and social engagement. The lessons of past outbreaks have carved a path forward, but the journey is far from over.'}, {'doc_id': 3, 'source': 'Infectious Disease Preparedness: Lessons and Strategies for 2025 - https://medicalrealities.com/infectious-disease-preparedness-lessons-and-strategies-for-2025/', 'text': 'At its heart, infectious disease preparedness is a collective endeavor. It’s a reminder that in a world so interconnected, health is a shared responsibility. By investing in systems, science, and relationships now, we create a foundation that not only defends against future threats but also builds healthier, more resilient societies. So, as you reflect on these lessons and strategies, consider your own role in this global effort.'}, {'doc_id': 3, 'source': 'Infectious Disease Preparedness: Lessons and Strategies for 2025 - https://medicalrealities.com/infectious-disease-preparedness-lessons-and-strategies-for-2025/', 'text': 'So, research and innovation keep us evolving, adapting, and improving our defenses. They remind us that preparedness isn’t static; it’s a dynamic process that requires curiosity, creativity, and collaboration. As we navigate through 2025, it’s clear that infectious disease preparedness is evolving faster than ever.'}, {'doc_id': 4, 'source': 'Exploring Future Pandemic Preparedness Through the Development of Preventive Vaccine Platforms and the Key Roles of International Organizations in a Global Health Crisis - https://www.mdpi.com/2076-393X/13/1/56', 'text': 'Submission received: 22 November 2024 / Revised: 27 December 2024 / Accepted: 8 January 2025 / Published: 10 January 2025 ... Background: The emergence of more than 40 new infectious diseases since the 1980s has emerged as a serious global health concern, many of which are zoonotic. In response, many international organizations, including the US Centers for Disease Control and Prevention (CDC), the World Health Organization (WHO), and the European Center for Disease Prevention and Control (ECDC), have developed strategies to combat these health threats.'}, {'doc_id': 4, 'source': 'Exploring Future Pandemic Preparedness Through the Development of Preventive Vaccine Platforms and the Key Roles of International Organizations in a Global Health Crisis - https://www.mdpi.com/2076-393X/13/1/56', 'text': 'In the example above, the ability to rapidly produce and distribute effective vaccines is key to pandemic preparedness and response strategies. Therefore, vaccine technology platforms and international networks are expected to play crucial roles in controlling the spread of infectious diseases and responding swiftly to the emergence of new or variant viruses in the next generation [14]. Global collaboration is necessary to create a fair platform that provides equal benefits to all countries through safe, effective, and quality-assured vaccines and medicines.'}, {'doc_id': 4, 'source': 'Exploring Future Pandemic Preparedness Through the Development of Preventive Vaccine Platforms and the Key Roles of International Organizations in a Global Health Crisis - https://www.mdpi.com/2076-393X/13/1/56', 'text': 'International organizations such as the WHO, CEPI, GAVI, Bill & Melinda Gates Foundation (BMGF), Research Investment for Global Health Technology (RIGHT) Foundation, and IVI have actively announced support strategies to establish rapid vaccine development platforms and strategies in response to future pandemics caused by Disease X. In this study, WHO, CEPI, GAVI, and IVI were selected as international vaccine development support organizations that play a coordinated role in vaccine support, and their respective infectious disease preparedness programs were analyzed [15].'}, {'doc_id': 4, 'source': 'Exploring Future Pandemic Preparedness Through the Development of Preventive Vaccine Platforms and the Key Roles of International Organizations in a Global Health Crisis - https://www.mdpi.com/2076-393X/13/1/56', 'text': 'Jeon, J., & Kim, E. (2025). Exploring Future Pandemic Preparedness Through the Development of Preventive Vaccine Platforms and the Key Roles of International Organizations in a Global Health Crisis. Vaccines, 13(1), 56. https://doi.org/10.3390/vaccines13010056 · Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here. clear ... For Authors For Reviewers For Editors For Librarians For Publishers For Societies For Conference Organizers'}, {'doc_id': 5, 'source': 'Health Systems Preparedness for Infectious Disease Outbreaks: Relevance for Nephrology - ScienceDirect - https://www.sciencedirect.com/science/article/pii/S0270929523001754', 'text': 'Only with adequate preparation and more resilient health systems can we hope, as a global community, to build on the harsh lessons learned during COVID-19, and improve the response to the next infectious disease outbreak, epidemic, or even pandemic. ... Financial support: none. Conflicts of interest statement: Valerie A. Luyckx receives royalties as editor of “The Kidney” textbook, and is the Advoc\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nThe world\\'s first robotic massage therapy system mentioned in the article is Aescape.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'Wellness Trends for 2025 Shaping the Future of Health and Wellbeing - Destination Deluxe - https://destinationdeluxe.com/wellness-trends-2025/\\', \\'text\\': \\'From clean beauty and AI intergation to DNA testing and social wellness, read our predicted wellness trends for 2025\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Wellness Trends for 2025 Shaping the Future of Health and Wellbeing - Destination Deluxe - https://destinationdeluxe.com/wellness-trends-2025/\\', \\'text\\': \\'Moving beyond infrared saunas, cryotherapy, and sound healing chambers, 2025 is ushering in a new era of innovation with the introduction of robotics in wellness. One notable example is Aescape, the world’s first robotic massage therapy system, which uses advanced AI-powered robot arms to deliver precise, personalized massages without human touch.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Wellness Trends for 2025 Shaping the Future of Health and Wellbeing - Destination Deluxe - https://destinationdeluxe.com/wellness-trends-2025/\\', \\'text\\': \\'The growing interest in touchless treatments signals a shift towards innovative, tech-driven approaches that cater to modern wellness needs. As concerns about hygiene and the desire for personalized care continue to shape consumer preferences, robotic massage systems like Aescape are poised to become mainstream. These treatments offer a unique blend of precision, consistency, and data-driven customization, appealing to a broad demographic seeking safe, efficient, and effective alternatives to traditional therapies.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'Wellness Trends for 2025 Shaping the Future of Health and Wellbeing - Destination Deluxe - https://destinationdeluxe.com/wellness-trends-2025/\\', \\'text\\': \\'To make it easier, the team at Destination Deluxe has highlighted the most significant wellness trends for 2025 — each one promising to redefine our approach to physical, mental, and emotional health. Get ready to discover what’s next in the world of wellness. ... The rise of self-empowered wellness signals a shift towards sovereignty in health management, where wellness enthusiasts embrace biohacking and take control of their wellbeing through self-directed experimentation.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'The Future of Wellness 2025 Trends Report Key Takeaways | BeautyMatter - https://beautymatter.com/articles/the-new-touchpoints-of-wellness-in-2025\\', \\'text\\': \\'As some consumers embrace slower travel and more luxury-focused experiences, cruises and train travel are being given luxury updates like Dior Spa carriages on Belmond trains or COMO Hotels offering an Arctic cruise with COMO Shambhala wellness treatments like deep tissue massages. The spa treatments aboard cruise ships like Crystal Cruises include IV therapies, Restylane, and Elemis facials, show no lack of prestige compared to on-land offerings. Blue World Voyages offers a sports and wellness-themed cruise, with yoga and fitness amenities as well as air and water purification systems, vitamin C-infused showers, and circadian lighting onboard, a departure from debaucherous days of heavy drinking and gambling some might find on other ships.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'The Future of Wellness 2025 Trends Report Key Takeaways | BeautyMatter - https://beautymatter.com/articles/the-new-touchpoints-of-wellness-in-2025\\', \\'text\\': \"Spaces like Qatar’s Zulal Wellness Resort, which blends contemporary spa treatments with traditional Arabic and Islamic medicine will be sites of ancient practices mixing with modern facilities. Equally, The Longevity Hub with locations including Abu Dhabi and Riyadh, offers quantum body scanning and red light therapy alongside breathwork sessions. SHA Emirates, described as “the world\\'s first healthy living island” with more than 100 residencies, is expected to open in 2026.\"}, {\\'doc_id\\': 1, \\'source\\': \\'The Future of Wellness 2025 Trends Report Key Takeaways | BeautyMatter - https://beautymatter.com/articles/the-new-touchpoints-of-wellness-in-2025\\', \\'text\\': \\'As an antidote to the brain and culture rotting happening through constant online culture, individuals are embracing retro, even preindustrial experiences. While AI is undoubtedly infiltrating wellness through wearables, algorithm-driven fitness plans, or massage robots, that same technology is also driving the need for human experiences.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'The Future of Wellness 2025 Trends Report Key Takeaways | BeautyMatter - https://beautymatter.com/articles/the-new-touchpoints-of-wellness-in-2025\\', \\'text\\': \\'Aside from ensuring cross-generational diversity, employers should also ensure their work environments offer additional health benefits for employees. ... Whether it’s smartphone or substance addiction, treatment options are getting a luxury upgrade, with sober-curious and technology-free retreats hosted at five-star-worthy treatment centers like Carrara Treatment, Wellness & Spa in California and Paracelsus Recovery in Zurich, which offer spa treatment, yoga, and nutritional therapy alongside their treatment programs.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'The Future of Wellness trends survey 2025 | McKinsey - https://www.mckinsey.com/industries/consumer-packaged-goods/our-insights/future-of-wellness-trends\\', \\'text\\': \\'There are also differences in how younger and older consumers spend across wellness categories. While purchase rates for essential consumer health categories (such as oral care, cough and cold medication, and personal hygiene) are similar across demographics, younger consumers tend to purchase across a wider range of discretionary products (Exhibit 3), including health-tracking devices, massage tools, IV drips, and beauty and mindfulness apps.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'The Future of Wellness trends survey 2025 | McKinsey - https://www.mckinsey.com/industries/consumer-packaged-goods/our-insights/future-of-wellness-trends\\', \\'text\\': \\'Effective strategies include comarketing complementary products—such as skin care paired with at-home aesthetic devices like red-light therapy masks—and forging unique distribution collaborations, such as those between beauty and wellness players (supplements could be sold in beauty retailers, for example, while beauty products could be sold in fitness chains or health clinics).\\'}, {\\'doc_id\\': 3, \\'source\\': \\'The Future of Wellness trends survey 2025 | McKinsey - https://www.mckinsey.com/industries/consumer-packaged-goods/our-insights/future-of-wellness-trends\\', \\'text\\': \\'Fifty-six percent of in-person service purchasers in the United States reported traveling two or more hours for wellness retreats and 45 percent reported traveling that same amount of time for thermal therapies or yoga classes. Nearly 60 percent of consumers who traveled for health and wellness treatments in 2024 also said they expect to travel for these treatments in the next year.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'The Future of Wellness trends survey 2025 | McKinsey - https://www.mckinsey.com/industries/consumer-packaged-goods/our-insights/future-of-wellness-trends\\', \\'text\\': \\'While older generations tend to think of mental health solutions as those that are explicitly tied to treatment (such as talk therapy), younger generations are adopting a range of behaviors and making unexpected purchases, from skin care regimens to sleep hygiene, fitness routines, and socializing, in the name of improving their mental well-being.\\'}, {\\'doc_id\\': 4, \\'source\\': \"2025 Spa Trends You Can\\'t Miss: The Future Of Wellness Is Here! | Spavelous - https://spavelous.com/2025-spa-trends-you-cant-miss-future-of-wellness/\", \\'text\\': \\'Self-guided meditation pods and robotic massages are making wellness accessible and interactive like never before. Resense Spa in Geneva is leading the charge with touchless treatments that blend AI and virtual reality, offering guests deeply immersive relaxation journeys without the need for physical touch. More than ever, spas are focusing on mental wellness. Treatments combining massage with aromatherapy, sound therapy, and guided meditation will be more commonplace, creating experiences that nurture the mind as much as the body.\\'}, {\\'doc_id\\': 4, \\'source\\': \"2025 Spa Trends You Can\\'t Miss: The Future Of Wellness Is Here! | Spavelous - https://spavelous.com/2025-spa-trends-you-cant-miss-future-of-wellness/\", \\'text\\': \\'Inspired by the Japanese practice of Shinrin-Yoku, this massage takes place outdoors in a forested area, combining the healing effects of nature with therapeutic massage. The Scarlet Hotel in Cornwall, UK, offers this treatment, allowing guests to reconnect with nature while releasing tension. Spas are offering intravenous vitamin and nutrient therapy to help guests recharge from the inside out. The Ranch Malibu is incorporating nutrient IVs into their wellness programs, providing an instant boost to energy levels and overall health.\\'}, {\\'doc_id\\': 4, \\'source\\': \"2025 Spa Trends You Can\\'t Miss: The Future Of Wellness Is Here! | Spavelous - https://spavelous.com/2025-spa-trends-you-cant-miss-future-of-wellness/\", \\'text\\': \\'Cal-a-Vie Health Spa in California is at the forefront, offering vibrational healing sessions to harmonize energy and promote deep relaxation. A deeply relaxing treatment that combines elements of massage, joint mobilization, and shiatsu in warm water. The Chedi Andermatt in Switzerland offers Watsu sessions that help guests release physical and emotional tension while floating effortlessly. ... 2025 is all about embracing wellness in every possible way — from mind and body to community and the environment.\\'}, {\\'doc_id\\': 4, \\'source\\': \"2025 Spa Trends You Can\\'t Miss: The Future Of Wellness Is Here! | Spavelous - https://spavelous.com/2025-spa-trends-you-cant-miss-future-of-wellness/\", \\'text\\': \\'The Miraval Resort and Spa in Arizona will continue to lead the way with innovative mental wellness therapies, including their popular sound healing sessions that aim to balance mind and body. Eco-conscious spa-goers, rejoice! Sustainability is at the forefront of spa development in 2025, with spas using natural, locally-sourced products and minimizing their environmental footprint.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Global Wellness Summit Releases 10 Wellness Trends for 2025 - https://www.prnewswire.com/news-releases/global-wellness-summit-releases-10-wellness-trends-for-2025-302361531.html\\', \\'text\\': \\'A health and wellbeing company founded in 1959, Amway has a presence in more than 100 countries and territories around the world. For 12 years running, they\\\\\\'ve been named the number one direct selling company in the world. \"As the wellness industry continues to evolve, The Future of Wellness report plays a critical role in identifying and understanding emerging trends and providing insights that guide product innovation and strategic direction,\" said\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Global Wellness Summit Releases 10 Wellness Trends for 2025 - https://www.prnewswire.com/news-releases/global-wellness-summit-releases-10-wellness-trends-for-2025-302361531.html\\', \\'text\\': \\'As more destructive droughts loom, and as the public becomes more aware of water shortage issues, it will become imperative for the spa and wellness industries to change their practices—or risk being seen as an outdated, ethically obsolete model of wellbeing that neglects this rising crisis in planetary wellness.  · Augmented Biology Unlocking Human Potential Through Advanced Health Optimization · As advancements in health technology and genetic engineering unfold, a new paradigm is taking shape in which health is not merely sustained, but actively optimized and extended, enabling people to unlock their full neural, physiological, and psychological potential.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Global Wellness Summit Releases 10 Wellness Trends for 2025 - https://www.prnewswire.com/news-releases/global-wellness-summit-releases-10-wellness-trends-for-2025-302361531.html\\', \\'text\\': \\'Digital innovation is transforming healthcare in the Middle East, especially within the GCC countries, with major investments in artificial intelligence, robotics, genomic medicine and digital healthcare infrastructure. The market for beauty products celebrating Middle Eastern heritage is growing, with products like Asteri Beauty\\\\\\'s vegan, \"desert-proof\" collection, or MZN Bodycare\\\\\\'s line, inspired by the plants of Saudi Arabia. Extremely ambitious investment in preventative healthcare, sports, and wellness infrastructure and tourism, are creating a new global hub for wellbeing—one that once seemed unlikely.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Global Wellness Summit Releases 10 Wellness Trends for 2025 - https://www.prnewswire.com/news-releases/global-wellness-summit-releases-10-wellness-trends-for-2025-302361531.html\\', \\'text\\': \\'In a polarized wellness market, we\\\\\\'ll see both \"analog wellness\" (a great logging off and seizing of pre-digital experiences) and a futuristic \"augmented biology\" for superhuman optimization; saunas and supplements will be reimagined; and the wellness world will tackle serious issues like addiction, teen wellness, the global water crisis, and the aging workforce · MIAMI, Jan. 28, 2025 /PRNewswire/ -- The  · Global Wellness Summit (GWS) today released its annual Future of Wellness report, the longest-running, most detailed (130-page) forecast of what will make waves in health and wellness in the year ahead.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'Satisfaction and Feasibility Evaluation of an Electronic Massager—Expert Manipulative Massage Automation (EMMA): A Pilot Study - PMC - https://pmc.ncbi.nlm.nih.gov/articles/PMC10498686/\\', \\'text\\': \\'Depending on the parameters set by the healthcare professional or the user, the massage experience can be customized to be gentler or more intense, focused on specific areas, or adjusted in other ways to better fit the user’s needs. These settings could vary for each participant, creating unique massage experiences. Thus, as with any medical or therapeutic intervention, the effectiveness of the EMMA massage robot needs to be validated through well-designed clinical trials.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'Satisfaction and Feasibility Evaluation of an Electronic Massager—Expert Manipulative Massage Automation (EMMA): A Pilot Study - PMC - https\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n",
      "{'input_ids': tensor([[32010,  1632,   618,  ..., 29889, 32007, 32001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "Error: 'SlidingWindowLayer' object has no attribute 'max_batch_size'\n",
      "[{'role': 'user', 'content': 'Ground Truth:\\nThe article \\'10 Health Trends of 2025 Revolutionizing Healthcare\\' was published on December 10, 2024.\\n\\nSnippet:\\n[{\\'doc_id\\': 0, \\'source\\': \\'10 Health Trends of 2025 Revolutionizing Healthcare | MedPark Hospital - https://www.medparkhospital.com/en-US/lifestyles/10-health-trends-of-2025\\', \\'text\\': \\'2025 is poised to be a pivotal moment of transformative changes in medicine. Groundbreaking technological advancements will reshape healthcare, enhancing efficiency and enabling individuals to access and understand their health information more easily.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'10 Health Trends of 2025 Revolutionizing Healthcare | MedPark Hospital - https://www.medparkhospital.com/en-US/lifestyles/10-health-trends-of-2025\\', \\'text\\': \\'The health trends anticipated for 2025 signal a significant transformation of the healthcare landscape. Treatments will become increasingly precise and personalized, emphasizing holistic care that addresses physical and mental well-being driven by cutting-edge technology. People will have easier and quicker access to health information and medical services. 2025 will revolutionize healthcare, ushering in a new era of precision and accessibility that promotes sustainable and improved well-being.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'10 Health Trends of 2025 Revolutionizing Healthcare | MedPark Hospital - https://www.medparkhospital.com/en-US/lifestyles/10-health-trends-of-2025\\', \\'text\\': \\'In 2025, we anticipate increased products and services that reflect these values. With the ability to rapidly analyze vast amounts of data with precision, Artificial Intelligence (AI) and Machine Learning are revolutionizing disease diagnosis. These technologies enable early detection of illnesses and more accurate prediction of personal health trends.\\'}, {\\'doc_id\\': 0, \\'source\\': \\'10 Health Trends of 2025 Revolutionizing Healthcare | MedPark Hospital - https://www.medparkhospital.com/en-US/lifestyles/10-health-trends-of-2025\\', \\'text\\': \\'The Royal Society of Thailand (2020) defines Precision Medicine as a medical approach that delivers highly effective and personalized health treatments by targeting specific factors such as genetics, environment, lifestyle, and more. Precision medicine can maximize treatment efficacy while minimizing unwanted side effects. It represents a revolution in modern medicine and healthcare that deserves significant attention\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Top 10 Healthcare Trends in 2025 | Transforming the Future of Healthcare - https://www.emergenresearch.com/blog/top-10-healthcare-trends-in-2025\\', \\'text\\': \\'Healthcare executives are reporting increased optimism, with 69% expecting revenue growth and 71% anticipating greater profitability in 2025 indicating high industry confidence in these emerging trends. The intersection of wearable technology, telemedicine, mental health solutions, and green practices is building an ecosystem in which patient care becomes more preventive, proactive, and targeted than ever. · Artificial Intelligence and Machine Learning Revolution · · Precision Medicine and Personalized Treatment Approaches · · Telehealth and Remote Healthcare Services Expansion\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Top 10 Healthcare Trends in 2025 | Transforming the Future of Healthcare - https://www.emergenresearch.com/blog/top-10-healthcare-trends-in-2025\\', \\'text\\': \\'The 2025 health industry is experiencing a revolutionary tidal wave with technology advancements, changed patient expectations, and transformed healthcare delivery models. These ten trends indicate fundamental shifts towards more patient-centered, accessible, efficient, and sustainable healthcare systems with an emphasis on patient outcomes and addressing operational issues facing healthcare organizations internationally.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Top 10 Healthcare Trends in 2025 | Transforming the Future of Healthcare - https://www.emergenresearch.com/blog/top-10-healthcare-trends-in-2025\\', \\'text\\': \\'The healthcare industry in 2025 is at the forefront of a record-breaking technological revolution, catalyzed by groundbreaking innovations that are fundamentally transforming the way medical care is being delivered, accessed, and experienced worldwide. From AI-driven diagnostics to precision medicine based on individual genetic data this year marks a milestone with digital health technology converging to create smarter, more accessible, and tailored healthcare systems.\\'}, {\\'doc_id\\': 1, \\'source\\': \\'Top 10 Healthcare Trends in 2025 | Transforming the Future of Healthcare - https://www.emergenresearch.com/blog/top-10-healthcare-trends-in-2025\\', \\'text\\': \"Since the Medical Waste Tracking Act expired in 1991, medical waste regulation has primarily fallen under state environmental and health departments\\' jurisdiction, with additional oversight from federal agencies including the CDC, OSHA, and FDA. Automation solutions are revolutionizing healthcare workforce management and operational effectiveness in 2025, solving ongoing challenges such as workforce shortages and administrative complexity.\"}, {\\'doc_id\\': 2, \\'source\\': \\'Top health care trends of 2025 and how they will impact U.S. employers - https://newsroom.cigna.com/top-health-care-trends-of-2025\\', \\'text\\': \\'This article was created with the assistance of AI tools. It was reviewed, edited, and fact-checked by Cigna Healthcare’s editorial team and subject matter experts.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Top health care trends of 2025 and how they will impact U.S. employers - https://newsroom.cigna.com/top-health-care-trends-of-2025\\', \\'text\\': \\'Access to behavioral health care has improved greatly over the last 5 to 10 years, yet it remains an issue for many Americans. In 2025, we will see a bigger shift toward integrating mental health into primary care to improve access, as well as advances in behavioral care navigation through personalized assistance, identifying the right methods of care, helping people find appointments, and providing 24/7 real-time clinical support.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Top health care trends of 2025 and how they will impact U.S. employers - https://newsroom.cigna.com/top-health-care-trends-of-2025\\', \\'text\\': \\'In 2025, clinical excellence will be emphasized through benefits that offer whole-person support, clinical guidance, and end-to-end integrated care models and solutions in areas such as women’s health and condition-specific care. Integrated care models that focus on holistic patient care will become of utmost importance. A review of 34 studies published in the National Library of Medicine found that integrated care models reduce costs, help eliminate waste, improve health outcomes, and increase patient satisfaction.\\'}, {\\'doc_id\\': 2, \\'source\\': \\'Top health care trends of 2025 and how they will impact U.S. employers - https://newsroom.cigna.com/top-health-care-trends-of-2025\\', \\'text\\': \\'Individual and family medical and dental insurance plans are insured by Cigna Health and Life Insurance Company (CHLIC), Cigna HealthCare of Arizona, Inc., Cigna HealthCare of Illinois, Inc., Cigna HealthCare of Georgia, Inc., Cigna HealthCare of North Carolina, Inc., Cigna HealthCare of South Carolina, Inc., and Cigna HealthCare of Texas, Inc.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Technology Trends in Healthcare for 2025 - https://stfalcon.com/en/blog/post/technology-trends-in-healthcare\\', \\'text\\': \\'The 21st century has propelled medicine into an era of rapid technological advancements, revolutionizing patient care. As we look ahead, the possibilities for future trends in healthcare technology appear boundless, pushing the boundaries of what we once thought was possible. The emerging healthcare industry trends in 2025 hold tremendous potential for significantly enhancing the well-being of patients on a global scale.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Technology Trends in Healthcare for 2025 - https://stfalcon.com/en/blog/post/technology-trends-in-healthcare\\', \\'text\\': \"Many healthcare centers are adopting Fast Healthcare Interoperability Resources (FHIR) to advance interoperability and address challenges in seamless data sharing. Beyond the legal considerations, this technology sets the stage for a paradigm shift from traditional paper-based records to a more agile and interconnected approach. Let\\'s build a solution that\\'s smart, sleek, and powerful.contact us ... Since 2020, telemedicine has undergone significant growth, revolutionizing the way patients and healthcare professionals engage in consultations, it became a significant technology trend in healthcare.\"}, {\\'doc_id\\': 3, \\'source\\': \\'Technology Trends in Healthcare for 2025 - https://stfalcon.com/en/blog/post/technology-trends-in-healthcare\\', \\'text\\': \\'The future of the industry will be shaped by the latest technology in healthcare trends that will redefine the entire medical industry. With the convergence of innovation, data utilization, and patient-centric care, we are witnessing a revolution that transcends traditional boundaries.\\'}, {\\'doc_id\\': 3, \\'source\\': \\'Technology Trends in Healthcare for 2025 - https://stfalcon.com/en/blog/post/technology-trends-in-healthcare\\', \\'text\\': \\'Predictive analytics, personalized medicine, and digital twin technology are just a few examples of the top digital trends in healthcare that are revolutionizing patient care by enhancing quality, efficiency, and agility.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'2025 global health care outlook | Deloitte Insights - https://www.deloitte.com/us/en/insights/industry/health-care/life-sciences-and-health-care-industry-outlooks/2025-global-health-care-executive-outlook.html\\', \\'text\\': \\'A Deloitte survey reveals that health care executives in six countries are prioritizing efficiency, productivity, and patient engagement in 2025\\'}, {\\'doc_id\\': 4, \\'source\\': \\'2025 global health care outlook | Deloitte Insights - https://www.deloitte.com/us/en/insights/industry/health-care/life-sciences-and-health-care-industry-outlooks/2025-global-health-care-executive-outlook.html\\', \\'text\\': \\'Healthcare Asia Magazine, “NABH launches preliminary standards for HIS, EMR systems; seeks feedback,” Medical Buyer, July 24, 2024. View in Article · Ministry of Health of the Republic of Indonesia, “Blueprint for digital health transformation strategy 2024 for Indonesia”. View in Article · Asthma and Allergy Foundation of America, “Climate change and health,” accessed Jan. 13, 2025.\\'}, {\\'doc_id\\': 4, \\'source\\': \\'2025 global health care outlook | Deloitte Insights - https://www.deloitte.com/us/en/insights/industry/health-care/life-sciences-and-health-care-industry-outlooks/2025-global-health-care-executive-outlook.html\\', \\'text\\': \\'13, 2025. View in Article · Katie Palmer, “Generative AI is transforming radiology, and it’s only the beginning,” STAT, Dec. 6, 2024. View in Article · Deloitte Global, “Trust in the era of generative AI,” August 21, 2024. View in Article · Dr. Chinta Sidharthan, “FDA strengthens AI regulation to ensure patient safety and innovation in healthcare\\'}, {\\'doc_id\\': 4, \\'source\\': \\'2025 global health care outlook | Deloitte Insights - https://www.deloitte.com/us/en/insights/industry/health-care/life-sciences-and-health-care-industry-outlooks/2025-global-health-care-executive-outlook.html\\', \\'text\\': \\'For example, all nine private hospitals in Singapore have committed to sharing patient health information with the country’s national EHR, the Ministry of Health announced in late 2024.18 Malaysia is currently in the process of establishing a national EMR.19 IHH Healthcare, a private company that operates 80 hospitals across 10 countries, recently moved some on-site hospital database systems in Malaysia and Singapore to the cloud.20\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Next in health services: trends and analysis for 2025 - https://www.pwc.com/us/en/industries/health-industries/library/healthcare-trends.html\\', \\'text\\': \\'You can rise above the challenges of the new year by acting on the 10 sector dynamics we outline for 2025. Forge your future by creating a business model capable of delivering value for a healthier business and healthier patients and consumers. At the start of 2024, we expected a calmer year for healthcare.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Next in health services: trends and analysis for 2025 - https://www.pwc.com/us/en/industries/health-industries/library/healthcare-trends.html\\', \\'text\\': \\'The exposure of policy change was recognized overnight by the financial community. November 5 saw immediate gains and losses in every publicly traded healthcare company, with health system valuations swinging as much as ~10% within 24 hours. The likelihood of radical change in healthcare is rising as we begin 2025.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Next in health services: trends and analysis for 2025 - https://www.pwc.com/us/en/industries/health-industries/library/healthcare-trends.html\\', \\'text\\': \\'With greater change at the door requiring transformation and resilience, here are 10 sector dynamics you should watch and act on in 2025. Medical cost trend will continue to rise. Pharmaceutical costs, GLP-1s and other specialty drugs will increase in cost and utilization. The challenge can be daunting: seven out of 10 healthcare consumers say they either can’t afford healthcare and medications now or couldn’t afford to pay more if their costs increase.\\'}, {\\'doc_id\\': 5, \\'source\\': \\'Next in health services: trends and analysis for 2025 - https://www.pwc.com/us/en/industries/health-industries/library/healthcare-trends.html\\', \\'text\\': \\'PwC reported the highest medical cost inflation in 10 years led by rapidly growing GLP-1 market demand and unseen trends and signaled that drug spending is likely to continue to increase. ... The breadth of climate change directly impacted healthcare, with July as the hottest on record globally.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'The 3 megatrends that will shape the future of health | World Economic Forum - https://www.weforum.org/stories/2025/01/the-3-megatrends-that-will-shape-the-future-of-health/\\', \\'text\\': \\'The healthcare landscape is being transformed by three major trends: a rapidly ageing population, increasing urbanization and technological advancements. Technology, particularly artificial intelligence, is revolutionizing healthcare by accelerating drug discovery, enabling precision medicine and driving advancements in treatment.\\'}, {\\'doc_id\\': 6, \\'source\\': \\'The 3 megatrends that will shape the future of health | World Economic Forum -\\n\\nAnswer only with \\'Yes\\' if Ground Truth is NOT present, or \\'No\\' if it IS present.'}]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# معالجة كل الصفوف\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m file_brave3.iterrows():\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     file_brave3.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mcheck_with_phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     time.sleep(\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# لتخفيف الحمل على المودل\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# حفظ النسخة الجديدة\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mcheck_with_phi\u001b[39m\u001b[34m(gt, snip)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(messages)\n\u001b[32m     42\u001b[39m inputs = tokenizer.apply_chat_template(\n\u001b[32m     43\u001b[39m     messages,\n\u001b[32m     44\u001b[39m     add_generation_prompt=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     truncation=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     49\u001b[39m ).to(model.device)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28mprint\u001b[39m(inputs)\n\u001b[32m     52\u001b[39m outputs = model.generate(**inputs, max_new_tokens=\u001b[32m50\u001b[39m , cache_implementation=\u001b[33m\"\u001b[39m\u001b[33mstatic\u001b[39m\u001b[33m\"\u001b[39m )\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\collections\\__init__.py:1143\u001b[39m, in \u001b[36mUserDict.__repr__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1142\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\_tensor.py:590\u001b[39m, in \u001b[36mTensor.__repr__\u001b[39m\u001b[34m(self, tensor_contents)\u001b[39m\n\u001b[32m    586\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    587\u001b[39m         Tensor.\u001b[34m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents=tensor_contents\n\u001b[32m    588\u001b[39m     )\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_tensor_str\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\_tensor_str.py:726\u001b[39m, in \u001b[36m_str\u001b[39m\u001b[34m(self, tensor_contents)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad(), torch.utils._python_dispatch._disable_current_modes():\n\u001b[32m    725\u001b[39m     guard = torch._C._DisableFuncTorch()  \u001b[38;5;66;03m# noqa: F841\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\_tensor_str.py:647\u001b[39m, in \u001b[36m_str_intern\u001b[39m\u001b[34m(inp, tensor_contents)\u001b[39m\n\u001b[32m    645\u001b[39m                     tensor_str = _tensor_str(\u001b[38;5;28mself\u001b[39m.to_dense(), indent)\n\u001b[32m    646\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m                     tensor_str = \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layout != torch.strided:\n\u001b[32m    650\u001b[39m     suffixes.append(\u001b[33m\"\u001b[39m\u001b[33mlayout=\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.layout))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\_tensor_str.py:379\u001b[39m, in \u001b[36m_tensor_str\u001b[39m\u001b[34m(self, indent)\u001b[39m\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[32m    376\u001b[39m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[32m    377\u001b[39m     )\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     formatter = _Formatter(\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m summarize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\_tensor_str.py:417\u001b[39m, in \u001b[36mget_summarized_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    415\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack([get_summarized_data(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (start + end)])\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack(\u001b[43m[\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\_tensor_str.py:417\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    415\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack([get_summarized_data(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (start + end)])\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack([\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\_tensor_str.py:405\u001b[39m, in \u001b[36mget_summarized_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dim == \u001b[32m1\u001b[39m:\n\u001b[32m    404\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.size(\u001b[32m0\u001b[39m) > \u001b[32m2\u001b[39m * PRINT_OPTS.edgeitems:\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPRINT_OPTS\u001b[49m\u001b[43m.\u001b[49m\u001b[43medgeitems\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[43mPRINT_OPTS\u001b[49m\u001b[43m.\u001b[49m\u001b[43medgeitems\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    409\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف الأصلي\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# -------------------------\n",
    "# تهيئة المودل والمُرمّز\n",
    "# -------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")  # تشغيل على CPU\n",
    "\n",
    "MAX_INPUT_TOKENS = 4000  # لتقسيم النصوص الطويلة\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق من need_script\n",
    "# -------------------------\n",
    "def check_with_phi(gt, snip):\n",
    "    snippet_tokens = tokenizer.encode(snip)\n",
    "    parts = [snippet_tokens[i:i+MAX_INPUT_TOKENS] for i in range(0, len(snippet_tokens), MAX_INPUT_TOKENS)]\n",
    "    \n",
    "    for part_tokens in parts:\n",
    "        part_text = tokenizer.decode(part_tokens)\n",
    "        prompt_text = f\"Ground Truth:\\n{gt}\\n\\nSnippet:\\n{part_text}\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"\n",
    "        \n",
    "        try:\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "            print(messages)\n",
    "            inputs = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=True,\n",
    "                return_dict=True,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True\n",
    "            ).to(model.device)\n",
    "            print(inputs)\n",
    "\n",
    "            outputs = model.generate(**inputs, max_new_tokens=50 , cache_implementation=\"static\" )\n",
    "            print(outputs)\n",
    "            answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "            print(answer)\n",
    "            \n",
    "            if \"no\" in answer.lower():  # لو وجد Ground Truth\n",
    "                return \"No\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return \"Yes\"  # افتراضياً محتاج سكربت لو صار خطأ\n",
    "    \n",
    "    return \"Yes\"  # إذا ما وجد Ground Truth في أي جزء\n",
    "\n",
    "# -------------------------\n",
    "# معالجة كل الصفوف\n",
    "# -------------------------\n",
    "for idx, row in file_brave3.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = check_with_phi(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    time.sleep(1)  # لتخفيف الحمل على المودل\n",
    "\n",
    "# -------------------------\n",
    "# حفظ النسخة الجديدة\n",
    "# -------------------------\n",
    "new_file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_phi_checked.xlsx\"\n",
    "file_brave3.to_excel(new_file_path, index=False)\n",
    "print(f\"✅ تم حفظ النسخة الجديدة في: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9dca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (4.56.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: accelerate in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.6 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.6/11.6 MB 8.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.3/11.6 MB 12.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.6 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.6 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 12.1 MB/s  0:00:01\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.56.1\n",
      "    Uninstalling transformers-4.56.1:\n",
      "      Successfully uninstalled transformers-4.56.1\n",
      "Successfully installed transformers-4.56.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8e1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (4.56.2)\n",
      "Requirement already satisfied: torch in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers torch accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16426fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ZipFile.__del__ at 0x0000027B11E9D760>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py\", line 1894, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py\", line 1911, in close\n",
      "    self.fp.seek(self.start_dir)\n",
      "ValueError: seek of closed file\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbb8504d4164a1da33f330f56d82f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m     83\u001b[39m     row = file_brave3.iloc[idx]\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     file_brave3.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mcheck_with_phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mصف \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ✅ = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_brave3.at[idx,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# حفظ نسخة مؤقتة للتجربة\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mcheck_with_phi\u001b[39m\u001b[34m(gt, snip)\u001b[39m\n\u001b[32m     49\u001b[39m inputs = tokenizer.apply_chat_template(\n\u001b[32m     50\u001b[39m     messages,\n\u001b[32m     51\u001b[39m     add_generation_prompt=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m     truncation=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     56\u001b[39m ).to(model.device)\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# مهم لتفادي DynamicCache errors\u001b[39;49;00m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m answer = tokenizer.decode(outputs[\u001b[32m0\u001b[39m][inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[-\u001b[32m1\u001b[39m]:])\n\u001b[32m     66\u001b[39m answer = answer.strip().lower()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2539\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GenerationMixin.generate(\n\u001b[32m   2529\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2530\u001b[39m         inputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2534\u001b[39m         **kwargs,\n\u001b[32m   2535\u001b[39m     )\n\u001b[32m   2537\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.SAMPLE, GenerationMode.GREEDY_SEARCH):\n\u001b[32m   2538\u001b[39m     \u001b[38;5;66;03m# 11. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2539\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2544\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2546\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2547\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2550\u001b[39m     \u001b[38;5;66;03m# 11. run beam sample\u001b[39;00m\n\u001b[32m   2551\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._beam_search(\n\u001b[32m   2552\u001b[39m         input_ids,\n\u001b[32m   2553\u001b[39m         logits_processor=prepared_logits_processor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2557\u001b[39m         **model_kwargs,\n\u001b[32m   2558\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2870\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2868\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2869\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2870\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2872\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   2873\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   2874\u001b[39m     outputs,\n\u001b[32m   2875\u001b[39m     model_kwargs,\n\u001b[32m   2876\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2877\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\0a67737cc96d2554230f90338b163bc6380a2a85\\modeling_phi3.py:1243\u001b[39m, in \u001b[36mPhi3ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1240\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m   1242\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1255\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1256\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.lm_head(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\0a67737cc96d2554230f90338b163bc6380a2a85\\modeling_phi3.py:1121\u001b[39m, in \u001b[36mPhi3Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1111\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m   1112\u001b[39m         decoder_layer.\u001b[34m__call__\u001b[39m,\n\u001b[32m   1113\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m         use_cache,\n\u001b[32m   1119\u001b[39m     )\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1130\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\0a67737cc96d2554230f90338b163bc6380a2a85\\modeling_phi3.py:842\u001b[39m, in \u001b[36mPhi3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m attn_outputs, self_attn_weights, present_key_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    851\u001b[39m hidden_states = residual + \u001b[38;5;28mself\u001b[39m.resid_attn_dropout(attn_outputs)\n\u001b[32m    853\u001b[39m residual = hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\0a67737cc96d2554230f90338b163bc6380a2a85\\modeling_phi3.py:362\u001b[39m, in \u001b[36mPhi3Attention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[39m\n\u001b[32m    359\u001b[39m     attn_weights = attn_weights + attention_mask\n\u001b[32m    361\u001b[39m \u001b[38;5;66;03m# upcast attention to fp32\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m attn_weights = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m.to(value_states.dtype)\n\u001b[32m    363\u001b[39m attn_weights = nn.functional.dropout(attn_weights, p=\u001b[38;5;28mself\u001b[39m.attention_dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m    365\u001b[39m attn_output = torch.matmul(attn_weights, value_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:2139\u001b[39m, in \u001b[36msoftmax\u001b[39m\u001b[34m(input, dim, _stacklevel, dtype)\u001b[39m\n\u001b[32m   2137\u001b[39m     ret = \u001b[38;5;28minput\u001b[39m.softmax(dim)\n\u001b[32m   2138\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2139\u001b[39m     ret = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف الأصلي\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# -------------------------\n",
    "# تهيئة المودل والمُرمّز\n",
    "# -------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق من وجود Ground Truth داخل Snippet\n",
    "# -------------------------\n",
    "def check_with_phi(gt, snip):\n",
    "    prompt_text = f\"\"\"\n",
    "I have a Ground Truth and a Snippet.\n",
    "\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Question: Is the Ground Truth text present inside the Snippet?\n",
    "\n",
    "Answer only with:\n",
    "- \"No\" if the Ground Truth IS present\n",
    "- \"Yes\" if the Ground Truth is NOT present\n",
    "\"\"\"\n",
    "    try:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=20,\n",
    "                use_cache=False  # مهم لتفادي DynamicCache errors\n",
    "            )\n",
    "\n",
    "        answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "        answer = answer.strip().lower()\n",
    "\n",
    "        if \"yes\" in answer:\n",
    "            return \"Yes\"\n",
    "        elif \"no\" in answer:\n",
    "            return \"No\"\n",
    "        else:\n",
    "            return \"Yes\"  # افتراضياً\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"not found\"  # افتراضياً\n",
    "\n",
    "# -------------------------\n",
    "# تجربة على أول 5 صفوف فقط\n",
    "# -------------------------\n",
    "for idx in range(5):\n",
    "    row = file_brave3.iloc[idx]\n",
    "    file_brave3.at[idx, \"need_script\"] = check_with_phi(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    print(f\"صف {idx+1} ✅ = {file_brave3.at[idx, 'need_script']}\")\n",
    "\n",
    "# -------------------------\n",
    "# حفظ نسخة مؤقتة للتجربة\n",
    "# -------------------------\n",
    "test_file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_test5.xlsx\"\n",
    "file_brave3.to_excel(test_file_path, index=False)\n",
    "\n",
    "print(f\"✅ تم تحديث أول 5 صفوف وحفظ الملف: {test_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ee0021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1642d6ae7bc48db8b2a4c3b4bec6327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DynamicCache' object has no attribute 'seen_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# تجربة على أول 5 صفوف\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m file_brave3.head(\u001b[32m5\u001b[39m).iterrows():\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     file_brave3.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mcheck_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mصف \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_brave3.at[idx,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# حفظ نسخة جديدة\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mcheck_with_llm\u001b[39m\u001b[34m(gt, snip)\u001b[39m\n\u001b[32m     39\u001b[39m inputs = tokenizer(prompt, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m).to(model.device)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_NEW_TOKENS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m answer = tokenizer.decode(outputs[\u001b[32m0\u001b[39m][inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[-\u001b[32m1\u001b[39m]:])\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# التأكد من الحرف الأول فقط\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2539\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GenerationMixin.generate(\n\u001b[32m   2529\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2530\u001b[39m         inputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2534\u001b[39m         **kwargs,\n\u001b[32m   2535\u001b[39m     )\n\u001b[32m   2537\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.SAMPLE, GenerationMode.GREEDY_SEARCH):\n\u001b[32m   2538\u001b[39m     \u001b[38;5;66;03m# 11. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2539\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2544\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2546\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2547\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2550\u001b[39m     \u001b[38;5;66;03m# 11. run beam sample\u001b[39;00m\n\u001b[32m   2551\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._beam_search(\n\u001b[32m   2552\u001b[39m         input_ids,\n\u001b[32m   2553\u001b[39m         logits_processor=prepared_logits_processor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2557\u001b[39m         **model_kwargs,\n\u001b[32m   2558\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2860\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2856\u001b[39m     is_prefill = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2858\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):\n\u001b[32m   2859\u001b[39m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2860\u001b[39m     model_inputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_inputs_for_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2862\u001b[39m     \u001b[38;5;66;03m# prepare variable output controls (note: some models won't accept all output controls)\u001b[39;00m\n\u001b[32m   2863\u001b[39m     model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_attentions\u001b[39m\u001b[33m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\0a67737cc96d2554230f90338b163bc6380a2a85\\modeling_phi3.py:1291\u001b[39m, in \u001b[36mPhi3ForCausalLM.prepare_inputs_for_generation\u001b[39m\u001b[34m(self, input_ids, past_key_values, attention_mask, inputs_embeds, **kwargs)\u001b[39m\n\u001b[32m   1289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(past_key_values, Cache):\n\u001b[32m   1290\u001b[39m     cache_length = past_key_values.get_seq_length()\n\u001b[32m-> \u001b[39m\u001b[32m1291\u001b[39m     past_length = \u001b[43mpast_key_values\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseen_tokens\u001b[49m\n\u001b[32m   1292\u001b[39m     max_cache_length = past_key_values.get_max_length()\n\u001b[32m   1293\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'DynamicCache' object has no attribute 'seen_tokens'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "\n",
    "# -------------------------\n",
    "# تهيئة المودل\n",
    "# -------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"  # أو أي LLM متاح عندك\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")  # أو \"cuda\" لو عندك GPU\n",
    "model.eval()\n",
    "\n",
    "MAX_NEW_TOKENS = 50\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق باستخدام LLM\n",
    "# -------------------------\n",
    "def check_with_llm(gt, snip):\n",
    "    prompt = f\"\"\"\n",
    "Ground Truth:\n",
    "{gt}\n",
    "\n",
    "Snippet:\n",
    "{snip}\n",
    "\n",
    "Answer only with \"Yes\" if the Ground Truth is NOT present in the Snippet, or \"No\" if it IS present.\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=MAX_NEW_TOKENS)\n",
    "    answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "    \n",
    "    # التأكد من الحرف الأول فقط\n",
    "    if \"yes\" in answer.lower():\n",
    "        return \"Yes\"\n",
    "    else:\n",
    "        return \"No\"\n",
    "\n",
    "# -------------------------\n",
    "# تجربة على أول 5 صفوف\n",
    "# -------------------------\n",
    "for idx, row in file_brave3.head(5).iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = check_with_llm(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    print(f\"صف {idx+1} ✅ {file_brave3.at[idx, 'need_script']}\")\n",
    "\n",
    "# -------------------------\n",
    "# حفظ نسخة جديدة\n",
    "# -------------------------\n",
    "output_file = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script_llm.xlsx\"\n",
    "file_brave3.to_excel(output_file, index=False)\n",
    "print(f\"✅ تم الحفظ في: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32cfdb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (4.56.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (0.34.4)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.35.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarahalqahtani\\documents\\.venv\\lib\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n",
      "   ---------------------------------------- 0.0/563.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/563.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 563.3/563.3 kB 2.1 MB/s  0:00:00\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.34.4\n",
      "    Uninstalling huggingface-hub-0.34.4:\n",
      "      Successfully uninstalled huggingface-hub-0.34.4\n",
      "Successfully installed huggingface_hub-0.35.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a86959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn\n",
      "  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n",
      "     ---------------------------------------- 0.0/8.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/8.4 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 1.0/8.4 MB 5.6 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 3.9/8.4 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 8.1/8.4 MB 13.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 8.4/8.4 MB 12.8 MB/s  0:00:00\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\SarahAlqahtani\\\\AppData\\\\Local\\\\Temp\\\\pip-install-tzj6xgd6\\\\flash-attn_9459ca4817e14d02b95bec0893615858\\\\csrc\\\\composable_kernel\\\\client_example\\\\24_grouped_conv_activation\\\\grouped_convnd_fwd_scaleadd_scaleadd_relu\\\\grouped_conv_fwd_scaleadd_scaleadd_relu_bf16.cpp'\n",
      "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install flash-attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "250c942c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c9a99ecb564ea385720c8dc26d9e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m     38\u001b[39m     row = file_brave3.iloc[idx]\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     file_brave3.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mcheck_with_phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m done: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_brave3.at[idx,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m     time.sleep(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mcheck_with_phi\u001b[39m\u001b[34m(gt, snip)\u001b[39m\n\u001b[32m     21\u001b[39m inputs = tokenizer.apply_chat_template(\n\u001b[32m     22\u001b[39m     messages,\n\u001b[32m     23\u001b[39m     add_generation_prompt=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     truncation=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     28\u001b[39m ).to(model.device)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m answer = tokenizer.decode(outputs[\u001b[32m0\u001b[39m][inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[-\u001b[32m1\u001b[39m]:])\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mYes\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33myes\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m answer.lower() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNo\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2539\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GenerationMixin.generate(\n\u001b[32m   2529\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2530\u001b[39m         inputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2534\u001b[39m         **kwargs,\n\u001b[32m   2535\u001b[39m     )\n\u001b[32m   2537\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.SAMPLE, GenerationMode.GREEDY_SEARCH):\n\u001b[32m   2538\u001b[39m     \u001b[38;5;66;03m# 11. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2539\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2544\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2546\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2547\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2550\u001b[39m     \u001b[38;5;66;03m# 11. run beam sample\u001b[39;00m\n\u001b[32m   2551\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._beam_search(\n\u001b[32m   2552\u001b[39m         input_ids,\n\u001b[32m   2553\u001b[39m         logits_processor=prepared_logits_processor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2557\u001b[39m         **model_kwargs,\n\u001b[32m   2558\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2867\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2864\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   2866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m2867\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2868\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2869\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\0a67737cc96d2554230f90338b163bc6380a2a85\\modeling_phi3.py:1243\u001b[39m, in \u001b[36mPhi3ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1240\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m   1242\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1255\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1256\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.lm_head(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\0a67737cc96d2554230f90338b163bc6380a2a85\\modeling_phi3.py:1121\u001b[39m, in \u001b[36mPhi3Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1111\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m   1112\u001b[39m         decoder_layer.\u001b[34m__call__\u001b[39m,\n\u001b[32m   1113\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m         use_cache,\n\u001b[32m   1119\u001b[39m     )\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1130\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\0a67737cc96d2554230f90338b163bc6380a2a85\\modeling_phi3.py:842\u001b[39m, in \u001b[36mPhi3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m attn_outputs, self_attn_weights, present_key_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    851\u001b[39m hidden_states = residual + \u001b[38;5;28mself\u001b[39m.resid_attn_dropout(attn_outputs)\n\u001b[32m    853\u001b[39m residual = hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\0a67737cc96d2554230f90338b163bc6380a2a85\\modeling_phi3.py:346\u001b[39m, in \u001b[36mPhi3Attention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[39m\n\u001b[32m    343\u001b[39m key_states = repeat_kv(key_states, \u001b[38;5;28mself\u001b[39m.num_key_value_groups)\n\u001b[32m    344\u001b[39m value_states = repeat_kv(value_states, \u001b[38;5;28mself\u001b[39m.num_key_value_groups)\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m attn_weights = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m / math.sqrt(\u001b[38;5;28mself\u001b[39m.head_dim)\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attn_weights.size() != (bsz, \u001b[38;5;28mself\u001b[39m.num_heads, q_len, kv_seq_len):\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    350\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttention weights should be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(bsz,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m.num_heads,\u001b[38;5;250m \u001b[39mq_len,\u001b[38;5;250m \u001b[39mkv_seq_len)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but is\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    351\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_weights.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    352\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "def check_with_phi(gt, snip):\n",
    "    prompt_text = f\"Ground Truth:\\n{gt}\\n\\nSnippet:\\n{snip}\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=50 , use_cache=False)\n",
    "\n",
    "    answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "    return \"Yes\" if \"yes\" in answer.lower() else \"No\"\n",
    "\n",
    "# تجربة أول 5 صفوف فقط\n",
    "for idx in range(5):\n",
    "    row = file_brave3.iloc[idx]\n",
    "    file_brave3.at[idx, \"need_script\"] = check_with_phi(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done: {file_brave3.at[idx, 'need_script']}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "file_brave3.to_excel(r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_test.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744dc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd70dc3e4a854500bc88e02cd1796f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6047 > 4096). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n",
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n",
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n",
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n",
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n",
      "Error: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument 'attention_mask'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m file_brave3.iterrows():\n\u001b[32m     72\u001b[39m     file_brave3.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = check_with_phi_split(row[\u001b[33m\"\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m\"\u001b[39m], row[\u001b[33m\"\u001b[39m\u001b[33mbrave_sinp\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# لتخفيف الحمل على المودل\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# حفظ نسخة جديدة من الملف\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     78\u001b[39m new_file_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSarahAlqahtani\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbrave_sec_t2_with_need_script_v5.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# تحميل الملف الأصلي\n",
    "# -------------------------\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "file_brave3 = pd.read_excel(file_path)\n",
    "\n",
    "# التأكد من وجود العمود need_script\n",
    "if \"need_script\" not in file_brave3.columns:\n",
    "    file_brave3[\"need_script\"] = None\n",
    "else:\n",
    "    file_brave3[\"need_script\"] = file_brave3[\"need_script\"].astype(\"object\")\n",
    "\n",
    "# -------------------------\n",
    "# تهيئة المودل والمُرمّز\n",
    "# -------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.to(\"cpu\")  # تشغيل على CPU\n",
    "\n",
    "MAX_INPUT_TOKENS = 4000  # أقصى طول لكل جزء\n",
    "\n",
    "# -------------------------\n",
    "# دالة للتحقق من need_script مع تقسيم النصوص الطويلة\n",
    "# -------------------------\n",
    "def check_with_phi_split(gt, snip):\n",
    "    try:\n",
    "        # ترميز النص\n",
    "        snippet_tokens = tokenizer.encode(snip, add_special_tokens=False)\n",
    "        # تقسيم النص إلى أجزاء\n",
    "        parts = [snippet_tokens[i:i+MAX_INPUT_TOKENS] for i in range(0, len(snippet_tokens), MAX_INPUT_TOKENS)]\n",
    "\n",
    "        # لكل جزء\n",
    "        for part_tokens in parts:\n",
    "            prompt_text = f\"Ground Truth:\\n{gt}\\n\\nSnippet:\\n{tokenizer.decode(part_tokens)}\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "\n",
    "            # تحويل النص إلى مدخلات المودل\n",
    "            inputs = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=True,\n",
    "                return_dict=True,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True\n",
    "            ).to(model.device)\n",
    "\n",
    "            # توليد الإجابة\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=50,\n",
    "                attention_mask=inputs[\"attention_mask\"]  # تجنب مشاكل DynamicCache\n",
    "            )\n",
    "\n",
    "            answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "            if \"yes\" in answer.lower():\n",
    "                return \"Yes\"\n",
    "        return \"No\"  # إذا لم تعد أي قطعة بحاجة للسكربت\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"  # افتراضياً محتاج سكربت لو حدث خطأ\n",
    "\n",
    "# -------------------------\n",
    "# معالجة كل الصفوف\n",
    "# -------------------------\n",
    "for idx, row in file_brave3.iterrows():\n",
    "    file_brave3.at[idx, \"need_script\"] = check_with_phi_split(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    time.sleep(1)  # لتخفيف الحمل على المودل\n",
    "\n",
    "# -------------------------\n",
    "# حفظ نسخة جديدة من الملف\n",
    "# -------------------------\n",
    "new_file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_v5.xlsx\"\n",
    "file_brave3.to_excel(new_file_path, index=False)\n",
    "print(f\"✅ تم تحديث need_script لجميع الصفوف وحفظ نسخة جديدة في:\\n{new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e260c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_with_phi_split(gt, snip):\n",
    "    try:\n",
    "        snippet_tokens = tokenizer.encode(snip, add_special_tokens=False)\n",
    "        parts = [snippet_tokens[i:i+MAX_INPUT_TOKENS] for i in range(0, len(snippet_tokens), MAX_INPUT_TOKENS)]\n",
    "\n",
    "        for part_tokens in parts:\n",
    "            prompt_text = f\"Ground Truth:\\n{gt}\\n\\nSnippet:\\n{tokenizer.decode(part_tokens)}\\n\\nAnswer only with 'Yes' if Ground Truth is NOT present, or 'No' if it IS present.\"\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "\n",
    "            inputs = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=True,\n",
    "                return_dict=True,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True\n",
    "            ).to(model.device)\n",
    "\n",
    "            # هنا نتأكد أننا لا نمرر attention_mask مرتين\n",
    "            outputs = model.generate(\n",
    "                **{k:v for k,v in inputs.items() if k != \"attention_mask\"},\n",
    "                max_new_tokens=50\n",
    "            )\n",
    "\n",
    "            answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "            if \"yes\" in answer.lower():\n",
    "                return \"Yes\"\n",
    "        return \"No\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Yes\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Row 1/240 processed: Yes\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Row 2/240 processed: Yes\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Row 3/240 processed: Yes\n",
      "Error: 'DynamicCache' object has no attribute 'seen_tokens'\n",
      "Row 4/240 processed: Yes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m     file_brave3.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = result\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(file_brave3)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m processed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# لتخفيف الحمل على المودل\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# حفظ الملف باسم جديد\u001b[39;00m\n\u001b[32m      8\u001b[39m new_file_path = file_path.replace(\u001b[33m\"\u001b[39m\u001b[33m.xlsx\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_with_need_script_v2.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for idx, row in file_brave3.iterrows():\n",
    "    result = check_with_phi_split(row[\"ground_truth\"], row[\"brave_sinp\"])\n",
    "    file_brave3.at[idx, \"need_script\"] = result\n",
    "    print(f\"Row {idx+1}/{len(file_brave3)} processed: {result}\")\n",
    "    time.sleep(1)  # لتخفيف الحمل على المودل\n",
    "\n",
    "# حفظ الملف باسم جديد\n",
    "new_file_path = file_path.replace(\".xlsx\", \"_with_need_script_v2.xlsx\")\n",
    "file_brave3.to_excel(new_file_path, index=False)\n",
    "print(f\"✅ تم حفظ الملف الجديد: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "affad20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing rows 1 to 10...\n",
      "✅ Row 1 done → No\n",
      "✅ Row 2 done → No\n",
      "✅ Row 3 done → No\n",
      "✅ Row 4 done → No\n",
      "✅ Row 5 done → No\n",
      "✅ Row 6 done → No\n",
      "✅ Row 7 done → No\n",
      "✅ Row 8 done → No\n",
      "✅ Row 9 done → No\n",
      "✅ Row 10 done → No\n",
      " Processing rows 11 to 20...\n",
      "✅ Row 11 done → No\n",
      "✅ Row 12 done → No\n",
      "✅ Row 13 done → Yes\n",
      "✅ Row 14 done → No\n",
      "✅ Row 15 done → No\n",
      "✅ Row 16 done → No\n",
      "✅ Row 17 done → No\n",
      "✅ Row 18 done → No\n",
      "✅ Row 19 done → No\n",
      "✅ Row 20 done → No\n",
      " Processing rows 21 to 30...\n",
      "✅ Row 21 done → Yes\n",
      "✅ Row 22 done → No\n",
      "✅ Row 23 done → No\n",
      "✅ Row 24 done → No\n",
      "✅ Row 25 done → No\n",
      "✅ Row 26 done → No\n",
      "✅ Row 27 done → No\n",
      "✅ Row 28 done → No\n",
      "✅ Row 29 done → No\n",
      "✅ Row 30 done → No\n",
      " Processing rows 31 to 40...\n",
      "✅ Row 31 done → No\n",
      "✅ Row 32 done → No\n",
      "✅ Row 33 done → Yes\n",
      "✅ Row 34 done → No\n",
      "✅ Row 35 done → No\n",
      "✅ Row 36 done → No\n",
      "✅ Row 37 done → Yes\n",
      "✅ Row 38 done → No\n",
      "✅ Row 39 done → No\n",
      "✅ Row 40 done → No\n",
      " Processing rows 41 to 50...\n",
      "✅ Row 41 done → Yes\n",
      "✅ Row 42 done → No\n",
      "✅ Row 43 done → No\n",
      "✅ Row 44 done → No\n",
      "✅ Row 45 done → No\n",
      "✅ Row 46 done → No\n",
      "✅ Row 47 done → No\n",
      "✅ Row 48 done → Yes\n",
      "✅ Row 49 done → No\n",
      "✅ Row 50 done → No\n",
      " Processing rows 51 to 60...\n",
      "✅ Row 51 done → No\n",
      "✅ Row 52 done → No\n",
      "✅ Row 53 done → Yes\n",
      "✅ Row 54 done → No\n",
      "✅ Row 55 done → No\n",
      "✅ Row 56 done → Yes\n",
      "✅ Row 57 done → No\n",
      "✅ Row 58 done → No\n",
      "✅ Row 59 done → No\n",
      "✅ Row 60 done → No\n",
      " Processing rows 61 to 70...\n",
      "✅ Row 61 done → No\n",
      "✅ Row 62 done → No\n",
      "✅ Row 63 done → No\n",
      "✅ Row 64 done → No\n",
      "✅ Row 65 done → No\n",
      "✅ Row 66 done → No\n",
      "✅ Row 67 done → No\n",
      "✅ Row 68 done → Yes\n",
      "✅ Row 69 done → No\n",
      "✅ Row 70 done → No\n",
      " Processing rows 71 to 80...\n",
      "✅ Row 71 done → No\n",
      "✅ Row 72 done → No\n",
      "✅ Row 73 done → No\n",
      "✅ Row 74 done → No\n",
      "✅ Row 75 done → No\n",
      "✅ Row 76 done → No\n",
      "✅ Row 77 done → No\n",
      "✅ Row 78 done → No\n",
      "✅ Row 79 done → No\n",
      "✅ Row 80 done → Yes\n",
      " Processing rows 81 to 90...\n",
      "✅ Row 81 done → No\n",
      "✅ Row 82 done → No\n",
      "✅ Row 83 done → No\n",
      "✅ Row 84 done → No\n",
      "✅ Row 85 done → No\n",
      "✅ Row 86 done → No\n",
      "✅ Row 87 done → No\n",
      "✅ Row 88 done → Yes\n",
      "✅ Row 89 done → No\n",
      "✅ Row 90 done → Yes\n",
      " Processing rows 91 to 100...\n",
      "✅ Row 91 done → No\n",
      "✅ Row 92 done → No\n",
      "✅ Row 93 done → No\n",
      "✅ Row 94 done → No\n",
      "✅ Row 95 done → Yes\n",
      "✅ Row 96 done → No\n",
      "✅ Row 97 done → Yes\n",
      "✅ Row 98 done → No\n",
      "✅ Row 99 done → No\n",
      "✅ Row 100 done → Yes\n",
      " Processing rows 101 to 110...\n",
      "✅ Row 101 done → No\n",
      "✅ Row 102 done → No\n",
      "✅ Row 103 done → No\n",
      "✅ Row 104 done → No\n",
      "✅ Row 105 done → No\n",
      "✅ Row 106 done → No\n",
      "✅ Row 107 done → No\n",
      "✅ Row 108 done → No\n",
      "✅ Row 109 done → No\n",
      "✅ Row 110 done → No\n",
      " Processing rows 111 to 120...\n",
      "✅ Row 111 done → No\n",
      "✅ Row 112 done → No\n",
      "✅ Row 113 done → No\n",
      "✅ Row 114 done → No\n",
      "✅ Row 115 done → No\n",
      "✅ Row 116 done → No\n",
      "✅ Row 117 done → No\n",
      "✅ Row 118 done → Yes\n",
      "✅ Row 119 done → No\n",
      "✅ Row 120 done → No\n",
      " Processing rows 121 to 130...\n",
      "✅ Row 121 done → Yes\n",
      "✅ Row 122 done → No\n",
      "✅ Row 123 done → No\n",
      "✅ Row 124 done → No\n",
      "✅ Row 125 done → No\n",
      "✅ Row 126 done → No\n",
      "✅ Row 127 done → No\n",
      "✅ Row 128 done → Yes\n",
      "✅ Row 129 done → No\n",
      "✅ Row 130 done → No\n",
      " Processing rows 131 to 140...\n",
      "✅ Row 131 done → No\n",
      "✅ Row 132 done → No\n",
      "✅ Row 133 done → No\n",
      "✅ Row 134 done → No\n",
      "✅ Row 135 done → No\n",
      "✅ Row 136 done → No\n",
      "✅ Row 137 done → No\n",
      "✅ Row 138 done → No\n",
      "✅ Row 139 done → No\n",
      "✅ Row 140 done → No\n",
      " Processing rows 141 to 150...\n",
      "✅ Row 141 done → Yes\n",
      "✅ Row 142 done → No\n",
      "✅ Row 143 done → No\n",
      "✅ Row 144 done → No\n",
      "✅ Row 145 done → No\n",
      "✅ Row 146 done → No\n",
      "✅ Row 147 done → No\n",
      "✅ Row 148 done → No\n",
      "✅ Row 149 done → Yes\n",
      "✅ Row 150 done → No\n",
      " Processing rows 151 to 160...\n",
      "✅ Row 151 done → No\n",
      "✅ Row 152 done → No\n",
      "✅ Row 153 done → No\n",
      "✅ Row 154 done → No\n",
      "✅ Row 155 done → No\n",
      "✅ Row 156 done → No\n",
      "✅ Row 157 done → No\n",
      "✅ Row 158 done → No\n",
      "✅ Row 159 done → No\n",
      "✅ Row 160 done → No\n",
      " Processing rows 161 to 170...\n",
      "✅ Row 161 done → No\n",
      "✅ Row 162 done → No\n",
      "✅ Row 163 done → No\n",
      "✅ Row 164 done → No\n",
      "✅ Row 165 done → No\n",
      "✅ Row 166 done → No\n",
      "✅ Row 167 done → No\n",
      "✅ Row 168 done → No\n",
      "✅ Row 169 done → No\n",
      "✅ Row 170 done → No\n",
      " Processing rows 171 to 180...\n",
      "✅ Row 171 done → No\n",
      "✅ Row 172 done → No\n",
      "✅ Row 173 done → No\n",
      "✅ Row 174 done → No\n",
      "✅ Row 175 done → No\n",
      "✅ Row 176 done → No\n",
      "✅ Row 177 done → Yes\n",
      "✅ Row 178 done → No\n",
      "✅ Row 179 done → No\n",
      "✅ Row 180 done → No\n",
      " Processing rows 181 to 190...\n",
      "✅ Row 181 done → No\n",
      "✅ Row 182 done → Yes\n",
      "✅ Row 183 done → No\n",
      "✅ Row 184 done → No\n",
      "✅ Row 185 done → No\n",
      "✅ Row 186 done → No\n",
      "✅ Row 187 done → No\n",
      "✅ Row 188 done → No\n",
      "✅ Row 189 done → No\n",
      "✅ Row 190 done → No\n",
      " Processing rows 191 to 200...\n",
      "✅ Row 191 done → No\n",
      "✅ Row 192 done → No\n",
      "✅ Row 193 done → No\n",
      "✅ Row 194 done → No\n",
      "✅ Row 195 done → No\n",
      "✅ Row 196 done → No\n",
      "✅ Row 197 done → No\n",
      "✅ Row 198 done → No\n",
      "✅ Row 199 done → No\n",
      "✅ Row 200 done → No\n",
      " Processing rows 201 to 210...\n",
      "✅ Row 201 done → No\n",
      "✅ Row 202 done → No\n",
      "✅ Row 203 done → No\n",
      "✅ Row 204 done → No\n",
      "✅ Row 205 done → No\n",
      "✅ Row 206 done → No\n",
      "✅ Row 207 done → No\n",
      "✅ Row 208 done → No\n",
      "✅ Row 209 done → No\n",
      "✅ Row 210 done → No\n",
      " Processing rows 211 to 220...\n",
      "✅ Row 211 done → No\n",
      "✅ Row 212 done → No\n",
      "✅ Row 213 done → No\n",
      "✅ Row 214 done → No\n",
      "✅ Row 215 done → No\n",
      "✅ Row 216 done → No\n",
      "✅ Row 217 done → No\n",
      "✅ Row 218 done → No\n",
      "✅ Row 219 done → No\n",
      "✅ Row 220 done → Yes\n",
      " Processing rows 221 to 230...\n",
      "✅ Row 221 done → No\n",
      "✅ Row 222 done → No\n",
      "✅ Row 223 done → No\n",
      "✅ Row 224 done → No\n",
      "✅ Row 225 done → No\n",
      "✅ Row 226 done → No\n",
      "✅ Row 227 done → No\n",
      "✅ Row 228 done → No\n",
      "✅ Row 229 done → No\n",
      "✅ Row 230 done → No\n",
      " Processing rows 231 to 240...\n",
      "✅ Row 231 done → No\n",
      "✅ Row 232 done → No\n",
      "✅ Row 233 done → No\n",
      "✅ Row 234 done → No\n",
      "✅ Row 235 done → No\n",
      "✅ Row 236 done → No\n",
      "✅ Row 237 done → No\n",
      "✅ Row 238 done → No\n",
      "✅ Row 239 done → No\n",
      "✅ Row 240 done → No\n",
      "✅ Done! الملف محفوظ في: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_test.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 2. تحميل LLM من Hugging Face (مودل خفيف وبسيط)\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "# 3. دالة لتقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# 4. دالة تفحص ground_truth في كل chunk\n",
    "def check_with_llm(ground_truth, snippet):\n",
    "    chunks = chunk_text(snippet)  # تقسيم النص الطويل إلى أجزاء صغيرة\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"\n",
    "        You are a judge. Ground truth: \"{ground_truth}\".\n",
    "        Snippet: \"{chunk}\".\n",
    "        Question: Is the ground truth information present in the snippet? \n",
    "        Answer only with Yes or No.\n",
    "        \"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"yes\" in result.lower():\n",
    "            return \"No\"  # موجود → ما يحتاج سكربت\n",
    "    return \"Yes\"  # غير موجود → يحتاج سكربت\n",
    "\n",
    "\n",
    "# 5. تجربة على أول 5 صفوف فقط\n",
    "#for idx in range(min(5, len(df))):\n",
    "  #  df.at[idx, \"need_script\"] = check_with_llm(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "  #  print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# 5. تجربة على دفعات 10 صفوف\n",
    "batch_size = 10\n",
    "for start_idx in range(0, len(df), batch_size):\n",
    "    end_idx = min(start_idx + batch_size, len(df))\n",
    "    print(f\" Processing rows {start_idx+1} to {end_idx}...\")\n",
    "    for idx in range(start_idx, end_idx):\n",
    "        df.at[idx, \"need_script\"] = check_with_llm(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "        print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# 6. حفظ نسخة تجريبية\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_test.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"✅ Done! الملف محفوظ في:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acfc6b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row 1 done → Yes\n",
      "✅ Row 2 done → Yes\n",
      "✅ Row 3 done → Yes\n",
      "✅ Row 4 done → Yes\n",
      "✅ Row 5 done → Yes\n",
      "✅ Row 6 done → Yes\n",
      "✅ Row 7 done → Yes\n",
      "✅ Row 8 done → Yes\n",
      "✅ Row 9 done → Yes\n",
      "✅ Row 10 done → Yes\n",
      "✅ Done! أول 10 صفوف تم تعديلها وحفظ الملف: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_first10_fixed.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 2. دالة لتقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = str(text).split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# 3. دالة للتحقق من المطابقة الدقيقة\n",
    "def check_with_llm(ground_truth, snippet):\n",
    "    chunks = chunk_text(snippet)\n",
    "    for chunk in chunks:\n",
    "        # إذا ground_truth موجود داخل chunk → لا يحتاج سكربت\n",
    "        if str(ground_truth).strip() in str(chunk):\n",
    "            return \"No\"  # موجود → لا يحتاج سكربت\n",
    "    return \"Yes\"  # غير موجود → يحتاج سكربت\n",
    "\n",
    "\n",
    "# 4. إعادة معالجة أول 10 صفوف (استبدال أي قيم خاطئة في need_script)\n",
    "for idx in range(min(10, len(df))):\n",
    "    df.at[idx, \"need_script\"] = check_with_llm(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# 5. حفظ الملف النهائي بعد التعديل\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_first10_fixed.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"✅ Done! أول 10 صفوف تم تعديلها وحفظ الملف:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b55c2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row 1 done → Yes\n",
      "✅ Row 2 done → Yes\n",
      "✅ Row 3 done → Yes\n",
      "✅ Row 4 done → Yes\n",
      "✅ Row 5 done → Yes\n",
      "✅ Row 6 done → Yes\n",
      "✅ Row 7 done → Yes\n",
      "✅ Row 8 done → Yes\n",
      "✅ Row 9 done → Yes\n",
      "✅ Row 10 done → Yes\n",
      "✅ Done! أول 10 صفوف تم تعديلها وحفظ الملف: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_first10_fixed_t2.xlsx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import re  # لإزالة علامات الترقيم\n",
    "\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 2. دالة للتحقق من المطابقة الدقيقة مع تحسين البحث\n",
    "def check_with_llm(ground_truth, snippet):\n",
    "    # تحويل كل شيء إلى نصوص صغيرة وحذف الفراغات الزائدة\n",
    "    gt = str(ground_truth).strip().lower()\n",
    "    snip = str(snippet).strip().lower()\n",
    "    \n",
    "    # إزالة علامات الترقيم\n",
    "    gt = re.sub(r'[^\\w\\s]', '', gt)\n",
    "    snip = re.sub(r'[^\\w\\s]', '', snip)\n",
    "    \n",
    "    # البحث عن وجود ground_truth داخل snippet\n",
    "    if gt in snip:\n",
    "        return \"No\"  # موجود → لا يحتاج سكربت\n",
    "    else:\n",
    "        return \"Yes\"  # غير موجود → يحتاج سكربت\n",
    "\n",
    "# 3. معالجة أول 10 صفوف فقط\n",
    "for idx in range(min(10, len(df))):\n",
    "    df.at[idx, \"need_script\"] = check_with_llm(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# 4. حفظ الملف النهائي\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_first10_fixed_t2.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"✅ Done! أول 10 صفوف تم تعديلها وحفظ الملف:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45266059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row 1 done → No\n",
      "✅ Row 2 done → No\n",
      "✅ Row 3 done → No\n",
      "✅ Row 4 done → No\n",
      "✅ Row 5 done → No\n",
      "✅ Row 6 done → No\n",
      "✅ Row 7 done → No\n",
      "✅ Row 8 done → No\n",
      "✅ Row 9 done → No\n",
      "✅ Row 10 done → No\n",
      "✅ Done! أول 10 صفوف تمت معالجتها وحفظ الملف: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_first10_snippet_ref.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 2. تحميل LLM من Hugging Face\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "# 3. دالة لتقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = str(text).split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# 4. دالة للتحقق من مدى مطابقة ground_truth للـ snippet\n",
    "def check_with_llm(ground_truth, snippet):\n",
    "    chunks = chunk_text(snippet)\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"\n",
    "        You are a judge. Snippet (correct answer): \"{chunk}\".\n",
    "        Ground truth answer: \"{ground_truth}\".\n",
    "        Question: Is the ground truth exactly the same or very similar to the snippet? \n",
    "        Answer only with Yes if it is correct/similar, or No if it is wrong/different.\n",
    "        \"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=30, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"yes\" in result.lower():  # إذا ground_truth مطابق أو مشابه للـ snippet\n",
    "            return \"No\"  # لا يحتاج سكربت\n",
    "    return \"Yes\"  # غير مطابق → يحتاج سكربت\n",
    "\n",
    "# 5. معالجة أول 10 صفوف\n",
    "for idx in range(min(10, len(df))):\n",
    "    df.at[idx, \"need_script\"] = check_with_llm(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# 6. حفظ الملف النهائي\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_first10_snippet_ref.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"✅ Done! أول 10 صفوف تمت معالجتها وحفظ الملف:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e137b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588f52ac1fd64c519494ac754a3f90f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\SarahAlqahtani\\.cache\\huggingface\\hub\\models--google--flan-t5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ed8545474041909f84ff5cac2c755a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f634f3186e4456be19b9c087a48d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2114771279b4d328de7b762e0a51d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c418632f634f989766737cb122e92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a428457e40f452eb62655be131c71a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63aee6ac630c4342a41ba5d3f2fadf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row 1 done → No\n",
      "✅ Row 2 done → No\n",
      "✅ Row 3 done → No\n",
      "✅ Row 4 done → No\n",
      "✅ Row 5 done → No\n",
      "✅ Row 6 done → Yes\n",
      "✅ Row 7 done → No\n",
      "✅ Row 8 done → No\n",
      "✅ Row 9 done → No\n",
      "✅ Row 10 done → No\n",
      "✅ Done! أول 10 صفوف تمت معالجتها وحفظ الملف: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_first10_large.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 2. تحميل موديل Flan-T5-Large\n",
    "model_name = \"google/flan-t5-large\"\n",
    "qa_model = pipeline(\"text2text-generation\", model=model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 3. دالة لتقسيم النصوص على التوكنز\n",
    "def chunk_text_by_tokens(text, max_tokens=500):\n",
    "    words = str(text).split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_len = 0\n",
    "\n",
    "    for word in words:\n",
    "        token_len = len(tokenizer.encode(word, add_special_tokens=False))\n",
    "        if current_len + token_len > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_len = token_len\n",
    "        else:\n",
    "            current_chunk.append(word)\n",
    "            current_len += token_len\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# 4. دالة للتحقق من التشابه بين ground_truth و snippet\n",
    "def check_need_script(ground_truth, snippet):\n",
    "    chunks = chunk_text_by_tokens(snippet, max_tokens=500)\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"\n",
    "        You are a judge. Snippet (correct answer): \"{chunk}\".\n",
    "        Ground truth answer: \"{ground_truth}\".\n",
    "        Question: Is the ground truth exactly the same or very similar to the snippet? \n",
    "        Answer only with Yes if it is correct/similar, or No if it is wrong/different.\n",
    "        \"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=30, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"yes\" in result.lower():  # مشابه أو مطابق\n",
    "            return \"No\"  # لا يحتاج سكربت\n",
    "    return \"Yes\"  # مختلف → يحتاج سكربت\n",
    "\n",
    "# 5. معالجة أول 10 صفوف\n",
    "for idx in range(min(10, len(df))):\n",
    "    df.at[idx, \"need_script\"] = check_need_script(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# 6. حفظ الملف النهائي\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_need_script_first10_large.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"✅ Done! أول 10 صفوف تمت معالجتها وحفظ الملف:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "715a5a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row 1 done → No\n",
      "✅ Row 2 done → No\n",
      "✅ Row 3 done → No\n",
      "✅ Row 4 done → No\n",
      "✅ Row 5 done → No\n",
      "✅ Row 6 done → Yes\n",
      "✅ Row 7 done → No\n",
      "✅ Row 8 done → No\n",
      "✅ Row 9 done → No\n",
      "✅ Row 10 done → No\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\SARAHA~1\\\\AppData\\\\Local\\\\Temp\\\\openpyxl.g7pjo8ej'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# 6. حفظ الملف النهائي\u001b[39;00m\n\u001b[32m     56\u001b[39m output_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSarahAlqahtani\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbrave_need_script_first10_large_c2.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Done! أول 10 صفوف تمت معالجتها وحفظ الملف:\u001b[39m\u001b[33m\"\u001b[39m, output_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:2436\u001b[39m, in \u001b[36mNDFrame.to_excel\u001b[39m\u001b[34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   2423\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexcel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[32m   2425\u001b[39m formatter = ExcelFormatter(\n\u001b[32m   2426\u001b[39m     df,\n\u001b[32m   2427\u001b[39m     na_rep=na_rep,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2434\u001b[39m     inf_rep=inf_rep,\n\u001b[32m   2435\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2445\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:962\u001b[39m, in \u001b[36mExcelFormatter.write\u001b[39m\u001b[34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    960\u001b[39m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[32m    961\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m need_save:\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m         \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1357\u001b[39m, in \u001b[36mExcelWriter.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1355\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1356\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"synonym for save, to make it more file-like\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1357\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1358\u001b[39m     \u001b[38;5;28mself\u001b[39m._handles.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:110\u001b[39m, in \u001b[36mOpenpyxlWriter._save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_save\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    107\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m    Save workbook to disk.\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._handles.handle, mmap.mmap):\n\u001b[32m    112\u001b[39m         \u001b[38;5;66;03m# truncate file to the written content\u001b[39;00m\n\u001b[32m    113\u001b[39m         \u001b[38;5;28mself\u001b[39m._handles.handle.truncate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\workbook\\workbook.py:386\u001b[39m, in \u001b[36mWorkbook.save\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.write_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.worksheets:\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m.create_sheet()\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[43msave_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:294\u001b[39m, in \u001b[36msave_workbook\u001b[39m\u001b[34m(workbook, filename)\u001b[39m\n\u001b[32m    292\u001b[39m workbook.properties.modified = datetime.datetime.now(tz=datetime.timezone.utc).replace(tzinfo=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    293\u001b[39m writer = ExcelWriter(workbook, archive)\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:275\u001b[39m, in \u001b[36mExcelWriter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    274\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write data into the archive.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28mself\u001b[39m._archive.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:77\u001b[39m, in \u001b[36mExcelWriter.write_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     74\u001b[39m     custom_override = CustomOverride()\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.manifest.append(custom_override)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_worksheets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m._write_chartsheets()\n\u001b[32m     79\u001b[39m \u001b[38;5;28mself\u001b[39m._write_images()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:215\u001b[39m, in \u001b[36mExcelWriter._write_worksheets\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, ws \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.workbook.worksheets, \u001b[32m1\u001b[39m):\n\u001b[32m    214\u001b[39m     ws._id = idx\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_worksheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mws\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ws._drawing:\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m._write_drawing(ws._drawing)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:205\u001b[39m, in \u001b[36mExcelWriter.write_worksheet\u001b[39m\u001b[34m(self, ws)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28mself\u001b[39m._archive.write(writer.out, ws.path[\u001b[32m1\u001b[39m:])\n\u001b[32m    204\u001b[39m \u001b[38;5;28mself\u001b[39m.manifest.append(ws)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_writer.py:389\u001b[39m, in \u001b[36mWorksheetWriter.cleanup\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcleanup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    386\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    387\u001b[39m \u001b[33;03m    Remove tempfile\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m     os.remove(\u001b[38;5;28mself\u001b[39m.out)\n\u001b[32m    390\u001b[39m     ALL_TEMP_FILES.remove(\u001b[38;5;28mself\u001b[39m.out)\n",
      "\u001b[31mPermissionError\u001b[39m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\SARAHA~1\\\\AppData\\\\Local\\\\Temp\\\\openpyxl.g7pjo8ej'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 2. تحميل موديل Flan-T5-Large\n",
    "model_name = \"google/flan-t5-large\"\n",
    "qa_model = pipeline(\"text2text-generation\", model=model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 3. دالة لتقسيم النصوص على التوكنز\n",
    "def chunk_text_by_tokens(text, max_tokens=500):\n",
    "    words = str(text).split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_len = 0\n",
    "\n",
    "    for word in words:\n",
    "        token_len = len(tokenizer.encode(word, add_special_tokens=False))\n",
    "        if current_len + token_len > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_len = token_len\n",
    "        else:\n",
    "            current_chunk.append(word)\n",
    "            current_len += token_len\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# 4. دالة للتحقق من مطابقة ground_truth للـ snippet\n",
    "def check_need_script(ground_truth, snippet):\n",
    "    chunks = chunk_text_by_tokens(snippet, max_tokens=500)\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"\n",
    "Snippet (correct answer): \"{chunk}\"\n",
    "Ground truth answer: \"{ground_truth}\"\n",
    "Question: Does the ground truth match or closely resemble the snippet? \n",
    "Answer only with Yes or No.\n",
    "\"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=30, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"yes\" in result.lower():  # مشابه أو مطابق\n",
    "            return \"No\"  # لا يحتاج سكربت\n",
    "    return \"Yes\"  # مختلف → يحتاج سكربت\n",
    "\n",
    "# 5. معالجة أول 10 صفوف\n",
    "for idx in range(min(10, len(df))):\n",
    "    df.at[idx, \"need_script\"] = check_need_script(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# 6. حفظ الملف النهائي\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_need_script_first10_large_c2.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"✅ Done! أول 10 صفوف تمت معالجتها وحفظ الملف:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7625de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 1 to 10...\n",
      "✅ Row 1 done → No\n",
      "✅ Row 2 done → No\n",
      "✅ Row 3 done → No\n",
      "✅ Row 4 done → No\n",
      "✅ Row 5 done → No\n",
      "✅ Row 6 done → No\n",
      "✅ Row 7 done → No\n",
      "✅ Row 8 done → No\n",
      "✅ Row 9 done → No\n",
      "✅ Row 10 done → No\n",
      "Processing rows 11 to 20...\n",
      "✅ Row 11 done → No\n",
      "✅ Row 12 done → No\n",
      "✅ Row 13 done → No\n",
      "✅ Row 14 done → No\n",
      "✅ Row 15 done → No\n",
      "✅ Row 16 done → No\n",
      "✅ Row 17 done → No\n",
      "✅ Row 18 done → No\n",
      "✅ Row 19 done → No\n",
      "✅ Row 20 done → No\n",
      "Processing rows 21 to 30...\n",
      "✅ Row 21 done → No\n",
      "✅ Row 22 done → No\n",
      "✅ Row 23 done → No\n",
      "✅ Row 24 done → No\n",
      "✅ Row 25 done → No\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing rows \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_idx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_idx, end_idx):\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m         df.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mcheck_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m done → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.at[idx,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# 6. حفظ نسخة جديدة\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mcheck_with_llm\u001b[39m\u001b[34m(ground_truth, snippet)\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[32m     23\u001b[39m         prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33mYou are an expert judge.\u001b[39m\n\u001b[32m     25\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \u001b[33mAnswer ONLY with Yes or No.\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         result = \u001b[43mqa_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     36\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mno\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result.lower():  \u001b[38;5;66;03m# يعني القرواند تروث موجودة أو مشابهة\u001b[39;00m\n\u001b[32m     37\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNo\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# لا يحتاج سكربت\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:191\u001b[39m, in \u001b[36mText2TextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]], **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m    163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[32m    165\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    188\u001b[39m \u001b[33;03m          ids of the generated text.\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    193\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m    194\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[32m0\u001b[39m])\n\u001b[32m    195\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[32m    196\u001b[39m     ):\n\u001b[32m    197\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1467\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1459\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1460\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1461\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1464\u001b[39m         )\n\u001b[32m   1465\u001b[39m     )\n\u001b[32m   1466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1474\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1473\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1475\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1374\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1372\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1373\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:220\u001b[39m, in \u001b[36mText2TextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    218\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m output_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m out_b = output_ids.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2551\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2539\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._sample(\n\u001b[32m   2540\u001b[39m         input_ids,\n\u001b[32m   2541\u001b[39m         logits_processor=prepared_logits_processor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2546\u001b[39m         **model_kwargs,\n\u001b[32m   2547\u001b[39m     )\n\u001b[32m   2549\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2550\u001b[39m     \u001b[38;5;66;03m# 11. run beam sample\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2552\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2556\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2558\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2560\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode == GenerationMode.GROUP_BEAM_SEARCH:\n\u001b[32m   2561\u001b[39m     logger.warning_once(\n\u001b[32m   2562\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGroup Beam Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2563\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2564\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3350\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3347\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_attentions\u001b[39m\u001b[33m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   3348\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m-> \u001b[39m\u001b[32m3350\u001b[39m model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3352\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3353\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3354\u001b[39m     model_outputs,\n\u001b[32m   3355\u001b[39m     model_kwargs,\n\u001b[32m   3356\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3357\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1763\u001b[39m, in \u001b[36mT5ForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1760\u001b[39m         decoder_attention_mask = decoder_attention_mask.to(\u001b[38;5;28mself\u001b[39m.decoder.first_device)\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1763\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1764\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1765\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1766\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1767\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1768\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1769\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1770\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1771\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1772\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1773\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1774\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1775\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1776\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1779\u001b[39m sequence_output = decoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1099\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m   1097\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m-> \u001b[39m\u001b[32m1099\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1117\u001b[39m \u001b[38;5;66;03m# We share the position biases between the layers - the first layer store them\u001b[39;00m\n\u001b[32m   1118\u001b[39m \u001b[38;5;66;03m# layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\u001b[39;00m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:736\u001b[39m, in \u001b[36mT5Block.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_values, use_cache, output_attentions, return_dict, cache_position)\u001b[39m\n\u001b[32m    733\u001b[39m     attention_outputs = attention_outputs + cross_attention_outputs[\u001b[32m1\u001b[39m:]\n\u001b[32m    735\u001b[39m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hidden_states.dtype == torch.float16:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 2. تحميل LLM من Hugging Face (مودل أكبر للحصول على دقة أعلى)\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")  # هنا مودل كبير\n",
    "\n",
    "# 3. دالة لتقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# 4. دالة لتقييم كل snippet مقابل القرواند تروث\n",
    "def check_with_llm(ground_truth, snippet):\n",
    "    chunks = chunk_text(snippet)\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"\n",
    "You are an expert judge.\n",
    "\n",
    "Snippet (source of truth): \"{chunk}\"\n",
    "Ground truth answer: \"{ground_truth}\"\n",
    "\n",
    "Question: Based on the snippet, does the ground truth exactly match or closely resemble the information in the snippet? \n",
    "- If the ground truth is correct or very similar to the snippet → Answer: No\n",
    "- If the ground truth is missing or different → Answer: Yes\n",
    "\n",
    "Answer ONLY with Yes or No.\n",
    "\"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"no\" in result.lower():  # يعني القرواند تروث موجودة أو مشابهة\n",
    "            return \"No\"  # لا يحتاج سكربت\n",
    "    return \"Yes\"  # يحتاج سكربت إذا لم نجد تطابق\n",
    "\n",
    "# 5. تطبيق على كل الصفوف (مثال على دفعات 10 صفوف)\n",
    "batch_size = 10\n",
    "for start_idx in range(0, len(df), batch_size):\n",
    "    end_idx = min(start_idx + batch_size, len(df))\n",
    "    print(f\"Processing rows {start_idx+1} to {end_idx}...\")\n",
    "    for idx in range(start_idx, end_idx):\n",
    "        df.at[idx, \"need_script\"] = check_with_llm(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "        print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# 6. حفظ نسخة جديدة\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_test.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ Done! الملف محفوظ في:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "929d28ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 1 to 10...\n",
      "✅ Row 1 done → No\n",
      "✅ Row 2 done → No\n",
      "✅ Row 3 done → No\n",
      "✅ Row 4 done → No\n",
      "✅ Row 5 done → No\n",
      "✅ Row 6 done → No\n",
      "✅ Row 7 done → No\n",
      "✅ Row 8 done → No\n",
      "✅ Row 9 done → No\n",
      "✅ Row 10 done → No\n",
      "✅ Done! الملف محفوظ في: C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_test_3.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. تحميل LLM من Hugging Face\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. دالة استخراج الأرقام من النص\n",
    "def extract_numbers(text):\n",
    "    return [float(n.replace(',', '')) for n in re.findall(r'\\d+\\.?\\d*', text)]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. دالة تقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------\n",
    "# 5. دالة الحكم على كل snippet مع مراعاة النصوص والأرقام بنفس الأهمية\n",
    "def check_snippet_equal(ground_truth, snippet, tolerance=0.05):\n",
    "    # مقارنة الأرقام\n",
    "    gt_numbers = extract_numbers(ground_truth)\n",
    "    snippet_numbers = extract_numbers(snippet)\n",
    "    numbers_match = any(abs(gt - sn)/gt <= tolerance for gt in gt_numbers for sn in snippet_numbers) if gt_numbers else False\n",
    "\n",
    "    # مقارنة النصوص باستخدام LLM مع Prompt محسّن\n",
    "    chunks = chunk_text(snippet)\n",
    "    text_match = False\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"\n",
    "You are an expert judge in evaluating textual and numerical data.\n",
    "\n",
    "Snippet (source of information): \n",
    "\"{chunk}\"\n",
    "\n",
    "Ground truth statement: \n",
    "\"{ground_truth}\"\n",
    "\n",
    "Instructions:\n",
    "1. Carefully compare the snippet with the ground truth, considering both:\n",
    "   a) Textual content (words, meaning, context) \n",
    "   b) Numerical values (treat numbers as equally important as text)\n",
    "2. For numbers, consider them matching if they are within 5% of each other.\n",
    "3. Ignore minor formatting, synonyms, or small textual variations that do not change the meaning.\n",
    "4. Determine if the ground truth is fully present or closely matched in the snippet.\n",
    "5. Provide your answer ONLY as \"Yes\" or \"No\":\n",
    "   - \"No\" → The ground truth is fully present or closely matched.\n",
    "   - \"Yes\" → The ground truth is missing or significantly different.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"no\" in result.lower():\n",
    "            text_match = True\n",
    "            break\n",
    "\n",
    "    if numbers_match or text_match:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6. تتبع آخر صف تمّت معالجته\n",
    "progress_file = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\progress.txt\"\n",
    "\n",
    "if os.path.exists(progress_file):\n",
    "    with open(progress_file, \"r\") as f:\n",
    "        start_idx = int(f.read().strip())\n",
    "else:\n",
    "    start_idx = 0  # أول تشغيل\n",
    "\n",
    "batch_size = 10\n",
    "end_idx = min(start_idx + batch_size, len(df))\n",
    "\n",
    "print(f\"Processing rows {start_idx+1} to {end_idx}...\")\n",
    "\n",
    "for idx in range(start_idx, end_idx):\n",
    "    df.at[idx, \"need_script\"] = check_snippet_equal(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# -----------------------------\n",
    "# حفظ النسخة\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_test_3.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ Done! الملف محفوظ في:\", output_path)\n",
    "\n",
    "# -----------------------------\n",
    "# حفظ آخر صف تمّت معالجته\n",
    "with open(progress_file, \"w\") as f:\n",
    "    f.write(str(end_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32f526b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 11 to 20...\n",
      "✅ Row 11 done → No\n",
      "✅ Row 12 done → No\n",
      "✅ Row 13 done → No\n",
      "✅ Row 14 done → No\n",
      "✅ Row 15 done → No\n",
      "✅ Row 16 done → No\n",
      "✅ Row 17 done → No\n",
      "✅ Row 18 done → No\n",
      "✅ Row 19 done → No\n",
      "✅ Row 20 done → No\n",
      "✅ Done! الملف محفوظ في: C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_test_4.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import os\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. تحميل LLM من Hugging Face\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. دالة استخراج الأرقام من النص\n",
    "def extract_numbers(text):\n",
    "    return [float(n.replace(',', '')) for n in re.findall(r'\\d+\\.?\\d*', text)]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. دالة تحويل الأرقام لوحدة موحدة (مليار/مليون) إذا احتجنا\n",
    "def normalize_number(n):\n",
    "    return n  # يمكن إضافة تحويلات لو الأرقام بالمليار أو ترليون لاحقاً\n",
    "\n",
    "# -----------------------------\n",
    "# 5. دالة مقارنة نصوص بشكل سريع (fuzzy)\n",
    "def text_similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()  # يعطي نسبة التشابه 0-1\n",
    "\n",
    "# -----------------------------\n",
    "# 6. دالة الحكم على كل snippet مع مراعاة النصوص والأرقام بنفس الأهمية\n",
    "def check_snippet_equal(ground_truth, snippet, tolerance=0.05, text_threshold=0.85):\n",
    "    # مقارنة الأرقام أولاً\n",
    "    gt_numbers = [normalize_number(n) for n in extract_numbers(ground_truth)]\n",
    "    snippet_numbers = [normalize_number(n) for n in extract_numbers(snippet)]\n",
    "    numbers_match = any(abs(gt - sn)/gt <= tolerance for gt in gt_numbers for sn in snippet_numbers) if gt_numbers else False\n",
    "\n",
    "    # مقارنة النصوص باستخدام fuzzy + LLM مع Prompt محسّن\n",
    "    text_match = False\n",
    "    chunks = snippet.split('.')  # تقسيم على الجمل\n",
    "    for chunk in chunks:\n",
    "        # مقارنة سريعة\n",
    "        if text_similarity(ground_truth, chunk) >= text_threshold:\n",
    "            text_match = True\n",
    "            break\n",
    "        # LLM للتأكيد فقط\n",
    "        prompt = f\"\"\"\n",
    "You are an expert judge in evaluating textual and numerical data.\n",
    "\n",
    "Snippet: \n",
    "\"{chunk.strip()}\"\n",
    "\n",
    "Ground truth: \n",
    "\"{ground_truth}\"\n",
    "\n",
    "Instructions:\n",
    "- Consider textual content and numerical values equally.\n",
    "- Ignore small variations, synonyms, formatting differences.\n",
    "- Provide ONLY \"Yes\" or \"No\":\n",
    "  - \"No\" → Ground truth is fully or closely present.\n",
    "  - \"Yes\" → Ground truth is missing or significantly different.\n",
    "Answer:\n",
    "\"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"no\" in result.lower():\n",
    "            text_match = True\n",
    "            break\n",
    "\n",
    "    # القرار النهائي\n",
    "    if numbers_match or text_match:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# -----------------------------\n",
    "# 7. تتبع آخر صف تمّت معالجته\n",
    "progress_file = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\progress.txt\"\n",
    "\n",
    "if os.path.exists(progress_file):\n",
    "    with open(progress_file, \"r\") as f:\n",
    "        start_idx = int(f.read().strip())\n",
    "else:\n",
    "    start_idx = 0  # أول تشغيل\n",
    "\n",
    "batch_size = 10\n",
    "end_idx = min(start_idx + batch_size, len(df))\n",
    "\n",
    "print(f\"Processing rows {start_idx+1} to {end_idx}...\")\n",
    "\n",
    "for idx in range(start_idx, end_idx):\n",
    "    df.at[idx, \"need_script\"] = check_snippet_equal(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# -----------------------------\n",
    "# حفظ النسخة\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_test_4.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ Done! الملف محفوظ في:\", output_path)\n",
    "\n",
    "# -----------------------------\n",
    "# حفظ آخر صف تمّت معالجته\n",
    "with open(progress_file, \"w\") as f:\n",
    "    f.write(str(end_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f6e259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 1 to 10...\n",
      "✅ Row 1 done → No\n",
      "✅ Row 2 done → No\n",
      "✅ Row 3 done → No\n",
      "✅ Row 4 done → No\n",
      "✅ Row 5 done → No\n",
      "✅ Row 6 done → No\n",
      "✅ Row 7 done → No\n",
      "✅ Row 8 done → No\n",
      "✅ Row 9 done → No\n",
      "✅ Row 10 done → No\n",
      "✅ Done! الملف محفوظ في: C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_test_full.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. تحميل LLM من Hugging Face\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. دالة استخراج الأرقام من النص\n",
    "def extract_numbers(text):\n",
    "    return [float(n.replace(',', '')) for n in re.findall(r'\\d+\\.?\\d*', text)]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. دالة تقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------\n",
    "# 5. دالة الحكم على كل snippet مع مراعاة النصوص والأرقام بنفس الأهمية\n",
    "def check_snippet_equal(ground_truth, snippet, tolerance=0.05):\n",
    "    # مقارنة الأرقام\n",
    "    gt_numbers = extract_numbers(ground_truth)\n",
    "    snippet_numbers = extract_numbers(snippet)\n",
    "    numbers_match = any(abs(gt - sn)/gt <= tolerance for gt in gt_numbers for sn in snippet_numbers) if gt_numbers else False\n",
    "\n",
    "    # مقارنة النصوص باستخدام LLM مع Prompt محسّن\n",
    "    chunks = chunk_text(snippet)\n",
    "    text_match = False\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"\n",
    "You are an expert judge in evaluating textual and numerical data.\n",
    "\n",
    "Snippet (source of information): \n",
    "\"{chunk}\"\n",
    "\n",
    "Ground truth statement: \n",
    "\"{ground_truth}\"\n",
    "\n",
    "Instructions:\n",
    "1. Carefully compare the snippet with the ground truth, considering both:\n",
    "   a) Textual content (words, meaning, context) \n",
    "   b) Numerical values (treat numbers as equally important as text)\n",
    "2. For numbers, consider them matching if they are within 5% of each other.\n",
    "3. Ignore minor formatting, synonyms, or small textual variations that do not change the meaning.\n",
    "4. Determine if the ground truth is fully present or closely matched in the snippet.\n",
    "5. Provide your answer ONLY as \"Yes\" or \"No\":\n",
    "   - \"No\" → The ground truth is fully present or closely matched.\n",
    "   - \"Yes\" → The ground truth is missing or significantly different.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"no\" in result.lower():\n",
    "            text_match = True\n",
    "            break\n",
    "\n",
    "    if numbers_match or text_match:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6. بدء المعالجة من البداية دائمًا\n",
    "start_idx = 0\n",
    "batch_size = 10\n",
    "end_idx = min(start_idx + batch_size, len(df))\n",
    "\n",
    "print(f\"Processing rows {start_idx+1} to {end_idx}...\")\n",
    "\n",
    "for idx in range(start_idx, end_idx):\n",
    "    df.at[idx, \"need_script\"] = check_snippet_equal(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# -----------------------------\n",
    "# حفظ النسخة\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_test_full.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ Done! الملف محفوظ في:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38d1c6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 21 to 30...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing rows \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_idx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_idx, end_idx):\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     df.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mcheck_snippet_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m done → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.at[idx,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# حفظ النسخة\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mcheck_snippet_equal\u001b[39m\u001b[34m(ground_truth, snippet, tolerance)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[32m     41\u001b[39m         prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[33mYou are an expert fact-checker and data evaluator. Compare textual content and numerical values.\u001b[39m\n\u001b[32m     43\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m \u001b[33mAnswer:\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m         result = \u001b[43mqa_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     59\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mno\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result.lower():\n\u001b[32m     60\u001b[39m             text_match = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:191\u001b[39m, in \u001b[36mText2TextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]], **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m    163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[32m    165\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    188\u001b[39m \u001b[33;03m          ids of the generated text.\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    193\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m    194\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[32m0\u001b[39m])\n\u001b[32m    195\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[32m    196\u001b[39m     ):\n\u001b[32m    197\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1467\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1459\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1460\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1461\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1464\u001b[39m         )\n\u001b[32m   1465\u001b[39m     )\n\u001b[32m   1466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1474\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1473\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1475\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1374\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1372\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1373\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:220\u001b[39m, in \u001b[36mText2TextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    218\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m output_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m out_b = output_ids.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2337\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2333\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`attention_mask` passed to `generate` must be 2D.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[32m   2336\u001b[39m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2337\u001b[39m     model_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2338\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\n\u001b[32m   2339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2341\u001b[39m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[32m   2342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:856\u001b[39m, in \u001b[36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[39m\u001b[34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[39m\n\u001b[32m    854\u001b[39m encoder_kwargs[\u001b[33m\"\u001b[39m\u001b[33mreturn_dict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    855\u001b[39m encoder_kwargs[model_input_name] = inputs_tensor\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m]: ModelOutput = \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1099\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m   1097\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m-> \u001b[39m\u001b[32m1099\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1117\u001b[39m \u001b[38;5;66;03m# We share the position biases between the layers - the first layer store them\u001b[39;00m\n\u001b[32m   1118\u001b[39m \u001b[38;5;66;03m# layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\u001b[39;00m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:736\u001b[39m, in \u001b[36mT5Block.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_values, use_cache, output_attentions, return_dict, cache_position)\u001b[39m\n\u001b[32m    733\u001b[39m     attention_outputs = attention_outputs + cross_attention_outputs[\u001b[32m1\u001b[39m:]\n\u001b[32m    735\u001b[39m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hidden_states.dtype == torch.float16:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:343\u001b[39m, in \u001b[36mT5LayerFF.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[32m    342\u001b[39m     forwarded_states = \u001b[38;5;28mself\u001b[39m.layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     forwarded_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mDenseReluDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforwarded_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m     hidden_states = hidden_states + \u001b[38;5;28mself\u001b[39m.dropout(forwarded_states)\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:312\u001b[39m, in \u001b[36mT5DenseGatedActDense.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[32m    311\u001b[39m     hidden_gelu = \u001b[38;5;28mself\u001b[39m.act(\u001b[38;5;28mself\u001b[39m.wi_0(hidden_states))\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     hidden_linear = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwi_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m     hidden_states = hidden_gelu * hidden_linear\n\u001b[32m    314\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dropout(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. تحميل LLM من Hugging Face\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. دالة استخراج الأرقام من النص\n",
    "def extract_numbers(text):\n",
    "    return [float(n.replace(',', '')) for n in re.findall(r'\\d+\\.?\\d*', text)]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. دالة تقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------\n",
    "# 5. دالة الحكم على كل snippet مع مراعاة النصوص والأرقام بنفس الأهمية\n",
    "def check_snippet_equal(ground_truth, snippet, tolerance=0.05):\n",
    "    # مقارنة الأرقام\n",
    "    gt_numbers = extract_numbers(ground_truth)\n",
    "    snippet_numbers = extract_numbers(snippet)\n",
    "    numbers_match = any(abs(gt - sn)/gt <= tolerance for gt in gt_numbers for sn in snippet_numbers) if gt_numbers else False\n",
    "\n",
    "    # مقارنة النصوص باستخدام LLM مع Prompt محسّن\n",
    "    chunks = chunk_text(snippet)\n",
    "    text_match = False\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"\n",
    "You are an expert fact-checker and data evaluator. Compare textual content and numerical values.\n",
    "\n",
    "Snippet: \"{chunk}\"\n",
    "Ground truth: \"{ground_truth}\"\n",
    "\n",
    "Instructions:\n",
    "- Consider numbers and text equally important.\n",
    "- Numbers match if within 5%.\n",
    "- Text should match meaning; ignore minor formatting differences.\n",
    "- Respond ONLY \"Yes\" or \"No\":\n",
    "  - \"No\" → Ground truth is fully present or closely matched.\n",
    "  - \"Yes\" → Ground truth is missing or significantly different.\n",
    "- Give a single word only.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"no\" in result.lower():\n",
    "            text_match = True\n",
    "            break\n",
    "\n",
    "    if numbers_match or text_match:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6. تتبع آخر صف تمّت معالجته\n",
    "progress_file = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\progress.txt\"\n",
    "\n",
    "if os.path.exists(progress_file):\n",
    "    with open(progress_file, \"r\") as f:\n",
    "        start_idx = int(f.read().strip())  # متابعة من آخر صف\n",
    "else:\n",
    "    start_idx = 0  # أول تشغيل، يبدأ من الصف الأول\n",
    "\n",
    "batch_size = 10\n",
    "end_idx = min(start_idx + batch_size, len(df))\n",
    "\n",
    "print(f\"Processing rows {start_idx+1} to {end_idx}...\")\n",
    "\n",
    "for idx in range(start_idx, end_idx):\n",
    "    df.at[idx, \"need_script\"] = check_snippet_equal(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# -----------------------------\n",
    "# حفظ النسخة\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_test_prog2.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ Done! الملف محفوظ في:\", output_path)\n",
    "\n",
    "# -----------------------------\n",
    "# حفظ آخر صف تمّت معالجته\n",
    "with open(progress_file, \"w\") as f:\n",
    "    f.write(str(end_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9daa56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 1 to 10...\n",
      "✅ Row 1 done → No\n",
      "✅ Row 2 done → No\n",
      "✅ Row 3 done → No\n",
      "✅ Row 4 done → No\n",
      "✅ Row 5 done → No\n",
      "✅ Row 6 done → No\n",
      "✅ Row 7 done → No\n",
      "✅ Row 8 done → No\n",
      "✅ Row 9 done → No\n",
      "✅ Row 10 done → No\n",
      "✅ Done! الملف محفوظ في: C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_test_progress_5.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. تحميل LLM من Hugging Face\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. دالة استخراج الأرقام من النص\n",
    "def extract_numbers(text):\n",
    "    return [float(n.replace(',', '')) for n in re.findall(r'\\d+\\.?\\d*', text)]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. دالة تقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------\n",
    "# 5. دالة الحكم على كل snippet مع مراعاة النصوص والأرقام بنفس الأهمية\n",
    "def check_snippet_equal(ground_truth, snippet, tolerance=0.05):\n",
    "    gt_numbers = extract_numbers(ground_truth)\n",
    "    snippet_numbers = extract_numbers(snippet)\n",
    "    numbers_match = any(abs(gt - sn)/gt <= tolerance for gt in gt_numbers for sn in snippet_numbers) if gt_numbers else False\n",
    "\n",
    "    chunks = chunk_text(snippet)\n",
    "    text_match = False\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"\n",
    "You are an expert fact-checker and data evaluator. Compare textual content and numerical values.\n",
    "\n",
    "Examples:\n",
    "1) Snippet: \"The MENA e-commerce market reached $40 billion in 2024.\"\n",
    "   Ground truth: \"The estimated market value of the MENA e-commerce market in 2024 is $41.6 billion.\"\n",
    "   Answer: No\n",
    "\n",
    "2) Snippet: \"The UAE online orders grew by 7% in 2024.\"\n",
    "   Ground truth: \"The UAE online orders grew by 7% in 2024.\"\n",
    "   Answer: No\n",
    "\n",
    "3) Snippet: \"Saudi Arabia's e-commerce revenue was $52.5 billion.\"\n",
    "   Ground truth: \"Saudi Arabia's e-commerce revenue was around $52.5 billion.\"\n",
    "   Answer: No\n",
    "\n",
    "4) Snippet: \"The regional Average Order Value (AOV) increased from $30 in 2023 to $35.6 in 2024.\"\n",
    "   Ground truth: \"The AOV in MENA increased from $30 in 2023 to $35.6 in 2024.\"\n",
    "   Answer: No\n",
    "\n",
    "\n",
    "Snippet: \"{chunk}\"\n",
    "Ground truth: \"{ground_truth}\"\n",
    "\n",
    "Instructions:\n",
    "- Consider numbers and text equally important.\n",
    "- Numbers match if within 5%.\n",
    "- Text should match meaning; ignore minor formatting differences.\n",
    "- Respond ONLY \"Yes\" or \"No\":\n",
    "  - \"No\" → Ground truth is fully present or closely matched.\n",
    "  - \"Yes\" → Ground truth is missing or significantly different.\n",
    "- Give a single word only.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"no\" in result.lower():\n",
    "            text_match = True\n",
    "            break\n",
    "\n",
    "    if numbers_match or text_match:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6. تتبع آخر صف تمّت معالجته في ملف جديد (progress_new.txt)\n",
    "progress_file_new = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\progress_2.txt\"\n",
    "\n",
    "if os.path.exists(progress_file_new):\n",
    "    with open(progress_file_new, \"r\") as f:\n",
    "        start_idx = int(f.read().strip())\n",
    "else:\n",
    "    start_idx = 0  # أول تشغيل لهذا الملف الجديد\n",
    "\n",
    "batch_size = 10\n",
    "end_idx = min(start_idx + batch_size, len(df))\n",
    "\n",
    "print(f\"Processing rows {start_idx+1} to {end_idx}...\")\n",
    "\n",
    "for idx in range(start_idx, end_idx):\n",
    "    df.at[idx, \"need_script\"] = check_snippet_equal(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# -----------------------------\n",
    "# حفظ النسخة\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_test_progress_5.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ Done! الملف محفوظ في:\", output_path)\n",
    "\n",
    "# -----------------------------\n",
    "# حفظ آخر صف تمّت معالجته في الملف الجديد\n",
    "with open(progress_file_new, \"w\") as f:\n",
    "    f.write(str(end_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56e285fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 21 to 30...\n",
      "✅ Row 21 done → No\n",
      "✅ Row 22 done → No\n",
      "✅ Row 23 done → No\n",
      "✅ Row 24 done → No\n",
      "✅ Row 25 done → No\n",
      "✅ Row 26 done → No\n",
      "✅ Row 27 done → No\n",
      "✅ Row 28 done → Yes\n",
      "✅ Row 29 done → No\n",
      "✅ Row 30 done → No\n",
      "✅ Done! الملف محفوظ في: C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_test_start_from_0.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. تحميل LLM من Hugging Face\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=-1)  # CPU\n",
    "\n",
    "# -----------------------------\n",
    "# 3. دالة استخراج الأرقام من النص\n",
    "def extract_numbers(text):\n",
    "    return [float(n.replace(',', '').replace('$','').replace('B','e9').replace('M','e6')) for n in re.findall(r'\\d+\\.?\\d*B?M?', text)]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. دالة تقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------\n",
    "# 5. دالة الحكم على كل snippet\n",
    "def check_snippet_equal(ground_truth, snippet, tolerance=0.05):\n",
    "    # مقارنة الأرقام أولًا (أكثر من 5% → Yes فورًا)\n",
    "    gt_numbers = extract_numbers(ground_truth)\n",
    "    snippet_numbers = extract_numbers(snippet)\n",
    "    numbers_match = False\n",
    "    for gt in gt_numbers:\n",
    "        for sn in snippet_numbers:\n",
    "            if abs(gt - sn)/gt <= tolerance:\n",
    "                numbers_match = True\n",
    "                break\n",
    "        if numbers_match:\n",
    "            break\n",
    "\n",
    "    if gt_numbers and not numbers_match:\n",
    "        return \"Yes\"  # الأرقام مختلفة جدًا → لا حاجة للـ LLM\n",
    "\n",
    "    # مقارنة النصوص باستخدام LLM مع أمثلة\n",
    "    chunks = chunk_text(snippet)\n",
    "    text_match = False\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"\n",
    "You are an expert fact-checker and data evaluator. Compare textual content and numerical values.\n",
    "\n",
    "Examples:\n",
    "1) Snippet: \"The MENA e-commerce market reached $40 billion in 2024.\"\n",
    "   Ground truth: \"The estimated market value of the MENA e-commerce market in 2024 is $41.6 billion.\"\n",
    "   Answer: No\n",
    "\n",
    "2) Snippet: \"The UAE online orders grew by 7% in 2024.\"\n",
    "   Ground truth: \"The UAE online orders grew by 7% in 2024.\"\n",
    "   Answer: No\n",
    "\n",
    "3) Snippet: \"Saudi Arabia's e-commerce revenue was $52.5 billion.\"\n",
    "   Ground truth: \"Saudi Arabia's e-commerce revenue was around $52.5 billion.\"\n",
    "   Answer: No\n",
    "\n",
    "4) Snippet: \"The regional Average Order Value (AOV) increased from $30 in 2023 to $35.6 in 2024.\"\n",
    "   Ground truth: \"The AOV in MENA increased from $30 in 2023 to $35.6 in 2024.\"\n",
    "   Answer: No\n",
    "\n",
    "Snippet: \"{chunk}\"\n",
    "Ground truth: \"{ground_truth}\"\n",
    "\n",
    "Instructions:\n",
    "- Consider numbers and text equally important.\n",
    "- Numbers match if within 5%. If not, answer Yes immediately.\n",
    "- Text should match meaning; ignore minor formatting differences.\n",
    "- Respond ONLY \"Yes\" or \"No\":\n",
    "  - \"No\" → Ground truth is fully present or closely matched.\n",
    "  - \"Yes\" → Ground truth is missing or significantly different.\n",
    "- Give a single word only.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"no\" in result.lower():\n",
    "            text_match = True\n",
    "            break\n",
    "\n",
    "    if numbers_match or text_match:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6. إعداد ملف progress وقراءة آخر صف معالج\n",
    "progress_file = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\progress_start_from_0.txt\"\n",
    "\n",
    "if os.path.exists(progress_file):\n",
    "    with open(progress_file, \"r\") as f:\n",
    "        start_idx = int(f.read())\n",
    "else:\n",
    "    start_idx = 0\n",
    "\n",
    "batch_size = 10\n",
    "end_idx = min(start_idx + batch_size, len(df))\n",
    "\n",
    "print(f\"Processing rows {start_idx+1} to {end_idx}...\")\n",
    "\n",
    "for idx in range(start_idx, end_idx):\n",
    "    df.at[idx, \"need_script\"] = check_snippet_equal(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "# -----------------------------\n",
    "# حفظ النسخة\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_test_start_from_0.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ Done! الملف محفوظ في:\", output_path)\n",
    "\n",
    "# -----------------------------\n",
    "# حفظ آخر صف تمّت معالجته\n",
    "with open(progress_file, \"w\") as f:\n",
    "    f.write(str(end_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b32c0835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row 1 done → No\n",
      "✅ Row 2 done → No\n",
      "✅ Row 3 done → No\n",
      "✅ Row 4 done → No\n",
      "✅ Row 5 done → No\n",
      "✅ Row 6 done → No\n",
      "✅ Row 7 done → No\n",
      "✅ Row 8 done → No\n",
      "✅ Row 9 done → No\n",
      "✅ Row 10 done → No\n",
      "✅ Row 11 done → No\n",
      "✅ Row 12 done → No\n",
      "✅ Row 13 done → No\n",
      "✅ Row 14 done → No\n",
      "✅ Row 15 done → No\n",
      "✅ Row 16 done → No\n",
      "✅ Row 17 done → No\n",
      "✅ Row 18 done → Yes\n",
      "✅ Row 19 done → No\n",
      "✅ Row 20 done → No\n",
      "✅ Row 21 done → No\n",
      "✅ Row 22 done → No\n",
      "✅ Row 23 done → No\n",
      "✅ Row 24 done → No\n",
      "✅ Row 25 done → No\n",
      "✅ Row 26 done → No\n",
      "✅ Row 27 done → No\n",
      "✅ Row 28 done → Yes\n",
      "✅ Row 29 done → No\n",
      "✅ Row 30 done → No\n",
      "✅ Row 31 done → No\n",
      "✅ Row 32 done → No\n",
      "✅ Row 33 done → No\n",
      "✅ Row 34 done → No\n",
      "✅ Row 35 done → No\n",
      "✅ Row 36 done → No\n",
      "✅ Row 37 done → No\n",
      "✅ Row 38 done → No\n",
      "✅ Row 39 done → No\n",
      "✅ Row 40 done → No\n",
      "✅ Row 41 done → No\n",
      "✅ Row 42 done → No\n",
      "✅ Row 43 done → No\n",
      "✅ Row 44 done → No\n",
      "✅ Row 45 done → No\n",
      "✅ Row 46 done → No\n",
      "✅ Row 47 done → No\n",
      "✅ Row 48 done → No\n",
      "✅ Row 49 done → No\n",
      "✅ Row 50 done → No\n",
      "✅ Row 51 done → No\n",
      "✅ Row 52 done → No\n",
      "✅ Row 53 done → No\n",
      "✅ Row 54 done → No\n",
      "✅ Row 55 done → No\n",
      "✅ Row 56 done → No\n",
      "✅ Row 57 done → No\n",
      "✅ Row 58 done → Yes\n",
      "✅ Row 59 done → No\n",
      "✅ Row 60 done → No\n",
      "✅ Row 61 done → No\n",
      "✅ Row 62 done → No\n",
      "✅ Row 63 done → No\n",
      "✅ Row 64 done → No\n",
      "✅ Row 65 done → No\n",
      "✅ Row 66 done → No\n",
      "✅ Row 67 done → No\n",
      "✅ Row 68 done → No\n",
      "✅ Row 69 done → No\n",
      "✅ Row 70 done → No\n",
      "✅ Row 71 done → No\n",
      "✅ Row 72 done → No\n",
      "✅ Row 73 done → No\n",
      "✅ Row 74 done → No\n",
      "✅ Row 75 done → No\n",
      "✅ Row 76 done → No\n",
      "✅ Row 77 done → No\n",
      "✅ Row 78 done → No\n",
      "✅ Row 79 done → No\n",
      "✅ Row 80 done → No\n",
      "✅ Row 81 done → No\n",
      "✅ Row 82 done → No\n",
      "✅ Row 83 done → No\n",
      "✅ Row 84 done → No\n",
      "✅ Row 85 done → No\n",
      "✅ Row 86 done → No\n",
      "✅ Row 87 done → No\n",
      "✅ Row 88 done → No\n",
      "✅ Row 89 done → No\n",
      "✅ Row 90 done → No\n",
      "✅ Row 91 done → No\n",
      "✅ Row 92 done → No\n",
      "✅ Row 93 done → No\n",
      "✅ Row 94 done → No\n",
      "✅ Row 95 done → No\n",
      "✅ Row 96 done → No\n",
      "✅ Row 97 done → No\n",
      "✅ Row 98 done → No\n",
      "✅ Row 99 done → No\n",
      "✅ Row 100 done → No\n",
      "✅ Row 101 done → No\n",
      "✅ Row 102 done → No\n",
      "✅ Row 103 done → No\n",
      "✅ Row 104 done → No\n",
      "✅ Row 105 done → No\n",
      "✅ Row 106 done → No\n",
      "✅ Row 107 done → No\n",
      "✅ Row 108 done → No\n",
      "✅ Row 109 done → No\n",
      "✅ Row 110 done → No\n",
      "✅ Row 111 done → No\n",
      "✅ Row 112 done → No\n",
      "✅ Row 113 done → No\n",
      "✅ Row 114 done → No\n",
      "✅ Row 115 done → No\n",
      "✅ Row 116 done → No\n",
      "✅ Row 117 done → No\n",
      "✅ Row 118 done → No\n",
      "✅ Row 119 done → No\n",
      "✅ Row 120 done → No\n",
      "✅ Row 121 done → No\n",
      "✅ Row 122 done → No\n",
      "✅ Row 123 done → No\n",
      "✅ Row 124 done → No\n",
      "✅ Row 125 done → No\n",
      "✅ Row 126 done → No\n",
      "✅ Row 127 done → No\n",
      "✅ Row 128 done → No\n",
      "✅ Row 129 done → No\n",
      "✅ Row 130 done → No\n",
      "✅ Row 131 done → No\n",
      "✅ Row 132 done → No\n",
      "✅ Row 133 done → No\n",
      "✅ Row 134 done → No\n",
      "✅ Row 135 done → No\n",
      "✅ Row 136 done → No\n",
      "✅ Row 137 done → No\n",
      "✅ Row 138 done → No\n",
      "✅ Row 139 done → No\n",
      "✅ Row 140 done → No\n",
      "✅ Row 141 done → No\n",
      "✅ Row 142 done → No\n",
      "✅ Row 143 done → No\n",
      "✅ Row 144 done → No\n",
      "✅ Row 145 done → No\n",
      "✅ Row 146 done → Yes\n",
      "✅ Row 147 done → No\n",
      "✅ Row 148 done → No\n",
      "✅ Row 149 done → No\n",
      "✅ Row 150 done → Yes\n",
      "✅ Row 151 done → No\n",
      "✅ Row 152 done → No\n",
      "✅ Row 153 done → No\n",
      "✅ Row 154 done → No\n",
      "✅ Row 155 done → No\n",
      "✅ Row 156 done → No\n",
      "✅ Row 157 done → No\n",
      "✅ Row 158 done → No\n",
      "✅ Row 159 done → No\n",
      "✅ Row 160 done → No\n",
      "✅ Row 161 done → No\n",
      "✅ Row 162 done → No\n",
      "✅ Row 163 done → No\n",
      "✅ Row 164 done → No\n",
      "✅ Row 165 done → No\n",
      "✅ Row 166 done → No\n",
      "✅ Row 167 done → No\n",
      "✅ Row 168 done → No\n",
      "✅ Row 169 done → No\n",
      "✅ Row 170 done → No\n",
      "✅ Row 171 done → No\n",
      "✅ Row 172 done → No\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# 6. معالجة كل الصفوف من البداية\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     df.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mcheck_snippet_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m done → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.at[idx,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# حفظ النسخة النهائية\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mcheck_snippet_equal\u001b[39m\u001b[34m(ground_truth, snippet, tolerance)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gt \u001b[38;5;129;01min\u001b[39;00m gt_numbers:\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m sn \u001b[38;5;129;01min\u001b[39;00m snippet_numbers:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43msn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m/\u001b[49m\u001b[43mgt\u001b[49m <= tolerance:\n\u001b[32m     38\u001b[39m             numbers_match = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     39\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mZeroDivisionError\u001b[39m: float division by zero"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. تحميل LLM من Hugging Face\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=-1)  # CPU\n",
    "\n",
    "# -----------------------------\n",
    "# 3. دالة استخراج الأرقام من النص\n",
    "def extract_numbers(text):\n",
    "    return [float(n.replace(',', '').replace('$','').replace('B','e9').replace('M','e6')) \n",
    "            for n in re.findall(r'\\d+\\.?\\d*B?M?', text)]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. دالة تقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------\n",
    "# 5. دالة الحكم على كل snippet\n",
    "def check_snippet_equal(ground_truth, snippet, tolerance=0.05):\n",
    "    gt_numbers = extract_numbers(ground_truth)\n",
    "    snippet_numbers = extract_numbers(snippet)\n",
    "    numbers_match = False\n",
    "    for gt in gt_numbers:\n",
    "        for sn in snippet_numbers:\n",
    "            if abs(gt - sn)/gt <= tolerance:\n",
    "                numbers_match = True\n",
    "                break\n",
    "        if numbers_match:\n",
    "            break\n",
    "\n",
    "    if gt_numbers and not numbers_match:\n",
    "        return \"Yes\"\n",
    "\n",
    "    chunks = chunk_text(snippet)\n",
    "    text_match = False\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"\n",
    "You are an expert fact-checker and data evaluator. Compare textual content and numerical values.\n",
    "\n",
    "Examples:\n",
    "1) Snippet: \"The MENA e-commerce market reached $40 billion in 2024.\"\n",
    "   Ground truth: \"The estimated market value of the MENA e-commerce market in 2024 is $41.6 billion.\"\n",
    "   Answer: No\n",
    "\n",
    "2) Snippet: \"The UAE online orders grew by 7% in 2024.\"\n",
    "   Ground truth: \"The UAE online orders grew by 7% in 2024.\"\n",
    "   Answer: No\n",
    "\n",
    "3) Snippet: \"Saudi Arabia's e-commerce revenue was $52.5 billion.\"\n",
    "   Ground truth: \"Saudi Arabia's e-commerce revenue was around $52.5 billion.\"\n",
    "   Answer: No\n",
    "\n",
    "4) Snippet: \"The regional Average Order Value (AOV) increased from $30 in 2023 to $35.6 in 2024.\"\n",
    "   Ground truth: \"The AOV in MENA increased from $30 in 2023 to $35.6 in 2024.\"\n",
    "   Answer: No\n",
    "\n",
    "Snippet: \"{chunk}\"\n",
    "Ground truth: \"{ground_truth}\"\n",
    "\n",
    "Instructions:\n",
    "- Consider numbers and text equally important.\n",
    "- Numbers match if within 5%. If not, answer Yes immediately.\n",
    "- Text should match meaning; ignore minor formatting differences.\n",
    "- Respond ONLY \"Yes\" or \"No\":\n",
    "  - \"No\" → Ground truth is fully present or closely matched.\n",
    "  - \"Yes\" → Ground truth is missing or significantly different.\n",
    "- Give a single word only.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"no\" in result.lower():\n",
    "            text_match = True\n",
    "            break\n",
    "\n",
    "    if numbers_match or text_match:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6. معالجة كل الصفوف من البداية\n",
    "for idx in range(len(df)):\n",
    "    df.at[idx, \"need_script\"] = check_snippet_equal(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "# -----------------------------\n",
    "# حفظ النسخة النهائية\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_full_Final.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ Done! الملف محفوظ في:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a0702df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 61dea141-e787-4b25-8235-f1e7840bbde2)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-large/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: ba0c0ff1-35d2-4c03-98d2-88c8fb08ba03)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-large/resolve/main/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 5cc59115-6499-4f0c-ab1f-b28a31cf4874)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-large/resolve/main/config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 8fcad8bb-9e4f-4b36-99dd-aa77fd6d651c)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-large/resolve/main/config.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 36b79cef-60df-4cfd-85c2-11f2e84db752)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-large/resolve/main/config.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row 1 done → No\n",
      "✅ Row 2 done → No\n",
      "✅ Row 3 done → No\n",
      "✅ Row 4 done → No\n",
      "✅ Row 5 done → No\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 111\u001b[39m\n\u001b[32m    108\u001b[39m output_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSarahAlqahtani\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mneed_script_full_safe.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_idx, \u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     df.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mcheck_snippet_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrave_sinp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m done → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.at[idx,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# حفظ تدريجي كل 10 صفوف\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mcheck_snippet_equal\u001b[39m\u001b[34m(ground_truth, snippet, tolerance)\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[32m     53\u001b[39m         prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[33mYou are an expert fact-checker and data evaluator. Compare textual content and numerical values.\u001b[39m\n\u001b[32m     55\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m \u001b[33mAnswer:\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m         result = \u001b[43mqa_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     88\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mno\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result.lower():\n\u001b[32m     89\u001b[39m             text_match = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:191\u001b[39m, in \u001b[36mText2TextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]], **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m    163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[32m    165\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    188\u001b[39m \u001b[33;03m          ids of the generated text.\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    193\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m    194\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[32m0\u001b[39m])\n\u001b[32m    195\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[32m    196\u001b[39m     ):\n\u001b[32m    197\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1467\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1459\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1460\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1461\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1464\u001b[39m         )\n\u001b[32m   1465\u001b[39m     )\n\u001b[32m   1466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1474\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1473\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1475\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1374\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1372\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1373\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:220\u001b[39m, in \u001b[36mText2TextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    218\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m output_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m out_b = output_ids.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2551\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2539\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._sample(\n\u001b[32m   2540\u001b[39m         input_ids,\n\u001b[32m   2541\u001b[39m         logits_processor=prepared_logits_processor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2546\u001b[39m         **model_kwargs,\n\u001b[32m   2547\u001b[39m     )\n\u001b[32m   2549\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2550\u001b[39m     \u001b[38;5;66;03m# 11. run beam sample\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2552\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2556\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2558\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2560\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode == GenerationMode.GROUP_BEAM_SEARCH:\n\u001b[32m   2561\u001b[39m     logger.warning_once(\n\u001b[32m   2562\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGroup Beam Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2563\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2564\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3350\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3347\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_attentions\u001b[39m\u001b[33m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   3348\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m-> \u001b[39m\u001b[32m3350\u001b[39m model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3352\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3353\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3354\u001b[39m     model_outputs,\n\u001b[32m   3355\u001b[39m     model_kwargs,\n\u001b[32m   3356\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3357\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1763\u001b[39m, in \u001b[36mT5ForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1760\u001b[39m         decoder_attention_mask = decoder_attention_mask.to(\u001b[38;5;28mself\u001b[39m.decoder.first_device)\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1763\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1764\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1765\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1766\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1767\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1768\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1769\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1770\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1771\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1772\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1773\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1774\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1775\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1776\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1779\u001b[39m sequence_output = decoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1099\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m   1097\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m-> \u001b[39m\u001b[32m1099\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1117\u001b[39m \u001b[38;5;66;03m# We share the position biases between the layers - the first layer store them\u001b[39;00m\n\u001b[32m   1118\u001b[39m \u001b[38;5;66;03m# layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\u001b[39;00m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:710\u001b[39m, in \u001b[36mT5Block.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_values, use_cache, output_attentions, return_dict, cache_position)\u001b[39m\n\u001b[32m    708\u001b[39m do_cross_attention = \u001b[38;5;28mself\u001b[39m.is_decoder \u001b[38;5;129;01mand\u001b[39;00m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_cross_attention:\n\u001b[32m--> \u001b[39m\u001b[32m710\u001b[39m     cross_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     hidden_states = cross_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    723\u001b[39m     \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:639\u001b[39m, in \u001b[36mT5LayerCrossAttention.forward\u001b[39m\u001b[34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_values, use_cache, query_length, output_attentions, cache_position)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    626\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    636\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    637\u001b[39m ):\n\u001b[32m    638\u001b[39m     normed_hidden_states = \u001b[38;5;28mself\u001b[39m.layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     attention_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mEncDecAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    651\u001b[39m     layer_output = hidden_states + \u001b[38;5;28mself\u001b[39m.dropout(attention_output[\u001b[32m0\u001b[39m])\n\u001b[32m    652\u001b[39m     outputs = (layer_output,) + attention_output[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:513\u001b[39m, in \u001b[36mT5Attention.forward\u001b[39m\u001b[34m(self, hidden_states, mask, key_value_states, position_bias, past_key_values, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m     key_states = \u001b[38;5;28mself\u001b[39m.k(current_states)\n\u001b[32m--> \u001b[39m\u001b[32m513\u001b[39m     value_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    514\u001b[39m     key_states = key_states.view(batch_size, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.n_heads, \u001b[38;5;28mself\u001b[39m.key_value_proj_dim).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    515\u001b[39m     value_states = value_states.view(batch_size, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.n_heads, \u001b[38;5;28mself\u001b[39m.key_value_proj_dim).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. تحميل LLM من Hugging Face\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=-1)  # CPU\n",
    "\n",
    "# -----------------------------\n",
    "# 3. دالة استخراج الأرقام من النص\n",
    "def extract_numbers(text):\n",
    "    return [float(n.replace(',', '').replace('$','').replace('B','e9').replace('M','e6')) \n",
    "            for n in re.findall(r'\\d+\\.?\\d*B?M?', str(text))]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. دالة تقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = str(text).split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------\n",
    "# 5. دالة الحكم على كل snippet\n",
    "def check_snippet_equal(ground_truth, snippet, tolerance=0.05):\n",
    "    gt_numbers = extract_numbers(ground_truth)\n",
    "    snippet_numbers = extract_numbers(snippet)\n",
    "    numbers_match = False\n",
    "\n",
    "    for gt in gt_numbers:\n",
    "        if gt == 0:  # تجنّب القسمة على صفر\n",
    "            continue\n",
    "        for sn in snippet_numbers:\n",
    "            if abs(gt - sn) / gt <= tolerance:\n",
    "                numbers_match = True\n",
    "                break\n",
    "        if numbers_match:\n",
    "            break\n",
    "\n",
    "    if gt_numbers and not numbers_match:\n",
    "        return \"Yes\"\n",
    "\n",
    "    chunks = chunk_text(snippet)\n",
    "    text_match = False\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"\n",
    "You are an expert fact-checker and data evaluator. Compare textual content and numerical values.\n",
    "\n",
    "Examples:\n",
    "1) Snippet: \"The MENA e-commerce market reached $40 billion in 2024.\"\n",
    "   Ground truth: \"The estimated market value of the MENA e-commerce market in 2024 is $41.6 billion.\"\n",
    "   Answer: No\n",
    "\n",
    "2) Snippet: \"The UAE online orders grew by 7% in 2024.\"\n",
    "   Ground truth: \"The UAE online orders grew by 7% in 2024.\"\n",
    "   Answer: No\n",
    "\n",
    "3) Snippet: \"Saudi Arabia's e-commerce revenue was $52.5 billion.\"\n",
    "   Ground truth: \"Saudi Arabia's e-commerce revenue was around $52.5 billion.\"\n",
    "   Answer: No\n",
    "\n",
    "4) Snippet: \"The regional Average Order Value (AOV) increased from $30 in 2023 to $35.6 in 2024.\"\n",
    "   Ground truth: \"The AOV in MENA increased from $30 in 2023 to $35.6 in 2024.\"\n",
    "   Answer: No\n",
    "\n",
    "Snippet: \"{chunk}\"\n",
    "Ground truth: \"{ground_truth}\"\n",
    "\n",
    "Instructions:\n",
    "- Consider numbers and text equally important.\n",
    "- Numbers match if within 5%. If not, answer Yes immediately.\n",
    "- Text should match meaning; ignore minor formatting differences.\n",
    "- Respond ONLY \"Yes\" or \"No\":\n",
    "  - \"No\" → Ground truth is fully present or closely matched.\n",
    "  - \"Yes\" → Ground truth is missing or significantly different.\n",
    "- Give a single word only.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "        result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        if \"no\" in result.lower():\n",
    "            text_match = True\n",
    "            break\n",
    "\n",
    "    if numbers_match or text_match:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6. ملف progress لحفظ آخر مكان\n",
    "progress_file = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\progress_safe.txt\"\n",
    "if os.path.exists(progress_file):\n",
    "    with open(progress_file, \"r\") as f:\n",
    "        start_idx = int(f.read())\n",
    "else:\n",
    "    start_idx = 0\n",
    "\n",
    "# -----------------------------\n",
    "# 7. معالجة كل الصفوف من البداية أو من آخر مكان\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_full_safe.xlsx\"\n",
    "\n",
    "for idx in range(start_idx, len(df)):\n",
    "    df.at[idx, \"need_script\"] = check_snippet_equal(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "    print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "\n",
    "    # حفظ تدريجي كل 10 صفوف\n",
    "    if (idx + 1) % 10 == 0 or idx == len(df) - 1:\n",
    "        df.to_excel(output_path, index=False)\n",
    "        with open(progress_file, \"w\") as f:\n",
    "            f.write(str(idx + 1))\n",
    "        print(f\"💾 Progress saved at row {idx+1}\")\n",
    "\n",
    "print(\"✅ Done! الملف محفوظ في:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "044a2d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row 1 done → No\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\SARAHA~1\\\\AppData\\\\Local\\\\Temp\\\\openpyxl.xl0cghts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 131\u001b[39m\n\u001b[32m    128\u001b[39m         df.at[idx, \u001b[33m\"\u001b[39m\u001b[33mneed_script\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mError\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m# حفظ فوري بعد كل صف\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# حفظ نهائي (تأكيد)\u001b[39;00m\n\u001b[32m    134\u001b[39m df.to_excel(output_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:2436\u001b[39m, in \u001b[36mNDFrame.to_excel\u001b[39m\u001b[34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   2423\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexcel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[32m   2425\u001b[39m formatter = ExcelFormatter(\n\u001b[32m   2426\u001b[39m     df,\n\u001b[32m   2427\u001b[39m     na_rep=na_rep,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2434\u001b[39m     inf_rep=inf_rep,\n\u001b[32m   2435\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2445\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:962\u001b[39m, in \u001b[36mExcelFormatter.write\u001b[39m\u001b[34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    960\u001b[39m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[32m    961\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m need_save:\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m         \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1357\u001b[39m, in \u001b[36mExcelWriter.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1355\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1356\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"synonym for save, to make it more file-like\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1357\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1358\u001b[39m     \u001b[38;5;28mself\u001b[39m._handles.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:110\u001b[39m, in \u001b[36mOpenpyxlWriter._save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_save\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    107\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m    Save workbook to disk.\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._handles.handle, mmap.mmap):\n\u001b[32m    112\u001b[39m         \u001b[38;5;66;03m# truncate file to the written content\u001b[39;00m\n\u001b[32m    113\u001b[39m         \u001b[38;5;28mself\u001b[39m._handles.handle.truncate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\workbook\\workbook.py:386\u001b[39m, in \u001b[36mWorkbook.save\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.write_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.worksheets:\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m.create_sheet()\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[43msave_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:294\u001b[39m, in \u001b[36msave_workbook\u001b[39m\u001b[34m(workbook, filename)\u001b[39m\n\u001b[32m    292\u001b[39m workbook.properties.modified = datetime.datetime.now(tz=datetime.timezone.utc).replace(tzinfo=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    293\u001b[39m writer = ExcelWriter(workbook, archive)\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:275\u001b[39m, in \u001b[36mExcelWriter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    274\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write data into the archive.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28mself\u001b[39m._archive.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:77\u001b[39m, in \u001b[36mExcelWriter.write_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     74\u001b[39m     custom_override = CustomOverride()\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.manifest.append(custom_override)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_worksheets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m._write_chartsheets()\n\u001b[32m     79\u001b[39m \u001b[38;5;28mself\u001b[39m._write_images()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:215\u001b[39m, in \u001b[36mExcelWriter._write_worksheets\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, ws \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.workbook.worksheets, \u001b[32m1\u001b[39m):\n\u001b[32m    214\u001b[39m     ws._id = idx\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_worksheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mws\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ws._drawing:\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m._write_drawing(ws._drawing)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:205\u001b[39m, in \u001b[36mExcelWriter.write_worksheet\u001b[39m\u001b[34m(self, ws)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28mself\u001b[39m._archive.write(writer.out, ws.path[\u001b[32m1\u001b[39m:])\n\u001b[32m    204\u001b[39m \u001b[38;5;28mself\u001b[39m.manifest.append(ws)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SarahAlqahtani\\Documents\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_writer.py:389\u001b[39m, in \u001b[36mWorksheetWriter.cleanup\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcleanup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    386\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    387\u001b[39m \u001b[33;03m    Remove tempfile\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m     os.remove(\u001b[38;5;28mself\u001b[39m.out)\n\u001b[32m    390\u001b[39m     ALL_TEMP_FILES.remove(\u001b[38;5;28mself\u001b[39m.out)\n",
      "\u001b[31mPermissionError\u001b[39m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\SARAHA~1\\\\AppData\\\\Local\\\\Temp\\\\openpyxl.xl0cghts'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from transformers import pipeline\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. تحميل النموذج مع Retry عند فشل الاتصال\n",
    "max_retries = 5\n",
    "retry_delay = 5  # ثواني\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=-1)  # CPU\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Attempt {attempt+1} failed: {e}\")\n",
    "        if attempt < max_retries - 1:\n",
    "            print(f\"⏳ Retrying in {retry_delay} seconds...\")\n",
    "            time.sleep(retry_delay)\n",
    "        else:\n",
    "            raise RuntimeError(\"Failed to load model after multiple attempts\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. دالة استخراج الأرقام\n",
    "def extract_numbers(text):\n",
    "    numbers = []\n",
    "    for n in re.findall(r'\\d+\\.?\\d*B?M?', str(text)):\n",
    "        n = n.replace(',', '').replace('$','')\n",
    "        if 'B' in n:\n",
    "            numbers.append(float(n.replace('B','')) * 1e9)\n",
    "        elif 'M' in n:\n",
    "            numbers.append(float(n.replace('M','')) * 1e6)\n",
    "        else:\n",
    "            numbers.append(float(n))\n",
    "    return numbers\n",
    "\n",
    "# -----------------------------\n",
    "# 4. دالة تقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_words=200):\n",
    "    words = str(text).split()\n",
    "    return [\" \".join(words[i:i+max_words]) for i in range(0, len(words), max_words)]\n",
    "\n",
    "# -----------------------------\n",
    "# 5. دالة تقييم كل snippet مع الحفاظ على البرومبت كما هو\n",
    "def check_snippet_equal(ground_truth, snippet, tolerance=0.05):\n",
    "    gt_numbers = extract_numbers(ground_truth)\n",
    "    snippet_numbers = extract_numbers(snippet)\n",
    "\n",
    "    # مقارنة الأرقام\n",
    "    numbers_match = False\n",
    "    for gt in gt_numbers:\n",
    "        if gt == 0:  # لتجنب ZeroDivisionError\n",
    "            continue\n",
    "        for sn in snippet_numbers:\n",
    "            if abs(gt - sn)/gt <= tolerance:\n",
    "                numbers_match = True\n",
    "                break\n",
    "        if numbers_match:\n",
    "            break\n",
    "\n",
    "    if gt_numbers and not numbers_match:\n",
    "        return \"Yes\"\n",
    "\n",
    "    # تقسيم النصوص الطويلة\n",
    "    chunks = chunk_text(snippet)\n",
    "    text_match = False\n",
    "    for chunk in chunks:\n",
    "        # هنا نحتفظ بالبرومبت الأصلي كما وضعتيه\n",
    "        prompt = f\"\"\"\n",
    "You are an expert fact-checker and data evaluator. Compare textual content and numerical values.\n",
    "\n",
    "Examples:\n",
    "1) Snippet: \"The MENA e-commerce market reached $40 billion in 2024.\"\n",
    "   Ground truth: \"The estimated market value of the MENA e-commerce market in 2024 is $41.6 billion.\"\n",
    "   Answer: No\n",
    "\n",
    "2) Snippet: \"The UAE online orders grew by 7% in 2024.\"\n",
    "   Ground truth: \"The UAE online orders grew by 7% in 2024.\"\n",
    "   Answer: No\n",
    "\n",
    "3) Snippet: \"Saudi Arabia's e-commerce revenue was $52.5 billion.\"\n",
    "   Ground truth: \"Saudi Arabia's e-commerce revenue was around $52.5 billion.\"\n",
    "   Answer: No\n",
    "\n",
    "4) Snippet: \"The regional Average Order Value (AOV) increased from $30 in 2023 to $35.6 in 2024.\"\n",
    "   Ground truth: \"The AOV in MENA increased from $30 in 2023 to $35.6 in 2024.\"\n",
    "   Answer: No\n",
    "\n",
    "Snippet: \"{chunk}\"\n",
    "Ground truth: \"{ground_truth}\"\n",
    "\n",
    "Instructions:\n",
    "- Consider numbers and text equally important.\n",
    "- Numbers match if within 5%. If not, answer Yes immediately.\n",
    "- Text should match meaning; ignore minor formatting differences.\n",
    "- Respond ONLY \"Yes\" or \"No\":\n",
    "  - \"No\" → Ground truth is fully present or closely matched.\n",
    "  - \"Yes\" → Ground truth is missing or significantly different.\n",
    "- Give a single word only.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "        try:\n",
    "            result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "            if \"no\" in result.lower():\n",
    "                text_match = True\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error in row evaluation: {e}\")\n",
    "            continue\n",
    "\n",
    "    return \"No\" if numbers_match or text_match else \"Yes\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6. المعالجة مع الحفظ بعد كل صف\n",
    "output_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_full_Final.xlsx\"\n",
    "\n",
    "for idx in range(len(df)):\n",
    "    try:\n",
    "        df.at[idx, \"need_script\"] = check_snippet_equal(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "        print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Row {idx+1} failed: {e}\")\n",
    "        df.at[idx, \"need_script\"] = \"Error\"\n",
    "\n",
    "    # حفظ فوري بعد كل صف\n",
    "    df.to_excel(output_path, index=False)\n",
    "\n",
    "# حفظ نهائي (تأكيد)\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ Done! الملف محفوظ في:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71da63da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row 1 done → No\n",
      "✅ Row 2 done → No\n",
      "✅ Row 3 done → No\n",
      "✅ Row 4 done → No\n",
      "✅ Row 5 done → No\n",
      "✅ Row 6 done → No\n",
      "✅ Row 7 done → No\n",
      "✅ Row 8 done → No\n",
      "✅ Row 9 done → No\n",
      "✅ Row 10 done → No\n",
      "✅ Row 11 done → No\n",
      "✅ Row 12 done → No\n",
      "✅ Row 13 done → No\n",
      "✅ Row 14 done → No\n",
      "✅ Row 15 done → No\n",
      "✅ Row 16 done → No\n",
      "✅ Row 17 done → No\n",
      "✅ Row 18 done → Yes\n",
      "✅ Row 19 done → No\n",
      "✅ Row 20 done → No\n",
      "✅ Row 21 done → No\n",
      "✅ Row 22 done → No\n",
      "✅ Row 23 done → No\n",
      "✅ Row 24 done → No\n",
      "✅ Row 25 done → No\n",
      "✅ Row 26 done → No\n",
      "✅ Row 27 done → No\n",
      "✅ Row 28 done → Yes\n",
      "✅ Row 29 done → No\n",
      "✅ Row 30 done → No\n",
      "✅ Row 31 done → No\n",
      "✅ Row 32 done → No\n",
      "✅ Row 33 done → No\n",
      "✅ Row 34 done → No\n",
      "✅ Row 35 done → No\n",
      "✅ Row 36 done → No\n",
      "✅ Row 37 done → No\n",
      "✅ Row 38 done → No\n",
      "✅ Row 39 done → No\n",
      "✅ Row 40 done → No\n",
      "✅ Row 41 done → No\n",
      "✅ Row 42 done → No\n",
      "✅ Row 43 done → No\n",
      "✅ Row 44 done → No\n",
      "✅ Row 45 done → No\n",
      "✅ Row 46 done → No\n",
      "✅ Row 47 done → No\n",
      "✅ Row 48 done → No\n",
      "✅ Row 49 done → No\n",
      "✅ Row 50 done → No\n",
      "✅ Row 51 done → No\n",
      "✅ Row 52 done → Yes\n",
      "✅ Row 53 done → No\n",
      "✅ Row 54 done → No\n",
      "✅ Row 55 done → No\n",
      "✅ Row 56 done → No\n",
      "✅ Row 57 done → No\n",
      "✅ Row 58 done → Yes\n",
      "✅ Row 59 done → No\n",
      "✅ Row 60 done → No\n",
      "✅ Row 61 done → No\n",
      "✅ Row 62 done → No\n",
      "✅ Row 63 done → No\n",
      "✅ Row 64 done → No\n",
      "✅ Row 65 done → No\n",
      "✅ Row 66 done → No\n",
      "✅ Row 67 done → No\n",
      "✅ Row 68 done → No\n",
      "✅ Row 69 done → No\n",
      "✅ Row 70 done → No\n",
      "✅ Row 71 done → No\n",
      "✅ Row 72 done → No\n",
      "✅ Row 73 done → No\n",
      "✅ Row 74 done → No\n",
      "✅ Row 75 done → No\n",
      "✅ Row 76 done → No\n",
      "✅ Row 77 done → No\n",
      "✅ Row 78 done → No\n",
      "✅ Row 79 done → No\n",
      "✅ Row 80 done → No\n",
      "✅ Row 81 done → No\n",
      "✅ Row 82 done → No\n",
      "✅ Row 83 done → No\n",
      "✅ Row 84 done → No\n",
      "✅ Row 85 done → No\n",
      "✅ Row 86 done → No\n",
      "✅ Row 87 done → No\n",
      "✅ Row 88 done → No\n",
      "✅ Row 89 done → No\n",
      "✅ Row 90 done → No\n",
      "✅ Row 91 done → No\n",
      "✅ Row 92 done → No\n",
      "✅ Row 93 done → No\n",
      "✅ Row 94 done → No\n",
      "✅ Row 95 done → No\n",
      "✅ Row 96 done → No\n",
      "✅ Row 97 done → No\n",
      "✅ Row 98 done → No\n",
      "✅ Row 99 done → No\n",
      "✅ Row 100 done → No\n",
      "✅ Row 101 done → No\n",
      "✅ Row 102 done → No\n",
      "✅ Row 103 done → No\n",
      "✅ Row 104 done → No\n",
      "✅ Row 105 done → No\n",
      "✅ Row 106 done → No\n",
      "✅ Row 107 done → No\n",
      "✅ Row 108 done → No\n",
      "✅ Row 109 done → No\n",
      "✅ Row 110 done → No\n",
      "✅ Row 111 done → No\n",
      "✅ Row 112 done → No\n",
      "✅ Row 113 done → No\n",
      "✅ Row 114 done → No\n",
      "✅ Row 115 done → No\n",
      "✅ Row 116 done → No\n",
      "✅ Row 117 done → No\n",
      "✅ Row 118 done → No\n",
      "✅ Row 119 done → No\n",
      "✅ Row 120 done → No\n",
      "✅ Row 121 done → No\n",
      "✅ Row 122 done → No\n",
      "✅ Row 123 done → No\n",
      "✅ Row 124 done → No\n",
      "✅ Row 125 done → No\n",
      "✅ Row 126 done → No\n",
      "✅ Row 127 done → No\n",
      "✅ Row 128 done → No\n",
      "✅ Row 129 done → No\n",
      "✅ Row 130 done → No\n",
      "✅ Row 131 done → No\n",
      "✅ Row 132 done → No\n",
      "✅ Row 133 done → No\n",
      "✅ Row 134 done → No\n",
      "✅ Row 135 done → No\n",
      "✅ Row 136 done → No\n",
      "✅ Row 137 done → No\n",
      "✅ Row 138 done → No\n",
      "✅ Row 139 done → No\n",
      "✅ Row 140 done → No\n",
      "✅ Row 141 done → No\n",
      "✅ Row 142 done → No\n",
      "✅ Row 143 done → No\n",
      "✅ Row 144 done → No\n",
      "✅ Row 145 done → No\n",
      "✅ Row 146 done → Yes\n",
      "✅ Row 147 done → No\n",
      "✅ Row 148 done → No\n",
      "✅ Row 149 done → No\n",
      "✅ Row 150 done → Yes\n",
      "✅ Row 151 done → No\n",
      "✅ Row 152 done → No\n",
      "✅ Row 153 done → No\n",
      "✅ Row 154 done → No\n",
      "✅ Row 155 done → No\n",
      "✅ Row 156 done → No\n",
      "✅ Row 157 done → No\n",
      "✅ Row 158 done → No\n",
      "✅ Row 159 done → No\n",
      "✅ Row 160 done → No\n",
      "✅ Row 161 done → No\n",
      "✅ Row 162 done → No\n",
      "✅ Row 163 done → No\n",
      "✅ Row 164 done → No\n",
      "✅ Row 165 done → No\n",
      "✅ Row 166 done → No\n",
      "✅ Row 167 done → No\n",
      "✅ Row 168 done → No\n",
      "✅ Row 169 done → No\n",
      "✅ Row 170 done → No\n",
      "✅ Row 171 done → No\n",
      "✅ Row 172 done → No\n",
      "✅ Row 173 done → Yes\n",
      "✅ Row 174 done → No\n",
      "✅ Row 175 done → No\n",
      "✅ Row 176 done → No\n",
      "✅ Row 177 done → No\n",
      "✅ Row 178 done → No\n",
      "✅ Row 179 done → No\n",
      "✅ Row 180 done → No\n",
      "✅ Row 181 done → No\n",
      "✅ Row 182 done → No\n",
      "✅ Row 183 done → No\n",
      "✅ Row 184 done → No\n",
      "✅ Row 185 done → No\n",
      "✅ Row 186 done → No\n",
      "✅ Row 187 done → No\n",
      "✅ Row 188 done → No\n",
      "✅ Row 189 done → No\n",
      "✅ Row 190 done → No\n",
      "✅ Row 191 done → No\n",
      "✅ Row 192 done → No\n",
      "✅ Row 193 done → No\n",
      "✅ Row 194 done → No\n",
      "✅ Row 195 done → No\n",
      "✅ Row 196 done → No\n",
      "✅ Row 197 done → No\n",
      "✅ Row 198 done → No\n",
      "✅ Row 199 done → No\n",
      "✅ Row 200 done → No\n",
      "✅ Row 201 done → No\n",
      "✅ Row 202 done → No\n",
      "✅ Row 203 done → No\n",
      "✅ Row 204 done → No\n",
      "✅ Row 205 done → No\n",
      "✅ Row 206 done → No\n",
      "✅ Row 207 done → No\n",
      "✅ Row 208 done → No\n",
      "✅ Row 209 done → No\n",
      "✅ Row 210 done → No\n",
      "✅ Row 211 done → No\n",
      "✅ Row 212 done → No\n",
      "✅ Row 213 done → No\n",
      "✅ Row 214 done → No\n",
      "✅ Row 215 done → No\n",
      "✅ Row 216 done → No\n",
      "✅ Row 217 done → No\n",
      "✅ Row 218 done → No\n",
      "✅ Row 219 done → No\n",
      "✅ Row 220 done → No\n",
      "✅ Row 221 done → No\n",
      "✅ Row 222 done → No\n",
      "✅ Row 223 done → No\n",
      "✅ Row 224 done → No\n",
      "✅ Row 225 done → No\n",
      "✅ Row 226 done → No\n",
      "✅ Row 227 done → No\n",
      "✅ Row 228 done → No\n",
      "✅ Row 229 done → No\n",
      "✅ Row 230 done → No\n",
      "✅ Row 231 done → No\n",
      "✅ Row 232 done → No\n",
      "✅ Row 233 done → No\n",
      "✅ Row 234 done → No\n",
      "✅ Row 235 done → No\n",
      "✅ Row 236 done → No\n",
      "✅ Row 237 done → No\n",
      "✅ Row 238 done → No\n",
      "✅ Row 239 done → No\n",
      "✅ Row 240 done → No\n",
      "✅ Done! الملف النهائي محفوظ في: C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_full_Final.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. تحميل LLM من Hugging Face\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=-1)  # CPU\n",
    "\n",
    "# -----------------------------\n",
    "# 3. دالة استخراج الأرقام من النص\n",
    "def extract_numbers(text):\n",
    "    try:\n",
    "        return [float(n.replace(',', '').replace('$','').replace('B','e9').replace('M','e6')) \n",
    "                for n in re.findall(r'\\d+\\.?\\d*B?M?', str(text))]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# -----------------------------\n",
    "# 4. دالة تقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = str(text).split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------\n",
    "# 5. دالة الحكم على كل snippet\n",
    "def check_snippet_equal(ground_truth, snippet, tolerance=0.05):\n",
    "    gt_numbers = extract_numbers(ground_truth)\n",
    "    snippet_numbers = extract_numbers(snippet)\n",
    "    numbers_match = False\n",
    "\n",
    "    for gt in gt_numbers:\n",
    "        if gt == 0:   # تجنب القسمة على صفر\n",
    "            continue\n",
    "        for sn in snippet_numbers:\n",
    "            if abs(gt - sn)/gt <= tolerance:\n",
    "                numbers_match = True\n",
    "                break\n",
    "        if numbers_match:\n",
    "            break\n",
    "\n",
    "    if gt_numbers and not numbers_match:\n",
    "        return \"Yes\"\n",
    "\n",
    "    chunks = chunk_text(snippet)\n",
    "    text_match = False\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"Ground truth: {ground_truth}\\nSnippet: {chunk}\\nAnswer Yes/No only.\"\n",
    "        try:\n",
    "            result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        except Exception as e:\n",
    "            return \"Error\"\n",
    "        if \"no\" in result.lower():\n",
    "            text_match = True\n",
    "            break\n",
    "\n",
    "    if numbers_match or text_match:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6. معالجة كل الصفوف مع الحفظ التدريجي\n",
    "progress_csv = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\progress.csv\"\n",
    "output_excel = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_full_Final.xlsx\"\n",
    "\n",
    "for idx in range(len(df)):\n",
    "    try:\n",
    "        df.at[idx, \"need_script\"] = check_snippet_equal(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "        print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "    except Exception as e:\n",
    "        df.at[idx, \"need_script\"] = \"Error\"\n",
    "        print(f\"⚠️ Row {idx+1} Error → {e}\")\n",
    "\n",
    "    # حفظ تقدم تدريجي في CSV (خفيف وما يقفل الملف)\n",
    "    if idx % 5 == 0:  # كل 5 صفوف\n",
    "        df.to_csv(progress_csv, index=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. الحفظ النهائي في Excel\n",
    "df.to_excel(output_excel, index=False)\n",
    "print(\"✅ Done! الملف النهائي محفوظ في:\", output_excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8265a086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset cleaned and saved to: C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_cleaned_4.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. إزالة الصفوف اللي عمود brave_sinp فيها فاضي أو NaN\n",
    "df = df[df['brave_sinp'].notna() & (df['brave_sinp'].str.strip() != \"\")]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. تطبيع عمود need_script (Yes/No) مع الاحتفاظ بالقيم الأخرى\n",
    "def normalize_need_script(x):\n",
    "    val = str(x).strip().lower()\n",
    "    if val == \"yes\":\n",
    "        return \"Yes\"\n",
    "    elif val == \"no\":\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return x  # الاحتفاظ بالقيمة الأصلية\n",
    "\n",
    "df['need_script'] = df['need_script'].apply(normalize_need_script)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. إزالة التكرارات داخل كل خلية في عمود links\n",
    "def unique_links(cell):\n",
    "    try:\n",
    "        links = ast.literal_eval(str(cell))\n",
    "        return list(set(links))  # إزالة التكرارات\n",
    "    except:\n",
    "        return cell\n",
    "\n",
    "df['links'] = df['links'].apply(unique_links)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. حفظ الملف بعد التنظيف\n",
    "output_file = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_cleaned_4.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "print(\"✅ Dataset cleaned and saved to:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c02988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#كود فصل الروابط ##############\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def check_need_script(row):\n",
    "    ground_truth = str(row['ground_truth']).lower()\n",
    "    \n",
    "    try:\n",
    "        sinp_list = ast.literal_eval(str(row['brave_sinp']))\n",
    "    except:\n",
    "        return \"Yes\"  # لو صار خطأ نخليها Yes\n",
    "    \n",
    "    for item in sinp_list:\n",
    "        text = str(item.get('text', '')).lower()\n",
    "        # نتحقق إذا فيه تقاطع جزئي\n",
    "        if text in ground_truth or ground_truth in text:\n",
    "            return \"No\"\n",
    "    return \"Yes\"\n",
    "\n",
    "# نضيف العمود الجديد\n",
    "df['need_script'] = df.apply(check_need_script, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "#كود ازالة التكرارات الروابط\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. إزالة الصفوف اللي عمود brave_sinp فيها فاضي أو NaN\n",
    "df = df[df['brave_sinp'].notna() & (df['brave_sinp'].str.strip() != \"\")]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. تطبيع عمود need_script (Yes/No) مع الاحتفاظ بالقيم الأخرى\n",
    "def normalize_need_script(x):\n",
    "    val = str(x).strip().lower()\n",
    "    if val == \"yes\":\n",
    "        return \"Yes\"\n",
    "    elif val == \"no\":\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return x  # الاحتفاظ بالقيمة الأصلية\n",
    "\n",
    "df['need_script'] = df['need_script'].apply(normalize_need_script)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. إزالة التكرارات داخل كل خلية في عمود links\n",
    "def unique_links(cell):\n",
    "    try:\n",
    "        links = ast.literal_eval(str(cell))\n",
    "        return list(set(links))  # إزالة التكرارات\n",
    "    except:\n",
    "        return cell\n",
    "\n",
    "df['links'] = df['links'].apply(unique_links)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. حفظ الملف بعد التنظيف\n",
    "output_file = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_cleaned_4.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "print(\"✅ Dataset cleaned and saved to:\", output_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################\n",
    "#كود هل يحتاج الground truth سكربت او لا \n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "\n",
    "# -----------------------------\n",
    "# 1. تحميل الملف\n",
    "file_path = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\brave_sec_t2_with_script.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. تحميل LLM من Hugging Face\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=-1)  # CPU\n",
    "\n",
    "# -----------------------------\n",
    "# 3. دالة استخراج الأرقام من النص\n",
    "def extract_numbers(text):\n",
    "    try:\n",
    "        return [float(n.replace(',', '').replace('$','').replace('B','e9').replace('M','e6')) \n",
    "                for n in re.findall(r'\\d+\\.?\\d*B?M?', str(text))]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# -----------------------------\n",
    "# 4. دالة تقسيم النصوص الطويلة\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    words = str(text).split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        chunks.append(\" \".join(words[i:i+max_tokens]))\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------\n",
    "# 5. دالة الحكم على كل snippet\n",
    "def check_snippet_equal(ground_truth, snippet, tolerance=0.05):\n",
    "    gt_numbers = extract_numbers(ground_truth)\n",
    "    snippet_numbers = extract_numbers(snippet)\n",
    "    numbers_match = False\n",
    "\n",
    "    for gt in gt_numbers:\n",
    "        if gt == 0:   # تجنب القسمة على صفر\n",
    "            continue\n",
    "        for sn in snippet_numbers:\n",
    "            if abs(gt - sn)/gt <= tolerance:\n",
    "                numbers_match = True\n",
    "                break\n",
    "        if numbers_match:\n",
    "            break\n",
    "\n",
    "    if gt_numbers and not numbers_match:\n",
    "        return \"Yes\"\n",
    "\n",
    "    chunks = chunk_text(snippet)\n",
    "    text_match = False\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"Ground truth: {ground_truth}\\nSnippet: {chunk}\\nAnswer Yes/No only.\"\n",
    "        try:\n",
    "            result = qa_model(prompt, max_new_tokens=20, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "        except Exception as e:\n",
    "            return \"Error\"\n",
    "        if \"no\" in result.lower():\n",
    "            text_match = True\n",
    "            break\n",
    "\n",
    "    if numbers_match or text_match:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6. معالجة كل الصفوف مع الحفظ التدريجي\n",
    "progress_csv = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\progress.csv\"\n",
    "output_excel = r\"C:\\Users\\SarahAlqahtani\\Documents\\code\\need_script_full_Final.xlsx\"\n",
    "\n",
    "for idx in range(len(df)):\n",
    "    try:\n",
    "        df.at[idx, \"need_script\"] = check_snippet_equal(df.at[idx, \"ground_truth\"], df.at[idx, \"brave_sinp\"])\n",
    "        print(f\"✅ Row {idx+1} done → {df.at[idx, 'need_script']}\")\n",
    "    except Exception as e:\n",
    "        df.at[idx, \"need_script\"] = \"Error\"\n",
    "        print(f\"⚠️ Row {idx+1} Error → {e}\")\n",
    "\n",
    "    # حفظ تقدم تدريجي في CSV (خفيف وما يقفل الملف)\n",
    "    if idx % 5 == 0:  # كل 5 صفوف\n",
    "        df.to_csv(progress_csv, index=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. الحفظ النهائي في Excel\n",
    "df.to_excel(output_excel, index=False)\n",
    "print(\"✅ Done! الملف النهائي محفوظ في:\", output_excel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53595147",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_scores = evaluate_accuracy_llm(query, flat_context, ai_reply)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
